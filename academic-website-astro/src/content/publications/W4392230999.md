---
title: Large Language Models and Artificial Intelligence for Police Report Writing
authors:
- Ian T. Adams
date: '2024-01-01'
publishDate: '2024-01-01'
publication_types:
- '3'
publication: CrimRxiv
publication_short: ''
abstract: Large Language Models (LLMs), such as ChatGPT, are advanced artificial intelligence
  systems capable of understanding and generating human-like text. They are trained
  on vast amounts of textual data, enabling them to comprehend context, answer questions,
  generate summaries, and even engage in meaningful conversations. As these models
  continue to evolve, their potential applications in various industries, including
  law enforcement, are becoming more apparent, as are the potential threats <https://www.europol.europa.eu/publications-events/publications/chatgpt-impact-of-large-language-models-law-enforcement>
  . One particularly promising area of application for LLMs in policing is report
  writing. As many police executives know, not all officers possess strong writing
  skills, which can lead to inaccurate or incomplete reports. This can have serious
  consequences for criminal prosecutions, as well as expose departments to civil liability
  concerns. Implementing LLMs like ChatGPT for report-writing assistance may help
  address these issues. Even if not fully implemented at the agency level, officers
  across the country are already using these tools to help in their report generation.
  Given the stakes, it is wise for agencies to have a sophisticated view and policy
  on these tools. This paper introduces practitioners to LLMs for report writing,
  considers the implications of using such tools, and suggests a template-based approach
  to deploying the technology to patrol officers.
summary: Police officers are already using AI writing tools like ChatGPT to help write
  reports, but many departments lack clear policies about this practice. Poor report
  writing by officers can undermine criminal cases and expose police departments to
  lawsuits, so AI assistance could potentially improve report quality and reduce these
  risks. The research suggests that police departments need to develop guidelines
  for how officers can safely and effectively use these AI tools rather than ignoring
  their widespread informal use.
featured: false
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: https://doi.org/10.21428/cb6ab371.779603ee
url_video: ''
projects: []
tags: []
categories: []
links:
- name: OpenAlex
  url: https://openalex.org/W4392230999
- name: DOI
  url: https://doi.org/10.21428/cb6ab371.779603ee
---

## Summary

Police officers are already using AI writing tools like ChatGPT to help write reports, but many departments lack clear policies about this practice. Poor report writing by officers can undermine criminal cases and expose police departments to lawsuits, so AI assistance could potentially improve report quality and reduce these risks. The research suggests that police departments need to develop guidelines for how officers can safely and effectively use these AI tools rather than ignoring their widespread informal use.

*(AI-generated summary, v1, January 2026)*

## Citation Information

**Citations:** 6 (as of January 2026)

[View Publication](https://doi.org/10.21428/cb6ab371.779603ee)
