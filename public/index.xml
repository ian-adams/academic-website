<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ian T. Adams</title>
    <link>https://ianadamsresearch.com/</link>
      <atom:link href="https://ianadamsresearch.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Ian T. Adams</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>©`2026`</copyright><lastBuildDate>Sun, 04 Jan 2026 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ianadamsresearch.com/media/android-chrome-512x512.png</url>
      <title>Ian T. Adams</title>
      <link>https://ianadamsresearch.com/</link>
    </image>
    
    <item>
      <title>Interactive Dashboard for Mapping Police Violence Data</title>
      <link>https://ianadamsresearch.com/post/2026-01-04-mapping-police-violence-dashboard/</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/2026-01-04-mapping-police-violence-dashboard/</guid>
      <description>


&lt;p&gt;I’ve developed an interactive dashboard to explore data from &lt;a href=&#34;https://mappingpoliceviolence.org/&#34;&gt;Mapping Police Violence&lt;/a&gt;, a comprehensive database tracking police killings in the United States. The dashboard automatically pulls the latest data and provides multiple analytical views to examine temporal trends, demographic patterns, and geographic distributions.&lt;/p&gt;
&lt;div id=&#34;dashboard-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dashboard Features&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;MPV Analytical Engine&lt;/strong&gt; includes several key analytical modules:&lt;/p&gt;
&lt;div id=&#34;overview-panel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview Panel&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Real-time statistics including total incidents, per capita rates, and demographic breakdowns&lt;/li&gt;
&lt;li&gt;Cumulative trajectory visualization comparing year-over-year trends&lt;/li&gt;
&lt;li&gt;Temporal heatmaps showing patterns by day and month&lt;/li&gt;
&lt;li&gt;Day-of-week analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;demographics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Demographics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Racial and ethnic distribution of victims&lt;/li&gt;
&lt;li&gt;Age distribution and age-by-race breakdowns&lt;/li&gt;
&lt;li&gt;Analysis of unarmed victims by demographic group&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;behavioral-context&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Behavioral Context&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Armed/unarmed status of victims&lt;/li&gt;
&lt;li&gt;Types of alleged weapons&lt;/li&gt;
&lt;li&gt;Fleeing status at time of incident&lt;/li&gt;
&lt;li&gt;Mental health-related encounters over time&lt;/li&gt;
&lt;li&gt;Body camera adoption trends&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;geographic-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geographic Analysis&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;National map of incidents&lt;/li&gt;
&lt;li&gt;State and city-level breakdowns&lt;/li&gt;
&lt;li&gt;Top jurisdictions by incident count&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;accountability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Accountability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Criminal charges filed against officers over time&lt;/li&gt;
&lt;li&gt;Neighborhood income disparities&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;interactive-dashboard&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interactive Dashboard&lt;/h2&gt;
&lt;iframe src=&#34;https://iadams.shinyapps.io/Shiny_police_killings/&#34; width=&#34;100%&#34; height=&#34;800px&#34; style=&#34;border: 1px solid #ccc; border-radius: 4px;&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The dashboard may take a moment to load as it downloads and processes the latest data from Mapping Police Violence.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://iadams.shinyapps.io/Shiny_police_killings/&#34;&gt;Click here to open the dashboard in a new window&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;important-methodological-notes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Important Methodological Notes&lt;/h2&gt;
&lt;p&gt;This dashboard presents &lt;strong&gt;descriptive statistics only&lt;/strong&gt;. The data shows observed patterns but cannot establish causal relationships without additional controls for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Local crime rates&lt;/li&gt;
&lt;li&gt;Police deployment density&lt;/li&gt;
&lt;li&gt;Population demographics&lt;/li&gt;
&lt;li&gt;Socioeconomic factors&lt;/li&gt;
&lt;li&gt;Jurisdictional policies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The dashboard uses US Census population projections (2013-2025) to calculate per capita rates. All racial categorizations follow the source data from Mapping Police Violence.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-source&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Source&lt;/h2&gt;
&lt;p&gt;Data is automatically synchronized from &lt;a href=&#34;https://mappingpoliceviolence.org/&#34;&gt;Mapping Police Violence&lt;/a&gt;, which aggregates information from:
- Fatal Encounters
- The Washington Post’s Fatal Force database
- Additional cases identified through crowdsourcing and research&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;technical-details&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;The dashboard is built using:
- &lt;strong&gt;R Shiny&lt;/strong&gt; with the &lt;code&gt;bslib&lt;/code&gt; framework for modern UI components
- &lt;strong&gt;tidyverse&lt;/strong&gt; for data manipulation
- &lt;strong&gt;plotly&lt;/strong&gt; for interactive visualizations
- &lt;strong&gt;sf&lt;/strong&gt; and &lt;strong&gt;rnaturalearth&lt;/strong&gt; for geographic mapping&lt;/p&gt;
&lt;p&gt;The app automatically downloads fresh data daily and includes robust data cleaning pipelines to standardize variables across time periods.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;code-availability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code Availability&lt;/h2&gt;
&lt;p&gt;The complete source code for this dashboard is available in the &lt;a href=&#34;https://github.com/ian-adams/academic-website/tree/master/shiny-apps/mpv-dashboard&#34;&gt;academic-website repository&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;This dashboard is provided for research and educational purposes. The data presented reflects reported incidents and should be interpreted within the context of broader research on policing, public safety, and racial justice.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Agency-level fatal police shootings over time</title>
      <link>https://ianadamsresearch.com/post/agency-level-fatal-police-shootings-over-time/</link>
      <pubDate>Sun, 09 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/agency-level-fatal-police-shootings-over-time/</guid>
      <description>


&lt;p&gt;Dr. Justin Nix has been &lt;a href=&#34;https://github.com/jnixy/agency-level-fatal-OIS&#34;&gt;hard at work locating historical data&lt;/a&gt; for lethal police shootings in the United States. With his permission, the following tool allows you to see individual agencies in the dataset.&lt;/p&gt;
&lt;p&gt;Several limitations are to be noted with this data, please see &lt;a href=&#34;https://jnix.netlify.app/post/post23-are-ois-increasing/&#34;&gt;his post explaining the project for more&lt;/a&gt;.&lt;/p&gt;
&lt;iframe height=&#34;800&#34; width=&#34;100%&#34; frameborder=&#34;no&#34; src=&#34;https://ian-adams.shinyapps.io/visualize_agency_OIS_time/?_ga=2.133213966.1689258234.1681081673-2145317459.1681081673&#34;&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>LEMAS 2016 and 2020 Turnover Comparison</title>
      <link>https://ianadamsresearch.com/post/lemas-2016-and-2020-turnover-comparison/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/lemas-2016-and-2020-turnover-comparison/</guid>
      <description>


&lt;p&gt;In this blog post, we will analyze and compare the turnover rates of local police agencies with 100 or more sworn officers in the United States using the Law Enforcement Management and Administrative Statistics (LEMAS) data from 2016 and 2020. By the end of this post, you will learn how to import, preprocess, and visualize the LEMAS data to gain insights into the turnover rates of law enforcement agencies.&lt;/p&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;p&gt;First, let’s load the required libraries and set some global options for our code chunks. We will be using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(readr)
library(here)
library(scales)
library(viridis)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will import the 2016 and 2020 LEMAS data and preprocess it, including cleaning column names and selecting relevant columns for our analysis. Make sure you have already imported the 2016 data to an object named &lt;code&gt;df_raw_2016&lt;/code&gt; and the 2020 data to one named &lt;code&gt;df_raw_2020&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-import-and-preprocessing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Import and Preprocessing&lt;/h2&gt;
&lt;p&gt;In this section, we will import the 2016 and 2020 LEMAS data, preprocess the data, and calculate the turnover rates.&lt;/p&gt;
&lt;div id=&#34;lemas-2016-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LEMAS 2016 Data&lt;/h3&gt;
&lt;p&gt;Let’s start by importing the 2016 LEMAS data and preprocessing it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Import 2016 data

# Select relevant columns and calculate vacancies
df_2016 &amp;lt;- df_raw_2016 %&amp;gt;% select(
  lear_id,
  agencyname,
  agencytype,
  strata,
  population = popserved,
  ftsauth,
  ftsworn,
  total_separations = pers_sep_totr
) %&amp;gt;% mutate(vacancies = ftsauth - ftsworn) %&amp;gt;%
  filter(vacancies &amp;gt;= 0)

# Calculate vacancy and turnover rates
df_2016 &amp;lt;- df_2016 %&amp;gt;%
  mutate(vac_rate = (round((vacancies)/(ftsauth), digits = 2))*100,
         turnover_rate = total_separations / ftsworn)

# Filter agencies with 100 or more sworn officers
df100_2016 &amp;lt;- df_2016 %&amp;gt;% filter(strata == &amp;quot;(101) LP: 100+&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;lemas-2020-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LEMAS 2020 Data&lt;/h3&gt;
&lt;p&gt;Now, let’s import and preprocess the 2020 LEMAS data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Import 2020 data

# Renaming
df_2020 &amp;lt;- df_raw_2020 %&amp;gt;% select(
  agencyid,
  agencyname,
  agencytype = agencysamptype,
  strata,
  population = primarypop2020,
  sworn2019 = ftsworn_2019,
  sworn2020 = ftsworn,
  total_separations = tot_sep,
  vacancy2019 = ftvac_2019,
  vacancy2020 = ftvac
)


# Calculate vacancy rates
df_2020$vac_rate2020 &amp;lt;- (round((df_2020$vacancy2020)/(df_2020$sworn2020 + df_2020$vacancy2020), digits = 2))*100
df_2020$vac_rate2019 &amp;lt;- (round((df_2020$vacancy2019)/(df_2020$sworn2019 + df_2020$vacancy2019), digits = 2))*100

df_2020$turnover_rate &amp;lt;- df_2020$total_separations / df_2020$sworn2020

df100_2020 &amp;lt;- df_2020 %&amp;gt;% filter(sworn2019 &amp;gt; 99)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have imported and preprocessed both the 2016 and 2020 LEMAS datasets, let’s move on to visualizing the turnover rates and comparing them side-by-side.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;turnover-rate-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Turnover Rate Comparison&lt;/h2&gt;
&lt;p&gt;In this section, we will create a side-by-side comparison of the 2016 and 2020 turnover rates for local police agencies with 100 or more sworn officers.&lt;/p&gt;
&lt;p&gt;First, we will filter out the outliers and calculate the mean and standard deviation for the turnover rates in both datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df100_filtered_2016 &amp;lt;- df100_2016 %&amp;gt;% 
  filter(turnover_rate &amp;lt;= 0.30)

turnover_mean_2016 &amp;lt;- mean(df100_filtered_2016$turnover_rate, na.rm = TRUE)
turnover_sd_2016 &amp;lt;- sd(df100_filtered_2016$turnover_rate, na.rm = TRUE)

df100_filtered_2020 &amp;lt;- df100_2020 %&amp;gt;% 
  filter(turnover_rate &amp;lt;= 0.30)

turnover_mean_2020 &amp;lt;- mean(df100_filtered_2020$turnover_rate, na.rm = TRUE)
turnover_sd_2020 &amp;lt;- sd(df100_filtered_2020$turnover_rate, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let’s create a reusable function to generate the turnover rate plots for both years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_turnover &amp;lt;- function(df, year, mean, sd) {
  ggplot(data = df, aes(x = turnover_rate)) +  # Create the base ggplot with turnover_rate on the x-axis
    geom_histogram(binwidth = 0.025, fill = &amp;quot;steelblue&amp;quot;, color = &amp;quot;white&amp;quot;) +  # Add a histogram with custom colors and binwidth
    scale_x_continuous(breaks = seq(0, 0.5, 0.02), labels = scales::percent) +  # Set x-axis breaks and labels
    labs(title = paste0(year, &amp;quot; Turnover Rate&amp;quot;),  # Set the title
         subtitle = paste0(&amp;quot;Local Police Agencies with 100+ Sworn Officers (n=&amp;quot;, nrow(df), &amp;quot;)\n&amp;quot;,
                           &amp;quot;Mean: &amp;quot;, scales::percent(mean, accuracy = 0.01), &amp;quot; | &amp;quot;,
                           &amp;quot;SD: &amp;quot;, scales::percent(sd, accuracy = 0.01)),  # Set the subtitle with mean and SD values
         x = &amp;quot;Turnover Rate&amp;quot;,  # Set the x-axis label
         y = &amp;quot;Frequency&amp;quot;) +  # Set the y-axis label
    geom_vline(xintercept = mean, linetype=&amp;quot;dashed&amp;quot;, linewidth = 1.5, color = &amp;quot;yellow&amp;quot;) +  # Add a vertical dashed line at the mean
    theme_minimal() +  # Apply the minimal theme
    theme(plot.title = element_text(size = 18, face = &amp;quot;bold&amp;quot;, margin = margin(10, 0, 5, 0)),
          plot.subtitle = element_text(size = 14, margin = margin(0, 0, 10, 0)),
          axis.title = element_text(size = 14, face = &amp;quot;bold&amp;quot;),
          axis.text = element_text(size = 12),
          panel.grid.major.y = element_line(color = &amp;quot;gray&amp;quot;, linetype = &amp;quot;dashed&amp;quot;))  # Customize theme elements
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the plot_turnover function, let’s create the turnover rate plots for 2016 and 2020.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_2016 &amp;lt;- plot_turnover(df100_filtered_2016, &amp;quot;2016&amp;quot;, turnover_mean_2016, turnover_sd_2016)
plot_2020 &amp;lt;- plot_turnover(df100_filtered_2020, &amp;quot;2020&amp;quot;, turnover_mean_2020, turnover_sd_2020)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let’s display the plots side-by-side to compare the turnover rates in 2016 and 2020&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_2016
plot_2020&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/lemas-2016-and-2020-turnover-comparison/index.en_files/figure-html/display_plots-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/lemas-2016-and-2020-turnover-comparison/index.en_files/figure-html/display_plots-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the side-by-side comparison, we can observe the differences in turnover rates between 2016 and 2020 for local police agencies with 100 or more sworn officers. Note the distribution of the turnover rates and how the mean and standard deviation have changed over time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post, I have demonstrated how to import, preprocess, and visualize the LEMAS 2016 and 2020 datasets to analyze and compare the turnover rates in local police agencies with 100 or more sworn officers. The side-by-side comparison of the turnover rates provides valuable insights into the changes within law enforcement agencies over the years.&lt;/p&gt;
&lt;p&gt;By following these steps, you can further explore and analyze the LEMAS data and draw conclusions about various aspects of law enforcement management and administration.&lt;/p&gt;
&lt;p&gt;Feel free to extend this analysis to other variables or subsets of agencies within the LEMAS data or even compare other years to gain a deeper understanding of trends in law enforcement. Happy analyzing!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Counting &#34;Select All That Apply&#34; Questions in Qualtrics</title>
      <link>https://ianadamsresearch.com/post/counting-select-all-that-apply-questions-in-qualtrics-using-r/</link>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/counting-select-all-that-apply-questions-in-qualtrics-using-r/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/counting-select-all-that-apply-questions-in-qualtrics-using-r/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;qualtrics-messy-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Qualtrics Messy Data&lt;/h1&gt;
&lt;p&gt;My friend &lt;a href=&#34;https://www.devoncantwell.com/about-devon&#34;&gt;Devon Cantwell&lt;/a&gt; reached out with an interesting messy data caused by how Qualtrics produces “select all that apply” variables. For example, in her (mock) survey, she asks students to select all the colors that they personally find attractive from a list. When downloaded from Qualtrics, we get a dataframe that looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 940
## Columns: 4
## $ color_1 &amp;lt;fct&amp;gt; Sparkle, Blue, Blue, Sparkle, Blue, Sparkle, Sparkle, Green, B~
## $ color_2 &amp;lt;fct&amp;gt; NA, Moldy Book, NA, Moldy Book, Moldy Book, Honey Bee, Moldy B~
## $ color_3 &amp;lt;fct&amp;gt; NA, Apple Core Brown, NA, Apple Core Brown, NA, NA, NA, NA, NA~
## $ color_4 &amp;lt;fct&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So all students pick at least one color, some pick two, but relatively few pick three or four. One thing we might want to know is the first color selected by respondent? That’s relatively easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;% count(color_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##   color_1              n
##   &amp;lt;fct&amp;gt;            &amp;lt;int&amp;gt;
## 1 Blue               233
## 2 Green              134
## 3 Yellow              14
## 4 Sparkle            189
## 5 Apple Core Brown     6
## 6 Honey Bee           13
## 7 Moldy Book          42
## 8 &amp;lt;NA&amp;gt;               309&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this only tells us the first color selected, not how many times a color was selected. What if we want to count all the instances where “Moldy Book” was selected, across columns? Or getting a more succinct answer for all colors? Because these are not ordered in any way, and the respondent wasn’t asked for an ordered preference, we need to count across the variables.&lt;/p&gt;
&lt;p&gt;We can use &lt;code&gt;tidyr&lt;/code&gt; for a quick solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyr)

dat %&amp;gt;%
  gather(key, value, na.rm = TRUE) %&amp;gt;%
  count(value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attributes are not identical across measure variables;
## they will be dropped&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 2
##   value                n
##   &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;
## 1 Apple Core Brown    78
## 2 Blue               233
## 3 Green              134
## 4 Honey Bee           32
## 5 Moldy Book         222
## 6 Sparkle            230
## 7 Yellow              38&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Good thing we checked! It turns out that Sparkle and Moldy Book are basically just as popular as Blue! If we had stopped with just checking the first color picked, our inference for color preference would have been way off.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Developing Race and Gender Estimates for US Law Enforcement Leadership</title>
      <link>https://ianadamsresearch.com/post/developing-race-and-gender-estimates-for-us-law-enforcement-leadership/</link>
      <pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/developing-race-and-gender-estimates-for-us-law-enforcement-leadership/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/developing-race-and-gender-estimates-for-us-law-enforcement-leadership/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://ianadamsresearch.com/post/developing-race-and-gender-estimates-for-us-law-enforcement-leadership/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://ianadamsresearch.com/post/developing-race-and-gender-estimates-for-us-law-enforcement-leadership/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Researchers might be interested in developing a descriptive understanding of the gender and race composition of a particular industry, organization, or other institution. Oftentimes this is done with sampling from a population. This is the case in law enforcement. With approximately 18,000 sub-federal law enforcement agencies in the United States, and somewhere around 800,000 officers, it can be a challenging environment for researchers. Given the huge variation in agency type, size, composition, etc., generalizing across “law enforcement” is tricky at best.&lt;/p&gt;
&lt;p&gt;In this preliminary analysis, I attempt a population-level inference for US law enforcement agencies, to develop estimates of race and gender proportions in the “chief executive” spot. The chief executive for a sherrif’s office is the Sheriff (often elected), while in a state-level agency it might be Executive Director - there is a lot of variation.&lt;/p&gt;
&lt;div id=&#34;gender-and-race-in-us-law-enforcement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gender and Race in US Law Enforcement&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1080/08974454.2018.1520674&#34;&gt;John Shjarback and Natalie Todak (2019)&lt;/a&gt; use data from the 2013 Law Enforcement Management and Administrative Statistics (LEMAS) survey to analyze correlates of women in supervisory, mid-level, and chief executive roles in 2,826 municipal police, sheriff’s offices, and primary state law enforcement agencies. The 2013 LEMAS data was the first national survey to report on this level of data, and &lt;strong&gt;just 2.7% of the agencies were led by women&lt;/strong&gt;. My goal here will be to see if using a commercial database of a much larger set of agencies, combined with a probabilistic estimate of gender and race, compares to the estimates from the 2013 LEMAS.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bjs.ojp.gov/content/pub/pdf/lpd16p.pdf&#34;&gt;The 2016 LEMAS&lt;/a&gt; estimates that for chiefs across all size of local agencies, 89.6% were White, 4% Black, 3.1% Hispanic, and 2.4% other. It also estimates that in those same agencies, just 2.6% of chiefs were female. However, this 2016 sample design results in 2,612 local agencies (rather than the larger sample of all agencies), and uses a stratified sampling that intentionally oversamples from the largest agencies (+100 full-time officers).&lt;/p&gt;
&lt;p&gt;But another method might be obtaining population-level information and inferring race and gender for the individuals based on that information. &lt;a href=&#34;https://jacobdkaplan.com/&#34;&gt;Jacob Kaplan&lt;/a&gt; has developed the &lt;code&gt;predictrace&lt;/code&gt; package to do just that. The package develops a probability of race and gender based on the first name of a subject. This is from &lt;a href=&#34;https://jacobkap.github.io/predictrace/index.html&#34;&gt;the package’s introduction&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of predictrace is to predict the race of a surname or first name and the gender of a first name. This package uses U.S. Census data which says how many people of each race has a certain surname. For first name data, this package uses data from Tzioumis (2018). From this we can predict which race is mostly likely to have that surname or first name. The possible races are American Indian, Asian, Black, Hispanic, White, or two or more races. For the gender of first names, this package uses data from the United States Social Security Administration (SSA) that tells how many people of a given name are female and how many are male (no other genders are included). I use this to determine the proportion of each gender a name is, and use the gender with the higher proportion as the most likely gender for that name. Please note that the Census data on the race of first names is far smaller than the SSA data on the gender of first names, so you will match far fewer first names to race than to gender.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;In this short demonstration, I will attempt to develop race and gender estimates for individuals who lead US law enforcement agencies. To do so, I will rely on a commercial dataset from the National Directory of Law Enforcement Administrators (NDLEA). The dataset contains just over 37,000 listings for the chief administrator of law enforcement organizations at every level of the US system - from municipal police to heads of major federal agencies like the FBI, and everything in-between. The company that puts this database together commits to contacting every agency on the list at least once a year, and the company representative I spoke to said they are closer to once every three months. In my experience the dataset has been very reliable when I need to contact a head administrator directly.&lt;/p&gt;
&lt;p&gt;However, in order to constrain the analysis, I will just be looking at Campus Law Enforcement, County Sheriffs, and Municipal Law Enforcement agencies (n=17,104). Because I look at some correlations later with population, I drop any observations missing that information (missing n= 204), leaving a total of 16,900 observations. I’ll also reduce this to a simpler dataset by retaining only the department type, first name of administrator, state, and population served.&lt;/p&gt;
Let’s check and see if that looks right.
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
DeptType
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
FirstName
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
MailingState
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Population
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Campus Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dave
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paul
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
VA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Justin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AK
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100k-1M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Thomas
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MI
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25k-50k
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Troy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MO
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Ronald
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Julian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100k-1M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
John
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
OK
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
David
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MI
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
PA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;25,000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Looks like population data is pretty spotty (there’s an outlier from a typo that had the population of Shelby County, TN, at over 93 million! I fixed it behind the scenes here), but that’s not our main focus here today. Overall, it’s looking pretty good!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inferring-race-and-gender-from-first-name-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inferring Race and Gender from First Name Data&lt;/h2&gt;
&lt;p&gt;Kaplan’s package &lt;code&gt;predictrace&lt;/code&gt; will derive a gender and race classification for first names contained within our dataset. First we’ll use the &lt;code&gt;predict_gender&lt;/code&gt; call, and then the &lt;code&gt;predict_race&lt;/code&gt; functions to build the initial lists.&lt;/p&gt;
&lt;p&gt;As you can see, the package reports probabilities for each entry, and gives a best-guess (&lt;code&gt;likely_gender&lt;/code&gt; and &lt;code&gt;likely_race&lt;/code&gt;) given those probabilities.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
match_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
likely_race
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_american_indian
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_asian
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_black
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_hispanic
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_white
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_2races
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Steve
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
steve
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0721
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0221
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0483
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8540
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0010
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Eliezer
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
eliezer
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hector
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
hector
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
hispanic
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0135
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0045
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9270
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0550
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Ron
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ron
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0469
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0402
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0235
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8844
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0017
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
James
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
james
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0147
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0328
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9402
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0012
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Desiree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
desiree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0334
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1246
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1155
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7143
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0091
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kevin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
kevin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0324
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0284
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0082
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9296
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rick
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rick
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0284
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0073
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0277
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9314
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0022
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Christopher
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
christopher
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0140
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0200
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0179
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9454
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0014
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Karl
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
karl
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0007
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0260
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0281
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9374
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0007
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
match_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
likely_gender
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_female
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
probability_male
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Michael
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
michael
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0049518
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9950482
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berkley
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
berkley
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6417722
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3582278
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kelly
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
kelly
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8523312
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1476688
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Donald
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
donald
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0039238
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9960762
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Alfonzo
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
alfonzo
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Joseph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
joseph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0040515
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9959485
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scott
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
scott
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0033662
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9966338
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Christopher
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
christopher
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0046306
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9953694
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dennis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
dennis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0042935
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9957065
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Donald
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
donald
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0039238
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9960762
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
So now let’s quickly add the best-guess from the &lt;code&gt;predictrace&lt;/code&gt; package back to our original data, and quickly get a feel for the overall distribution of gender and race.
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-7&#34;&gt;Table 1: &lt;/span&gt;Summary Statistics
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
N
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Percent
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
DeptType
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16900
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… Municipal Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11697
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
69.2%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… Campus Law Enforcement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2038
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
12.1%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… County Sheriffs
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3165
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
18.7%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Population
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16900
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… &amp;lt;25,000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
13614
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
80.6%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… 25k-50k
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1562
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9.2%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… 50k-100k
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
868
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.1%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… 100k-1M
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
797
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.7%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… 1M-10M
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
gender
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16619
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… male
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15583
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
93.8%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… female
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1036
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.2%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16175
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… white
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
15844
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
98%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.4%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… hispanic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
234
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1.4%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… hispanic, white
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.2%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… asian, white
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0%
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;Let’s breakdown race and gender estimates by population of the area served by the agency. Because of the very low counts in Hispanic/White, and Asian/White, I’m going to collapse those into Hispanic and Asian categories respectively. As population data for very small areas (&amp;lt;1000 pop.) can be spotty in the NDLEA, we lose some observations.&lt;/p&gt;
&lt;div id=&#34;phheblmehe&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#phheblmehe .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#phheblmehe .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#phheblmehe .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#phheblmehe .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#phheblmehe .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#phheblmehe .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#phheblmehe .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#phheblmehe .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#phheblmehe .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#phheblmehe .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#phheblmehe .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#phheblmehe .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#phheblmehe .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#phheblmehe .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#phheblmehe .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#phheblmehe .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#phheblmehe .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#phheblmehe .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#phheblmehe .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#phheblmehe .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#phheblmehe .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#phheblmehe .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#phheblmehe .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#phheblmehe .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#phheblmehe .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#phheblmehe .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#phheblmehe .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#phheblmehe .gt_left {
  text-align: left;
}

#phheblmehe .gt_center {
  text-align: center;
}

#phheblmehe .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#phheblmehe .gt_font_normal {
  font-weight: normal;
}

#phheblmehe .gt_font_bold {
  font-weight: bold;
}

#phheblmehe .gt_font_italic {
  font-style: italic;
}

#phheblmehe .gt_super {
  font-size: 65%;
}

#phheblmehe .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  &lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-9&#34;&gt;Table 2: &lt;/span&gt;&lt;strong&gt;Race and Gender of Chief Administrator, by Population Served&lt;/strong&gt;&lt;/caption&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Variable&lt;/strong&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Overall&lt;/strong&gt;, N = 16,900&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;&amp;lt;25,000&lt;/strong&gt;, N = 13,614&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;25k-50k&lt;/strong&gt;, N = 1,562&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;50k-100k&lt;/strong&gt;, N = 868&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;100k-1M&lt;/strong&gt;, N = 797&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;1M-10M&lt;/strong&gt;, N = 59&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;font-weight: bold;&#34;&gt;race&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;White&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15,844 (97.95%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;12,796 (98.13%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,483 (97.95%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;793 (97.42%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;720 (95.87%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;52 (92.86%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Black&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;67 (0.41%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;50 (0.38%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;6 (0.40%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;6 (0.74%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;4 (0.53%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1 (1.79%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Hispanic&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;236 (1.46%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;175 (1.34%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;23 (1.52%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;14 (1.72%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;21 (2.80%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;3 (5.36%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Asian&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;28 (0.17%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;19 (0.15%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;2 (0.13%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1 (0.12%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;6 (0.80%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0 (0.00%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Unknown&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;725&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;574&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;48&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;54&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;46&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;3&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;font-weight: bold;&#34;&gt;gender&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;male&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15,583 (93.77%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;12,569 (93.85%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,456 (94.12%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;791 (93.94%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;718 (92.17%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;49 (83.05%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;female&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,036 (6.23%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;823 (6.15%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;91 (5.88%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;51 (6.06%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;61 (7.83%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;10 (16.95%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Unknown&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;281&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;222&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;26&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;18&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  &lt;tfoot&gt;
    &lt;tr class=&#34;gt_footnotes&#34;&gt;
      &lt;td colspan=&#34;7&#34;&gt;
        &lt;p class=&#34;gt_footnote&#34;&gt;
          &lt;sup class=&#34;gt_footnote_marks&#34;&gt;
            &lt;em&gt;1&lt;/em&gt;
          &lt;/sup&gt;
           
          n (%)
          &lt;br /&gt;
        &lt;/p&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Perhaps unsurprisingly, law enforcement agencies are predominantly led by males. However, there may be progress over the decade or so. Compared to the LEMAS 2013 data, which estimated just 2.7% of agencies were led by women, my analysis estimates that overall 6.2% of agencies are led by women. The proportion of women-led agencies tends to be stable around 6% until we get to the larger population centers, and in the largest (between 1M and 10M pop.), 17% of the agencies are led by women. This is much larger than the 8.5% suggested by the 2016 LEMAS, though the largest category there is 250,000+ population.&lt;/p&gt;
&lt;p&gt;In terms of racial characteristics, this analysis suggests that, overall, 98% of agencies are led by White chief executives. This percentage is negatively correlated with population. In other words, the percentage of White chief executives tends to decrease as the size of population served increases. Even at the top-end of population size, however, these positions are heavily skewed, as seen in the largest (1M to 10M) areas, where 93% of chief executives are estimated to be White.&lt;/p&gt;
&lt;p&gt;Let’s see if the proportions hold across agency types as well.&lt;/p&gt;
&lt;div id=&#34;iixvrpylhv&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#iixvrpylhv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#iixvrpylhv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iixvrpylhv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#iixvrpylhv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#iixvrpylhv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iixvrpylhv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iixvrpylhv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#iixvrpylhv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#iixvrpylhv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#iixvrpylhv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#iixvrpylhv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#iixvrpylhv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#iixvrpylhv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#iixvrpylhv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#iixvrpylhv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#iixvrpylhv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#iixvrpylhv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#iixvrpylhv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iixvrpylhv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#iixvrpylhv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iixvrpylhv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#iixvrpylhv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#iixvrpylhv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iixvrpylhv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iixvrpylhv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#iixvrpylhv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iixvrpylhv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#iixvrpylhv .gt_left {
  text-align: left;
}

#iixvrpylhv .gt_center {
  text-align: center;
}

#iixvrpylhv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#iixvrpylhv .gt_font_normal {
  font-weight: normal;
}

#iixvrpylhv .gt_font_bold {
  font-weight: bold;
}

#iixvrpylhv .gt_font_italic {
  font-style: italic;
}

#iixvrpylhv .gt_super {
  font-size: 65%;
}

#iixvrpylhv .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  &lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-10&#34;&gt;Table 3: &lt;/span&gt;&lt;strong&gt;Race and Gender of Chief Administrator, by Department Type&lt;/strong&gt;&lt;/caption&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Variable&lt;/strong&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Overall&lt;/strong&gt;, N = 16,900&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Municipal Law Enforcement&lt;/strong&gt;, N = 11,697&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;Campus Law Enforcement&lt;/strong&gt;, N = 2,038&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;strong&gt;County Sheriffs&lt;/strong&gt;, N = 3,165&lt;sup class=&#34;gt_footnote_marks&#34;&gt;1&lt;/sup&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;font-weight: bold;&#34;&gt;race&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;White&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15,844 (97.95%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;11,035 (98.12%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,866 (96.73%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;2,943 (98.10%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Black&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;67 (0.41%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;40 (0.36%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15 (0.78%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;12 (0.40%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Hispanic&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;236 (1.46%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;155 (1.38%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;45 (2.33%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;36 (1.20%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Asian&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;28 (0.17%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;16 (0.14%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;3 (0.16%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;9 (0.30%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Unknown&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;725&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;451&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;109&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;165&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;font-weight: bold;&#34;&gt;gender&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;male&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;15,583 (93.77%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;10,910 (94.56%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,729 (86.71%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;2,944 (95.37%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;female&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;1,036 (6.23%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;628 (5.44%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;265 (13.29%)&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;143 (4.63%)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left&#34; style=&#34;text-align: left; text-indent: 10px;&#34;&gt;Unknown&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;281&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;159&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;44&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;78&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  &lt;tfoot&gt;
    &lt;tr class=&#34;gt_footnotes&#34;&gt;
      &lt;td colspan=&#34;5&#34;&gt;
        &lt;p class=&#34;gt_footnote&#34;&gt;
          &lt;sup class=&#34;gt_footnote_marks&#34;&gt;
            &lt;em&gt;1&lt;/em&gt;
          &lt;/sup&gt;
           
          n (%)
          &lt;br /&gt;
        &lt;/p&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, based on these results, agency type does not seem to be correlated with higher percentages of non-white chief executives. However, campus law enforcement agencies are much more likely than other agency types to be led by women - over 13% compared to the average of 6.3% overall.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There is a lot of investigation needed before relying on these estimates, as they are even more &lt;a href=&#34;https://www.washingtonpost.com/nation/2020/06/04/urban-areas-police-are-consistently-much-whiter-than-people-they-serve/&#34;&gt;overwhelmingly White than previous reporting would suggest&lt;/a&gt;. Recall that the 2016 LEMAS estimated that among local agency chiefs, 89.6% were White, 4% Black, 3.1% Hispanic, and 2.4% other race. The differences here suggest more analysis is needed, but several obvious options present themselves. It may be there are substantial gaps between the sampling in the LEMAS versus a population-level estimate. Alternatively, the probabilities themselves are skewing towards White likelihoods. The inclusion of more than just local agencies in this analysis also deserves some thought, as there may be agency characteristics that lead to higher proportions of non-Whites to be selected for the top job.&lt;/p&gt;
&lt;p&gt;Some of the gaps are too large to comfortably chalk up to sampling or research design. The 2016 LEMAS estimated that in agencies serving over 250,000 people, just 65% of chiefs were White, while the current analysis would suggest this number is between 92-96%. That large of a gap is a strong suggestion that the inference of race for this population is questionable. On the other hand, the gender inferences seem much more stable across this analysis and previous ones.&lt;/p&gt;
&lt;p&gt;As always, lots of warnings here about how seriously we should take these estimates. They are, after all, based on probabilistic inferences about race and gender given only a first name. There are lots of weaknesses to consider in that approach. On the other hand, this gives a much broader look at nearly the entire population of US law enforcement agencies in their respective categories (municipal, sheriff’s, campus, and state law enforcement).&lt;/p&gt;
&lt;p&gt;Many thanks to Jacob Kaplan, who developed the &lt;code&gt;predictrace&lt;/code&gt; package for R, as this quick analysis would not be possible without his hard work.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using ggplot2 to visualize the frequency of your name!</title>
      <link>https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;how-popular-is-your-name&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How popular is your name?&lt;/h1&gt;
&lt;p&gt;I really liked this simple &lt;code&gt;ggplot2&lt;/code&gt; exercise from &lt;a href=&#34;https://twitter.com/JennaEagleson&#34;&gt;Jenna Eagleson&lt;/a&gt; that I stumbled across today. I’m going to reproduce it here, and I think it’s a useful exercise for students who are still learning the &lt;code&gt;tidyverse&lt;/code&gt; and &lt;code&gt;ggplot2&lt;/code&gt; packages to play around with. I know &lt;em&gt;I&lt;/em&gt; get bored with diamonds, and even &lt;code&gt;palmerspenguins&lt;/code&gt;, so it’s good to throw something else into the mix to keep the learners’ minds engaged.&lt;/p&gt;
&lt;div id=&#34;first-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First Steps&lt;/h2&gt;
&lt;p&gt;We’ll be using just two packages today - so make sure you have both &lt;code&gt;tidyverse&lt;/code&gt; and the &lt;code&gt;babynames&lt;/code&gt; packages loaded up (and installed if this is the first time you’ve encountered them).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(babynames)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might not be familiar with the &lt;code&gt;babynames&lt;/code&gt; package, but it contains a very large data frame containing 1,924,665 entries of all names used at least five times from 1880 thru 2017. Here’s how Jenna describes it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The &lt;code&gt;babynames&lt;/code&gt; package has a data frame provided by the Social Security Administration with: year, sex, name, n (number of instances), and prop (number of instances of given name and gender in that year divided by total applicants). Unfortunately, this data only has binary male/female as sex options. This data set includes every name with at least 5 instances!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;initial-plotting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initial Plotting&lt;/h2&gt;
&lt;p&gt;Our most basic plot takes all the names and plots them over time. Keep in mind that the dataset we’re working with is very large, so this plot might take a while to generate!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;babynames %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = year, y = n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/index_files/figure-html/remedy002-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;but-what-about-your-name&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But What About &lt;em&gt;Your&lt;/em&gt; Name?&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;babynames&lt;/code&gt; package lets us tease out specific names. For now, let’s assign your name and sex to some variables that we can then plug into the plot. I’ll use my info here, but replace with whatever combination of name and sex you are interested in!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;myname &amp;lt;- &amp;quot;Ian&amp;quot;
mysex &amp;lt;- &amp;quot;M&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s create a plot using those parameters to see how common the name has been over time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;babynames %&amp;gt;%
  filter(name == myname, sex == mysex) %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = year, y = n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/index_files/figure-html/remedy004-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There you go! I was born in 1978, so it looks like I got in on the name before it was too cool :)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further Steps&lt;/h2&gt;
&lt;p&gt;But what if I want to see the distribution of my name’s popularity plotted against all other names? Good question, and here’s one way to go about it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mynameis &amp;lt;- &amp;quot;Ian&amp;quot;
mysexis &amp;lt;- &amp;quot;M&amp;quot;

myname &amp;lt;- babynames %&amp;gt;%
  filter(name == mynameis, sex == mysexis)

mynameminyear &amp;lt;- min(myname$year)-5
maxyear &amp;lt;- max(babynames$year)

babynames %&amp;gt;%
  filter(year &amp;gt; mynameminyear) %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = year, y = prop), alpha = 0.2, color = &amp;quot;gray&amp;quot;) +
    geom_point(data = myname, mapping = aes(x = year, y = prop), alpha = 0.8, color = &amp;quot;#013175&amp;quot;) +
# the below is just formatting, not required!  
theme_minimal() +
 theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        axis.title = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  ggtitle(paste(&amp;quot;Popularity of the name &amp;quot;, mynameis, &amp;quot; from &amp;quot;, mynameminyear, &amp;quot; to &amp;quot;, maxyear))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/index_files/figure-html/remedy005-1.png&#34; width=&#34;672&#34; /&gt;
Cool!&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-multiple-names&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting Multiple Names&lt;/h2&gt;
&lt;p&gt;Maybe you want to compare names with your siblings or your children - easily done. In this example we’ll be comparing three names, but the example could be expanded to however many you want!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name_one &amp;lt;- &amp;quot;Ian&amp;quot;
sex_one &amp;lt;- &amp;quot;M&amp;quot;

name_two &amp;lt;- &amp;quot;Annette&amp;quot;
sex_two &amp;lt;- &amp;quot;F&amp;quot;

name_three &amp;lt;- &amp;quot;Nancy&amp;quot;
sex_three &amp;lt;- &amp;quot;F&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the names set, now we can plot. You might start to see patterns to what we’ve been doing before. That’s good - one of the advantages of &lt;code&gt;ggplot2&lt;/code&gt; is that it brings a “grammar of graphics” to R, meaning we should be able to take separate pieces from different places and put them into new contexts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;firstname &amp;lt;- babynames %&amp;gt;%
  filter(name == name_one, sex == sex_one)

secondname &amp;lt;- babynames %&amp;gt;%
  filter(name == name_two, sex == sex_two)

thirdname &amp;lt;- babynames %&amp;gt;%
  filter(name == name_three, sex == sex_three)

legendcolors &amp;lt;- c(&amp;quot;name_one&amp;quot; = &amp;quot;#219EBC&amp;quot;, &amp;quot;name_two&amp;quot; = &amp;quot;#FB8500&amp;quot;, &amp;quot;name_three&amp;quot; = &amp;quot;#023047&amp;quot;)


babynames %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = year, y = prop), alpha = 0.1, color = &amp;quot;gray&amp;quot;) +
  geom_point(data = firstname, mapping = aes(x = year, y = prop, color = &amp;quot;name_one&amp;quot;), alpha = 0.8) +
  geom_point(data = secondname, mapping = aes(x = year, y = prop, color = &amp;quot;name_two&amp;quot;), alpha = 0.8) +
  geom_point(data = thirdname, mapping = aes(x = year, y = prop, color = &amp;quot;name_three&amp;quot;), alpha = 0.8) +
 
# The below is formatting and not required!
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        axis.title = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  ggtitle(paste(&amp;quot;Who has the most popular name?&amp;quot;)) +
  scale_color_manual(name = &amp;quot;Name&amp;quot;, values = legendcolors, labels = c(&amp;quot;Ian&amp;quot;, &amp;quot;Nancy&amp;quot;, &amp;quot;Annette&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/using-ggplot2-to-visualize-the-frequency-of-your-name/index_files/figure-html/remedy007-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Week 10 Solutions</title>
      <link>https://ianadamsresearch.com/courses/pubpl-6002/week-10/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/courses/pubpl-6002/week-10/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;div id=&#34;so-you-want-to-be-a-data-scientist&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;So you want to be a data scientist&lt;/h1&gt;
&lt;p&gt;This week can feel like a bit of a doozy, as the difficulty really ramps up. Something to remember - most data scientists spend most of their time cleaning, transforming, and &lt;em&gt;tidying&lt;/em&gt; their data. That’s what these chapters and questions are all about. So I want to make sure you have the correct answers, but more importantly, I want you to know &lt;strong&gt;you are not alone&lt;/strong&gt;, this stuff is hard! I’ve put the quote in front of you before, but this little bit of wisdom from Hadley Wickham, lead author of our class textbook, is important during times like we’re having right now:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“There is no way of going from knowing nothing about a subject to knowing something about a subject without going through a period of much frustration and suckiness. &lt;strong&gt;Push through. You’ll suck less&lt;/strong&gt;.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, onto the answers!&lt;/p&gt;
&lt;div id=&#34;exercise-5.2.4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.2.4&lt;/h2&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Why is &lt;code&gt;NA ^ 0&lt;/code&gt; not missing? Why is &lt;code&gt;NA | TRUE&lt;/code&gt; not missing?
Why is &lt;code&gt;FALSE &amp;amp; NA&lt;/code&gt; not missing? Can you figure out the general rule?
(&lt;code&gt;NA * 0&lt;/code&gt; is a tricky counterexample!)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA ^ 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;NA ^ 0 == 1&lt;/code&gt; since for all numeric values &lt;span class=&#34;math inline&#34;&gt;\(x ^ 0 = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA | TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;NA | TRUE&lt;/code&gt; is &lt;code&gt;TRUE&lt;/code&gt; because anything &lt;strong&gt;or&lt;/strong&gt; &lt;code&gt;TRUE&lt;/code&gt; is &lt;code&gt;TRUE&lt;/code&gt;.
If the missing value were &lt;code&gt;TRUE&lt;/code&gt;, then &lt;code&gt;TRUE | TRUE == TRUE&lt;/code&gt;,
and if the missing value was &lt;code&gt;FALSE&lt;/code&gt;, then &lt;code&gt;FALSE | TRUE == TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA &amp;amp; FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The value of &lt;code&gt;NA &amp;amp; FALSE&lt;/code&gt; is &lt;code&gt;FALSE&lt;/code&gt; because anything &lt;strong&gt;and&lt;/strong&gt; &lt;code&gt;FALSE&lt;/code&gt; is always &lt;code&gt;FALSE&lt;/code&gt;.
If the missing value were &lt;code&gt;TRUE&lt;/code&gt;, then &lt;code&gt;TRUE &amp;amp; FALSE == FALSE&lt;/code&gt;,
and if the missing value was &lt;code&gt;FALSE&lt;/code&gt;, then &lt;code&gt;FALSE &amp;amp; FALSE == FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA | FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;NA | FALSE&lt;/code&gt;, the value is unknown since &lt;code&gt;TRUE | FALSE == TRUE&lt;/code&gt;, but &lt;code&gt;FALSE | FALSE == FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA &amp;amp; TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;NA &amp;amp; TRUE&lt;/code&gt;, the value is unknown since &lt;code&gt;FALSE &amp;amp; TRUE== FALSE&lt;/code&gt;, but &lt;code&gt;TRUE &amp;amp; TRUE == TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NA * 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(x * 0 = 0\)&lt;/span&gt; for all finite numbers we might expect &lt;code&gt;NA * 0 == 0&lt;/code&gt;, but that’s not the case.
The reason that &lt;code&gt;NA * 0 != 0&lt;/code&gt; is that &lt;span class=&#34;math inline&#34;&gt;\(0 \times \infty\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0 \times -\infty\)&lt;/span&gt; are undefined.
R represents undefined results as &lt;code&gt;NaN&lt;/code&gt;, which is an abbreviation of “&lt;a href=&#34;https://en.wikipedia.org/wiki/NaN&#34;&gt;not a number&lt;/a&gt;”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Inf * 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NaN&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;-Inf * 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NaN&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-5.3.1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.3.1&lt;/h2&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;How could you use &lt;code&gt;arrange()&lt;/code&gt; to sort all missing values to the start? (Hint: use &lt;code&gt;is.na()&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The &lt;code&gt;arrange()&lt;/code&gt; function puts &lt;code&gt;NA&lt;/code&gt; values last.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(flights, dep_time) %&amp;gt;%
  tail()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 19
##    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
## 1  2013     9    30       NA           1842        NA       NA           2019
## 2  2013     9    30       NA           1455        NA       NA           1634
## 3  2013     9    30       NA           2200        NA       NA           2312
## 4  2013     9    30       NA           1210        NA       NA           1330
## 5  2013     9    30       NA           1159        NA       NA           1344
## 6  2013     9    30       NA            840        NA       NA           1020
## # ... with 11 more variables: arr_delay &amp;lt;dbl&amp;gt;, carrier &amp;lt;chr&amp;gt;, flight &amp;lt;int&amp;gt;,
## #   tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;, air_time &amp;lt;dbl&amp;gt;, distance &amp;lt;dbl&amp;gt;,
## #   hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using &lt;code&gt;desc()&lt;/code&gt; does not change that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(flights, desc(dep_time))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013    10    30     2400           2359         1      327            337
##  2  2013    11    27     2400           2359         1      515            445
##  3  2013    12     5     2400           2359         1      427            440
##  4  2013    12     9     2400           2359         1      432            440
##  5  2013    12     9     2400           2250        70       59           2356
##  6  2013    12    13     2400           2359         1      432            440
##  7  2013    12    19     2400           2359         1      434            440
##  8  2013    12    29     2400           1700       420      302           2025
##  9  2013     2     7     2400           2359         1      432            436
## 10  2013     2     7     2400           2359         1      443            444
## # ... with 336,766 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;,
## #   carrier &amp;lt;chr&amp;gt;, flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;,
## #   air_time &amp;lt;dbl&amp;gt;, distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To put &lt;code&gt;NA&lt;/code&gt; values first, we can add an indicator of whether the column has a missing value.
Then we sort by the missing indicator column and the column of interest.
For example, to sort the data frame by departure time (&lt;code&gt;dep_time&lt;/code&gt;) in ascending order but &lt;code&gt;NA&lt;/code&gt; values first, run the following.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(flights, desc(is.na(dep_time)), dep_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013     1     1       NA           1630        NA       NA           1815
##  2  2013     1     1       NA           1935        NA       NA           2240
##  3  2013     1     1       NA           1500        NA       NA           1825
##  4  2013     1     1       NA            600        NA       NA            901
##  5  2013     1     2       NA           1540        NA       NA           1747
##  6  2013     1     2       NA           1620        NA       NA           1746
##  7  2013     1     2       NA           1355        NA       NA           1459
##  8  2013     1     2       NA           1420        NA       NA           1644
##  9  2013     1     2       NA           1321        NA       NA           1536
## 10  2013     1     2       NA           1545        NA       NA           1910
## # ... with 336,766 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;,
## #   carrier &amp;lt;chr&amp;gt;, flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;,
## #   air_time &amp;lt;dbl&amp;gt;, distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;flights&lt;/code&gt; will first be sorted by &lt;code&gt;desc(is.na(dep_time))&lt;/code&gt;.
Since &lt;code&gt;desc(is.na(dep_time))&lt;/code&gt; is either &lt;code&gt;TRUE&lt;/code&gt; when &lt;code&gt;dep_time&lt;/code&gt; is missing, or &lt;code&gt;FALSE&lt;/code&gt;, when it is not, the rows with missing values of &lt;code&gt;dep_time&lt;/code&gt; will come first, since &lt;code&gt;TRUE &amp;gt; FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-5.4.1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.4.1&lt;/h2&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Brainstorm as many ways as possible to select &lt;code&gt;dep_time&lt;/code&gt;, &lt;code&gt;dep_delay&lt;/code&gt;, &lt;code&gt;arr_time&lt;/code&gt;, and &lt;code&gt;arr_delay&lt;/code&gt; from flights.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;These are a few ways to select columns.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Specify columns names as unquoted variable names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, dep_time, dep_delay, arr_time, arr_delay)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify column names as strings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, &amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the column numbers of the variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, 4, 6, 7, 9)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works, but is not good practice for two reasons.
First, the column location of variables may change, resulting in code that
may continue to run without error, but produce the wrong answer.
Second code is obfuscated, since it is not clear from the code which
variables are being selected. What variable does column 6 correspond to?
I just wrote the code, and I’ve already forgotten.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the names of the variables with character vector and &lt;code&gt;any_of()&lt;/code&gt; or &lt;code&gt;all_of()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, all_of(c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, any_of(c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful because the names of the variables can be stored in a
variable and passed to &lt;code&gt;all_of()&lt;/code&gt; or &lt;code&gt;any_of()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variables &amp;lt;- c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)
select(flights, all_of(variables))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two functions replace the deprecated function &lt;code&gt;one_of()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Selecting the variables by matching the start of their names using &lt;code&gt;starts_with()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, starts_with(&amp;quot;dep_&amp;quot;), starts_with(&amp;quot;arr_&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Selecting the variables using regular expressions with &lt;code&gt;matches()&lt;/code&gt;.
Regular expressions provide a flexible way to match string patterns
and are discussed in the &lt;a href=&#34;https://r4ds.had.co.nz/strings.html&#34;&gt;Strings&lt;/a&gt; chapter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, matches(&amp;quot;^(dep|arr)_(time|delay)$&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the names of the variables with a character vector and use the bang-bang operator (&lt;code&gt;!!&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variables &amp;lt;- c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)
select(flights, !!variables)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This and the following answers use the features of &lt;strong&gt;tidy evaluation&lt;/strong&gt; not covered in R4DS but covered in the &lt;a href=&#34;https://dplyr.tidyverse.org/articles/programming.html&#34;&gt;Programming with dplyr&lt;/a&gt; vignette.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the names of the variables in a character or list vector and use the bang-bang-bang operator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variables &amp;lt;- c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;)
select(flights, !!!variables)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the unquoted names of the variables in a list using &lt;code&gt;syms()&lt;/code&gt; and use the bang-bang-bang operator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variables &amp;lt;- syms(c(&amp;quot;dep_time&amp;quot;, &amp;quot;dep_delay&amp;quot;, &amp;quot;arr_time&amp;quot;, &amp;quot;arr_delay&amp;quot;))
select(flights, !!!variables)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    dep_time dep_delay arr_time arr_delay
##       &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517         2      830        11
##  2      533         4      850        20
##  3      542         2      923        33
##  4      544        -1     1004       -18
##  5      554        -6      812       -25
##  6      554        -4      740        12
##  7      555        -5      913        19
##  8      557        -3      709       -14
##  9      557        -3      838        -8
## 10      558        -2      753         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some things that &lt;strong&gt;don’t&lt;/strong&gt; work are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Matching the ends of their names using &lt;code&gt;ends_with()&lt;/code&gt; since this will incorrectly
include other variables. For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, ends_with(&amp;quot;arr_time&amp;quot;), ends_with(&amp;quot;dep_time&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 4
##    arr_time sched_arr_time dep_time sched_dep_time
##       &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1      830            819      517            515
##  2      850            830      533            529
##  3      923            850      542            540
##  4     1004           1022      544            545
##  5      812            837      554            600
##  6      740            728      554            558
##  7      913            854      555            600
##  8      709            723      557            600
##  9      838            846      557            600
## 10      753            745      558            600
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Matching the names using &lt;code&gt;contains()&lt;/code&gt; since there is not a pattern that can
include all these variables without incorrectly including others.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(flights, contains(&amp;quot;_time&amp;quot;), contains(&amp;quot;arr_&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 6
##    dep_time sched_dep_time arr_time sched_arr_time air_time arr_delay
##       &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1      517            515      830            819      227        11
##  2      533            529      850            830      227        20
##  3      542            540      923            850      160        33
##  4      544            545     1004           1022      183       -18
##  5      554            600      812            837      116       -25
##  6      554            558      740            728      150        12
##  7      555            600      913            854      158        19
##  8      557            600      709            723       53       -14
##  9      557            600      838            846      140        -8
## 10      558            600      753            745      138         8
## # ... with 336,766 more rows&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-5.5.2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.5.2&lt;/h2&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Compare &lt;code&gt;air_time&lt;/code&gt; with &lt;code&gt;arr_time - dep_time&lt;/code&gt;.
What do you expect to see?
What do you see?
What do you need to do to fix it?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;I expect that &lt;code&gt;air_time&lt;/code&gt; is the difference between the arrival (&lt;code&gt;arr_time&lt;/code&gt;) and departure times (&lt;code&gt;dep_time&lt;/code&gt;).
In other words, &lt;code&gt;air_time = arr_time - dep_time&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To check that this relationship, I’ll first need to convert the times to a form more amenable to arithmetic operations using the same calculations as the &lt;a href=&#34;#exercise-5.5.1&#34;&gt;previous exercise&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights_airtime &amp;lt;-
  mutate(flights,
    dep_time = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,
    arr_time = (arr_time %/% 100 * 60 + arr_time %% 100) %% 1440,
    air_time_diff = air_time - arr_time + dep_time
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, does &lt;code&gt;air_time = arr_time - dep_time&lt;/code&gt;?
If so, there should be no flights with non-zero values of &lt;code&gt;air_time_diff&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(filter(flights_airtime, air_time_diff != 0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 327150&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out that there are many flights for which &lt;code&gt;air_time != arr_time - dep_time&lt;/code&gt;.
Other than data errors, I can think of two reasons why &lt;code&gt;air_time&lt;/code&gt; would not equal &lt;code&gt;arr_time - dep_time&lt;/code&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The flight passes midnight, so &lt;code&gt;arr_time &amp;lt; dep_time&lt;/code&gt;.
In these cases, the difference in airtime should be by 24 hours (1,440 minutes).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The flight crosses time zones, and the total air time will be off by hours (multiples of 60).
All flights in &lt;code&gt;flights&lt;/code&gt; departed from New York City and are domestic flights in the US.
This means that flights will all be to the same or more westerly time zones.
Given the time-zones in the US, the differences due to time-zone should be 60 minutes (Central)
120 minutes (Mountain), 180 minutes (Pacific), 240 minutes (Alaska), or 300 minutes (Hawaii).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both of these explanations have clear patterns that I would expect to see if they
were true.
In particular, in both cases, since time-zones and crossing midnight only affects the hour part of the time, all values of &lt;code&gt;air_time_diff&lt;/code&gt; should be divisible by 60.
I’ll visually check this hypothesis by plotting the distribution of &lt;code&gt;air_time_diff&lt;/code&gt;.
If those two explanations are correct, distribution of &lt;code&gt;air_time_diff&lt;/code&gt; should comprise only spikes at multiples of 60.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights_airtime, aes(x = air_time_diff)) +
  geom_histogram(binwidth = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;
This is not the case.
While, the distribution of &lt;code&gt;air_time_diff&lt;/code&gt; has modes at multiples of 60 as hypothesized,
it shows that there are many flights in which the difference between air time and local arrival and departure times is not divisible by 60.&lt;/p&gt;
&lt;p&gt;Let’s also look at flights with Los Angeles as a destination.
The discrepancy should be 180 minutes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(filter(flights_airtime, dest == &amp;quot;LAX&amp;quot;), aes(x = air_time_diff)) +
  geom_histogram(binwidth = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 148 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To fix these time-zone issues, I would want to convert all the times to a date-time to handle overnight flights, and from local time to a common time zone, most likely &lt;a href=&#34;https://en.wikipedia.org/wiki/Coordinated_Universal_Time&#34;&gt;UTC&lt;/a&gt;, to handle flights crossing time-zones.
The &lt;code&gt;tzone&lt;/code&gt; column of &lt;code&gt;nycflights13::airports&lt;/code&gt; gives the time-zone of each airport.
See the &lt;a href=&#34;https://r4ds.had.co.nz/dates-and-times.html&#34;&gt;“Dates and Times”&lt;/a&gt; for an introduction on working with date and time data.&lt;/p&gt;
&lt;p&gt;But that still leaves the other differences unexplained.
So what else might be going on?
There seem to be too many problems for this to be data entry problems, so I’m probably missing something.
So, I’ll reread the documentation to make sure that I understand the definitions of &lt;code&gt;arr_time&lt;/code&gt;, &lt;code&gt;dep_time&lt;/code&gt;, and
&lt;code&gt;air_time&lt;/code&gt;.
The documentation contains a link to the source of the &lt;code&gt;flights&lt;/code&gt; data, &lt;a href=&#34;https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&#34; class=&#34;uri&#34;&gt;https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&lt;/a&gt;.
This documentation shows that the &lt;code&gt;flights&lt;/code&gt; data does not contain the variables &lt;code&gt;TaxiIn&lt;/code&gt;, &lt;code&gt;TaxiOff&lt;/code&gt;, &lt;code&gt;WheelsIn&lt;/code&gt;, and &lt;code&gt;WheelsOff&lt;/code&gt;.
It appears that the &lt;code&gt;air_time&lt;/code&gt; variable refers to flight time, which is defined as the time between wheels-off (take-off) and wheels-in (landing).
But the flight time does not include time spent on the runway taxiing to and from gates.
With this new understanding of the data, I now know that the relationship between &lt;code&gt;air_time&lt;/code&gt;, &lt;code&gt;arr_time&lt;/code&gt;, and &lt;code&gt;dep_time&lt;/code&gt; is &lt;code&gt;air_time &amp;lt;= arr_time - dep_time&lt;/code&gt;, supposing that the time zones of &lt;code&gt;arr_time&lt;/code&gt; and &lt;code&gt;dep_time&lt;/code&gt; are in the same time zone.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-5.6.7&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.6.7&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights.
Consider the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.&lt;/li&gt;
&lt;li&gt;A flight is always 10 minutes late.&lt;/li&gt;
&lt;li&gt;A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.&lt;/li&gt;
&lt;li&gt;99% of the time a flight is on time. 1% of the time it’s 2 hours late.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which is more important: arrival delay or departure delay?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;

&lt;p&gt;What this question gets at is a fundamental question of data analysis: the cost function.
As analysts, the reason we are interested in flight delay because it is costly to passengers.
But it is worth thinking carefully about how it is costly and use that information in ranking and measuring these scenarios.&lt;/p&gt;
&lt;p&gt;In many scenarios, arrival delay is more important.
In most cases, being arriving late is more costly to the passenger since it could disrupt the next stages of their travel, such as connecting flights or scheduled meetings.&lt;br /&gt;
If a departure is delayed without affecting the arrival time, this delay will not have those affects plans nor does it affect the total time spent traveling.
This delay could be beneficial, if less time is spent in the cramped confines of the airplane itself, or a negative, if that delayed time is still spent in the cramped confines of the airplane on the runway.&lt;/p&gt;
&lt;p&gt;Variation in arrival time is worse than consistency.
If a flight is always 30 minutes late and that delay is known, then it is as if the arrival time is that delayed time.
The traveler could easily plan for this.
But higher variation in flight times makes it harder to plan.&lt;/p&gt;
&lt;div id=&#34;section&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.6.7.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Come up with another approach that will give you the same output as &lt;code&gt;not_cancelled %&amp;gt;% count(dest)&lt;/code&gt; and &lt;code&gt;not_cancelled %&amp;gt;% count(tailnum, wt = distance)&lt;/code&gt; (without using &lt;code&gt;count()&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled &amp;lt;- flights %&amp;gt;%
  filter(!is.na(dep_delay), !is.na(arr_delay))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first expression is the following.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;% 
  count(dest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 104 x 2
##    dest      n
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 ABQ     254
##  2 ACK     264
##  3 ALB     418
##  4 ANC       8
##  5 ATL   16837
##  6 AUS    2411
##  7 AVL     261
##  8 BDL     412
##  9 BGR     358
## 10 BHM     269
## # ... with 94 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;count()&lt;/code&gt; function counts the number of instances within each group of variables.
Instead of using the &lt;code&gt;count()&lt;/code&gt; function, we can combine the &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarise()&lt;/code&gt; verbs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;%
  group_by(dest) %&amp;gt;%
  summarise(n = length(dest))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 104 x 2
##    dest      n
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 ABQ     254
##  2 ACK     264
##  3 ALB     418
##  4 ANC       8
##  5 ATL   16837
##  6 AUS    2411
##  7 AVL     261
##  8 BDL     412
##  9 BGR     358
## 10 BHM     269
## # ... with 94 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An alternative method for getting the number of observations in a data frame is the function &lt;code&gt;n()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;%
  group_by(dest) %&amp;gt;%
  summarise(n = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 104 x 2
##    dest      n
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 ABQ     254
##  2 ACK     264
##  3 ALB     418
##  4 ANC       8
##  5 ATL   16837
##  6 AUS    2411
##  7 AVL     261
##  8 BDL     412
##  9 BGR     358
## 10 BHM     269
## # ... with 94 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another alternative to &lt;code&gt;count()&lt;/code&gt; is to use &lt;code&gt;group_by()&lt;/code&gt; followed by &lt;code&gt;tally()&lt;/code&gt;.
In fact, &lt;code&gt;count()&lt;/code&gt; is effectively a short-cut for &lt;code&gt;group_by()&lt;/code&gt; followed by &lt;code&gt;tally()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  tally()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,037 x 2
##    tailnum     n
##    &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt;
##  1 D942DN      4
##  2 N0EGMQ    352
##  3 N10156    145
##  4 N102UW     48
##  5 N103US     46
##  6 N104UW     46
##  7 N10575    269
##  8 N105UW     45
##  9 N107US     41
## 10 N108UW     60
## # ... with 4,027 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second expression also uses the &lt;code&gt;count()&lt;/code&gt; function, but adds a &lt;code&gt;wt&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;% 
  count(tailnum, wt = distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,037 x 2
##    tailnum      n
##    &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 D942DN    3418
##  2 N0EGMQ  239143
##  3 N10156  109664
##  4 N102UW   25722
##  5 N103US   24619
##  6 N104UW   24616
##  7 N10575  139903
##  8 N105UW   23618
##  9 N107US   21677
## 10 N108UW   32070
## # ... with 4,027 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As before, we can replicate &lt;code&gt;count()&lt;/code&gt; by combining the &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarise()&lt;/code&gt; verbs.
But this time instead of using &lt;code&gt;length()&lt;/code&gt;, we will use &lt;code&gt;sum()&lt;/code&gt; with the weighting variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  summarise(n = sum(distance))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,037 x 2
##    tailnum      n
##    &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 D942DN    3418
##  2 N0EGMQ  239143
##  3 N10156  109664
##  4 N102UW   25722
##  5 N103US   24619
##  6 N104UW   24616
##  7 N10575  139903
##  8 N105UW   23618
##  9 N107US   21677
## 10 N108UW   32070
## # ... with 4,027 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like the previous example, we can also use the combination &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;tally()&lt;/code&gt;.
Any arguments to &lt;code&gt;tally()&lt;/code&gt; are summed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;not_cancelled %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  tally(distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,037 x 2
##    tailnum      n
##    &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 D942DN    3418
##  2 N0EGMQ  239143
##  3 N10156  109664
##  4 N102UW   25722
##  5 N103US   24619
##  6 N104UW   24616
##  7 N10575  139903
##  8 N105UW   23618
##  9 N107US   21677
## 10 N108UW   32070
## # ... with 4,027 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.6.7.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Our definition of cancelled flights &lt;code&gt;(is.na(dep_delay) | is.na(arr_delay))&lt;/code&gt; is slightly suboptimal.
Why?
Which is the most important column?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;If a flight never departs, then it won’t arrive.
A flight could also depart and not arrive if it crashes, or if it is redirected and lands in an airport other than its intended destination.
So the most important column is &lt;code&gt;arr_delay&lt;/code&gt;, which indicates the amount of delay in arrival.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(flights, !is.na(dep_delay), is.na(arr_delay)) %&amp;gt;%
  select(dep_time, arr_time, sched_arr_time, dep_delay, arr_delay)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,175 x 5
##    dep_time arr_time sched_arr_time dep_delay arr_delay
##       &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1     1525     1934           1805        -5        NA
##  2     1528     2002           1647        29        NA
##  3     1740     2158           2020        -5        NA
##  4     1807     2251           2103        29        NA
##  5     1939       29           2151        59        NA
##  6     1952     2358           2207        22        NA
##  7     2016       NA           2220        46        NA
##  8      905     1313           1045        43        NA
##  9     1125     1445           1146       120        NA
## 10     1848     2333           2151         8        NA
## # ... with 1,165 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this data &lt;code&gt;dep_time&lt;/code&gt; can be non-missing and &lt;code&gt;arr_delay&lt;/code&gt; missing but &lt;code&gt;arr_time&lt;/code&gt; not missing.
Some further &lt;a href=&#34;https://hyp.is/TsdRpofJEeqzs6-vUOfVBg/jrnold.github.io/r4ds-exercise-solutions/transform.html&#34;&gt;research&lt;/a&gt; found that these rows correspond to diverted flights.
The &lt;a href=&#34;https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&#34;&gt;BTS&lt;/a&gt; database that is the source for the &lt;code&gt;flights&lt;/code&gt; table contains additional information for diverted flights that is not included in the nycflights13 data.
The source contains a column &lt;code&gt;DivArrDelay&lt;/code&gt; with the description:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Difference in minutes between scheduled and actual arrival time for a diverted flight reaching scheduled destination.
The &lt;code&gt;ArrDelay&lt;/code&gt; column remains &lt;code&gt;NULL&lt;/code&gt; for all diverted flights.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.6.7.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Look at the number of cancelled flights per day.
Is there a pattern?
Is the proportion of cancelled flights related to the average delay?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;One pattern in cancelled flights per day is that the number of cancelled flights increases with the total number of flights per day.
The proportion of cancelled flights increases with the average delay of flights.&lt;/p&gt;
&lt;p&gt;To answer these questions, use definition of cancelled used in the
chapter &lt;a href=&#34;https://r4ds.had.co.nz/transform.html#counts&#34;&gt;Section 5.6.3&lt;/a&gt; and the
relationship &lt;code&gt;!(is.na(arr_delay) &amp;amp; is.na(dep_delay))&lt;/code&gt; is equal to
&lt;code&gt;!is.na(arr_delay) | !is.na(dep_delay)&lt;/code&gt; by &lt;a href=&#34;https://en.wikipedia.org/wiki/De_Morgan%27s_laws&#34;&gt;De Morgan’s law&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first part of the question asks for any pattern in the number of cancelled flights per day.
I’ll look at the relationship between the number of cancelled flights per day and the total number of flights in a day.
There should be an increasing relationship for two reasons.
First, if all flights are equally likely to be cancelled, then days with more flights should have a higher number of cancellations.
Second, it is likely that days with more flights would have a higher probability of cancellations because congestion itself can cause delays and any delay would affect more flights, and large delays can lead to cancellations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cancelled_per_day &amp;lt;- 
  flights %&amp;gt;%
  mutate(cancelled = (is.na(arr_delay) | is.na(dep_delay))) %&amp;gt;%
  group_by(year, month, day) %&amp;gt;%
  summarise(
    cancelled_num = sum(cancelled),
    flights_num = n(),
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;year&amp;#39;, &amp;#39;month&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plotting &lt;code&gt;flights_num&lt;/code&gt; against &lt;code&gt;cancelled_num&lt;/code&gt; shows that the number of flights
cancelled increases with the total number of flights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(cancelled_per_day) +
  geom_point(aes(x = flights_num, y = cancelled_num)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The second part of the question asks whether there is a relationship between the proportion of flights cancelled and the average departure delay.
I implied this in my answer to the first part of the question, when I noted that increasing delays could result in increased cancellations.
The question does not specify which delay, so I will show the relationship for both.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cancelled_and_delays &amp;lt;- 
  flights %&amp;gt;%
  mutate(cancelled = (is.na(arr_delay) | is.na(dep_delay))) %&amp;gt;%
  group_by(year, month, day) %&amp;gt;%
  summarise(
    cancelled_prop = mean(cancelled),
    avg_dep_delay = mean(dep_delay, na.rm = TRUE),
    avg_arr_delay = mean(arr_delay, na.rm = TRUE)
  ) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;year&amp;#39;, &amp;#39;month&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is a strong increasing relationship between both average departure delay and&lt;br /&gt;
and average arrival delay and the proportion of cancelled flights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(cancelled_and_delays) +
  geom_point(aes(x = avg_dep_delay, y = cancelled_prop))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(cancelled_and_delays) +
  geom_point(aes(x = avg_arr_delay, y = cancelled_prop))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.6.7.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Which carrier has the worst delays?
Challenge: can you disentangle the effects of bad airports vs. bad carriers?
Why/why not?
(Hint: think about &lt;code&gt;flights %&amp;gt;% group_by(carrier, dest) %&amp;gt;% summarise(n())&lt;/code&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  group_by(carrier) %&amp;gt;%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %&amp;gt;%
  arrange(desc(arr_delay))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 16 x 2
##    carrier arr_delay
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
##  1 F9         21.9  
##  2 FL         20.1  
##  3 EV         15.8  
##  4 YV         15.6  
##  5 OO         11.9  
##  6 MQ         10.8  
##  7 WN          9.65 
##  8 B6          9.46 
##  9 9E          7.38 
## 10 UA          3.56 
## 11 US          2.13 
## 12 VX          1.76 
## 13 DL          1.64 
## 14 AA          0.364
## 15 HA         -6.92 
## 16 AS         -9.93&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What airline corresponds to the &lt;code&gt;&#34;F9&#34;&lt;/code&gt; carrier code?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(airlines, carrier == &amp;quot;F9&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   carrier name                  
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;                 
## 1 F9      Frontier Airlines Inc.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can get part of the way to disentangling the effects of airports versus bad carriers by comparing the average delay of each carrier to the average delay of flights within a route (flights from the same origin to the same destination).
Comparing delays between carriers and within each route disentangles the effect of carriers and airports.
A better analysis would compare the average delay of a carrier’s flights to the average delay of &lt;em&gt;all other&lt;/em&gt; carrier’s flights within a route.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(!is.na(arr_delay)) %&amp;gt;%
  # Total delay by carrier within each origin, dest
  group_by(origin, dest, carrier) %&amp;gt;%
  summarise(
    arr_delay = sum(arr_delay),
    flights = n()
  ) %&amp;gt;%
  # Total delay within each origin dest
  group_by(origin, dest) %&amp;gt;%
  mutate(
    arr_delay_total = sum(arr_delay),
    flights_total = sum(flights)
  ) %&amp;gt;%
  # average delay of each carrier - average delay of other carriers
  ungroup() %&amp;gt;%
  mutate(
    arr_delay_others = (arr_delay_total - arr_delay) /
      (flights_total - flights),
    arr_delay_mean = arr_delay / flights,
    arr_delay_diff = arr_delay_mean - arr_delay_others
  ) %&amp;gt;%
  # remove NaN values (when there is only one carrier)
  filter(is.finite(arr_delay_diff)) %&amp;gt;%
  # average over all airports it flies to
  group_by(carrier) %&amp;gt;%
  summarise(arr_delay_diff = mean(arr_delay_diff)) %&amp;gt;%
  arrange(desc(arr_delay_diff))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;origin&amp;#39;, &amp;#39;dest&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 2
##    carrier arr_delay_diff
##    &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;
##  1 OO              27.3  
##  2 F9              17.3  
##  3 EV              11.0  
##  4 B6               6.41 
##  5 FL               2.57 
##  6 VX              -0.202
##  7 AA              -0.970
##  8 WN              -1.27 
##  9 UA              -1.86 
## 10 MQ              -2.48 
## 11 YV              -2.81 
## 12 9E              -3.54 
## 13 US              -4.14 
## 14 DL             -10.2  
## 15 AS             -15.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are more sophisticated ways to do this analysis, however comparing the delay of flights within each route goes a long ways toward disentangling airport and carrier effects.
To see a more complete example of this analysis, see this FiveThirtyEight &lt;a href=&#34;https://fivethirtyeight.com/features/the-best-and-worst-airlines-airports-and-flights-summer-2015-update/&#34;&gt;piece&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.6.7.6&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;What does the sort argument to &lt;code&gt;count()&lt;/code&gt; do?
When might you use it?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The sort argument to &lt;code&gt;count()&lt;/code&gt; sorts the results in order of &lt;code&gt;n&lt;/code&gt;.
You could use this anytime you would run &lt;code&gt;count()&lt;/code&gt; followed by &lt;code&gt;arrange()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, the following expression counts the number of flights to a destination and sorts the returned data from highest to lowest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  count(dest, sort = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 105 x 2
##    dest      n
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 ORD   17283
##  2 ATL   17215
##  3 LAX   16174
##  4 BOS   15508
##  5 MCO   14082
##  6 CLT   14064
##  7 SFO   13331
##  8 FLL   12055
##  9 MIA   11728
## 10 DCA    9705
## # ... with 95 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-5.7.1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 5.7.1&lt;/h2&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Refer back to the lists of useful mutate and filtering functions.
Describe how each operation changes when you combine it with grouping.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Summary functions (&lt;code&gt;mean()&lt;/code&gt;), offset functions (&lt;code&gt;lead()&lt;/code&gt;, &lt;code&gt;lag()&lt;/code&gt;), ranking functions (&lt;code&gt;min_rank()&lt;/code&gt;, &lt;code&gt;row_number()&lt;/code&gt;), operate within each group when used with &lt;code&gt;group_by()&lt;/code&gt; in
&lt;code&gt;mutate()&lt;/code&gt; or &lt;code&gt;filter()&lt;/code&gt;.
Arithmetic operators (&lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;), logical operators (&lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;), modular arithmetic operators (&lt;code&gt;%%&lt;/code&gt;, &lt;code&gt;%/%&lt;/code&gt;), logarithmic functions (&lt;code&gt;log&lt;/code&gt;) are not affected by &lt;code&gt;group_by&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Summary functions like &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;median()&lt;/code&gt;, &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;std()&lt;/code&gt; and others covered
in the section &lt;a href=&#34;https://r4ds.had.co.nz/transform.html#summarise-funs&#34;&gt;Useful Summary Functions&lt;/a&gt;
calculate their values within each group when used with &lt;code&gt;mutate()&lt;/code&gt; or &lt;code&gt;filter()&lt;/code&gt; and &lt;code&gt;group_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(x_mean = mean(x)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(x_mean_2 = mean(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group x_mean x_mean_2
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     1 a          5        2
## 2     2 a          5        2
## 3     3 a          5        2
## 4     4 b          5        5
## 5     5 b          5        5
## 6     6 b          5        5
## 7     7 c          5        8
## 8     8 c          5        8
## 9     9 c          5        8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arithmetic operators &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;^&lt;/code&gt; are not affected by &lt;code&gt;group_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(y = x + 2) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(z = x + 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group     y     z
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 a         3     3
## 2     2 a         4     4
## 3     3 a         5     5
## 4     4 b         6     6
## 5     5 b         7     7
## 6     6 b         8     8
## 7     7 c         9     9
## 8     8 c        10    10
## 9     9 c        11    11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The modular arithmetic operators &lt;code&gt;%/%&lt;/code&gt; and &lt;code&gt;%%&lt;/code&gt; are not affected by &lt;code&gt;group_by()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(y = x %% 2) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(z = x %% 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group     y     z
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 a         1     1
## 2     2 a         0     0
## 3     3 a         1     1
## 4     4 b         0     0
## 5     5 b         1     1
## 6     6 b         0     0
## 7     7 c         1     1
## 8     8 c         0     0
## 9     9 c         1     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The logarithmic functions &lt;code&gt;log()&lt;/code&gt;, &lt;code&gt;log2()&lt;/code&gt;, and &lt;code&gt;log10()&lt;/code&gt; are not affected by
&lt;code&gt;group_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(y = log(x)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(z = log(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group     y     z
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 a     0     0    
## 2     2 a     0.693 0.693
## 3     3 a     1.10  1.10 
## 4     4 b     1.39  1.39 
## 5     5 b     1.61  1.61 
## 6     6 b     1.79  1.79 
## 7     7 c     1.95  1.95 
## 8     8 c     2.08  2.08 
## 9     9 c     2.20  2.20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The offset functions &lt;code&gt;lead()&lt;/code&gt; and &lt;code&gt;lag()&lt;/code&gt; respect the groupings in &lt;code&gt;group_by()&lt;/code&gt;.
The functions &lt;code&gt;lag()&lt;/code&gt; and &lt;code&gt;lead()&lt;/code&gt; will only return values within each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(lag_x = lag(x),
         lead_x = lead(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group lag_x lead_x
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt;
## 1     1 a        NA      2
## 2     2 a         1      3
## 3     3 a         2     NA
## 4     4 b        NA      5
## 5     5 b         4      6
## 6     6 b         5     NA
## 7     7 c        NA      8
## 8     8 c         7      9
## 9     9 c         8     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The cumulative and rolling aggregate functions &lt;code&gt;cumsum()&lt;/code&gt;, &lt;code&gt;cumprod()&lt;/code&gt;, &lt;code&gt;cummin()&lt;/code&gt;, &lt;code&gt;cummax()&lt;/code&gt;, and &lt;code&gt;cummean()&lt;/code&gt; calculate values within each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(x_cumsum = cumsum(x)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(x_cumsum_2 = cumsum(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group x_cumsum x_cumsum_2
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1     1 a            1          1
## 2     2 a            3          3
## 3     3 a            6          6
## 4     4 b           10          4
## 5     5 b           15          9
## 6     6 b           21         15
## 7     7 c           28          7
## 8     8 c           36         15
## 9     9 c           45         24&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Logical comparisons, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, and &lt;code&gt;==&lt;/code&gt; are not affected by &lt;code&gt;group_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       y = 9:1,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(x_lte_y = x &amp;lt;= y) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(x_lte_y_2 = x &amp;lt;= y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 5
## # Groups:   group [3]
##       x     y group x_lte_y x_lte_y_2
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt;   &amp;lt;lgl&amp;gt;    
## 1     1     9 a     TRUE    TRUE     
## 2     2     8 a     TRUE    TRUE     
## 3     3     7 a     TRUE    TRUE     
## 4     4     6 b     TRUE    TRUE     
## 5     5     5 b     TRUE    TRUE     
## 6     6     4 b     FALSE   FALSE    
## 7     7     3 c     FALSE   FALSE    
## 8     8     2 c     FALSE   FALSE    
## 9     9     1 c     FALSE   FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ranking functions like &lt;code&gt;min_rank()&lt;/code&gt; work within each group when used with &lt;code&gt;group_by()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = 1:9,
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  mutate(rnk = min_rank(x)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  mutate(rnk2 = min_rank(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 4
## # Groups:   group [3]
##       x group   rnk  rnk2
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1     1 a         1     1
## 2     2 a         2     2
## 3     3 a         3     3
## 4     4 b         4     1
## 5     5 b         5     2
## 6     6 b         6     3
## 7     7 c         7     1
## 8     8 c         8     2
## 9     9 c         9     3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though not asked in the question, note that &lt;code&gt;arrange()&lt;/code&gt; ignores groups when sorting values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = runif(9),
       group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  arrange(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 2
## # Groups:   group [3]
##        x group
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 0.0941 a    
## 2 0.170  b    
## 3 0.606  a    
## 4 0.729  c    
## 5 0.744  b    
## 6 0.874  b    
## 7 0.897  c    
## 8 0.932  a    
## 9 0.956  c&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the order of values from &lt;code&gt;arrange()&lt;/code&gt; can interact with groups when
used with functions that rely on the ordering of elements, such as &lt;code&gt;lead()&lt;/code&gt;, &lt;code&gt;lag()&lt;/code&gt;,
or &lt;code&gt;cumsum()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(group = rep(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), each = 3), 
       x = runif(9)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  arrange(x) %&amp;gt;%
  mutate(lag_x = lag(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 3
## # Groups:   group [3]
##   group       x    lag_x
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 a     0.00549 NA      
## 2 c     0.109   NA      
## 3 a     0.152    0.00549
## 4 a     0.351    0.152  
## 5 c     0.552    0.109  
## 6 b     0.576   NA      
## 7 b     0.768    0.576  
## 8 c     0.810    0.552  
## 9 b     0.885    0.768&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section-5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Which plane (&lt;code&gt;tailnum&lt;/code&gt;) has the worst on-time record?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The question does not define a way to measure on-time record, so I will consider two metrics:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;proportion of flights not delayed or cancelled, and&lt;/li&gt;
&lt;li&gt;mean arrival delay.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first metric is the proportion of not-cancelled and on-time flights.
I use the presence of an arrival time as an indicator that a flight was not cancelled.
However, there are many planes that have never flown an on-time flight.
Additionally, many of the planes that have the lowest proportion of on-time flights have only flown a small number of flights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(!is.na(tailnum)) %&amp;gt;%
  mutate(on_time = !is.na(arr_time) &amp;amp; (arr_delay &amp;lt;= 0)) %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  summarise(on_time = mean(on_time), n = n()) %&amp;gt;%
  filter(min_rank(on_time) == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 110 x 3
##    tailnum on_time     n
##    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
##  1 N121DE        0     2
##  2 N136DL        0     1
##  3 N143DA        0     1
##  4 N17627        0     2
##  5 N240AT        0     5
##  6 N26906        0     1
##  7 N295AT        0     4
##  8 N302AS        0     1
##  9 N303AS        0     1
## 10 N32626        0     1
## # ... with 100 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, I will remove planes that flew at least 20 flights.
The choice of 20 was chosen because it round number near the first quartile of the number of flights by plane.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(count(flights, tailnum)$n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  25%  50%  75% 100% 
##    1   23   54  110 2512&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plane with the worst on time record that flew at least 20 flights is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(!is.na(tailnum), is.na(arr_time) | !is.na(arr_delay)) %&amp;gt;%
  mutate(on_time = !is.na(arr_time) &amp;amp; (arr_delay &amp;lt;= 0)) %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  summarise(on_time = mean(on_time), n = n()) %&amp;gt;%
  filter(n &amp;gt;= 20) %&amp;gt;%
  filter(min_rank(on_time) == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   tailnum on_time     n
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 N988AT    0.189    37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are cases where &lt;code&gt;arr_delay&lt;/code&gt; is missing but &lt;code&gt;arr_time&lt;/code&gt; is not missing.
I have not debugged the cause of this bad data, so these rows are dropped for
the purposes of this exercise.&lt;/p&gt;
&lt;p&gt;The second metric is the mean minutes delayed.
As with the previous metric, I will only consider planes which flew least 20 flights.
A different plane has the worst on-time record when measured as average minutes delayed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(!is.na(arr_delay)) %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  summarise(arr_delay = mean(arr_delay), n = n()) %&amp;gt;%
  filter(n &amp;gt;= 20) %&amp;gt;%
  filter(min_rank(desc(arr_delay)) == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   tailnum arr_delay     n
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 N203FR       59.1    41&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-6&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;What time of day should you fly if you want to avoid delays as much as possible?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Let’s group by the hour of the flight.
The earlier the flight is scheduled, the lower its expected delay.
This is intuitive as delays will affect later flights.
Morning flights have fewer (if any) previous flights that can delay them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  group_by(hour) %&amp;gt;%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %&amp;gt;%
  arrange(arr_delay)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 2
##     hour arr_delay
##    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1     7    -5.30 
##  2     5    -4.80 
##  3     6    -3.38 
##  4     9    -1.45 
##  5     8    -1.11 
##  6    10     0.954
##  7    11     1.48 
##  8    12     3.49 
##  9    13     6.54 
## 10    14     9.20 
## 11    23    11.8  
## 12    15    12.3  
## 13    16    12.6  
## 14    18    14.8  
## 15    22    16.0  
## 16    17    16.0  
## 17    19    16.7  
## 18    20    16.7  
## 19    21    18.4  
## 20     1   NaN&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-7&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;For each destination, compute the total minutes of delay.
For each flight, compute the proportion of the total delay for its destination.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The key to answering this question is to only include delayed flights when calculating the total delay and proportion of delay.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(arr_delay &amp;gt; 0) %&amp;gt;%
  group_by(dest) %&amp;gt;%
  mutate(
    arr_delay_total = sum(arr_delay),
    arr_delay_prop = arr_delay / arr_delay_total
  ) %&amp;gt;%
  select(dest, month, day, dep_time, carrier, flight,
         arr_delay, arr_delay_prop) %&amp;gt;%
  arrange(dest, desc(arr_delay_prop))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 133,004 x 8
## # Groups:   dest [103]
##    dest  month   day dep_time carrier flight arr_delay arr_delay_prop
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;
##  1 ABQ       7    22     2145 B6        1505       153         0.0341
##  2 ABQ      12    14     2223 B6          65       149         0.0332
##  3 ABQ      10    15     2146 B6          65       138         0.0308
##  4 ABQ       7    23     2206 B6        1505       137         0.0305
##  5 ABQ      12    17     2220 B6          65       136         0.0303
##  6 ABQ       7    10     2025 B6        1505       126         0.0281
##  7 ABQ       7    30     2212 B6        1505       118         0.0263
##  8 ABQ       7    28     2038 B6        1505       117         0.0261
##  9 ABQ      12     8     2049 B6          65       114         0.0254
## 10 ABQ       9     2     2212 B6        1505       109         0.0243
## # ... with 132,994 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is some ambiguity in the meaning of the term &lt;em&gt;flights&lt;/em&gt; in the question.
The first example defined a flight as a row in the &lt;code&gt;flights&lt;/code&gt; table, which is a trip by an aircraft from an airport at a particular date and time.
However, &lt;em&gt;flight&lt;/em&gt; could also refer to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Flight_number&#34;&gt;flight number&lt;/a&gt;, which is the code a carrier uses for an airline service of a route.
For example, &lt;code&gt;AA1&lt;/code&gt; is the flight number of the 09:00 American Airlines flight between JFK and LAX.
The flight number is contained in the &lt;code&gt;flights$flight&lt;/code&gt; column, though what is called a “flight” is a combination of the &lt;code&gt;flights$carrier&lt;/code&gt; and &lt;code&gt;flights$flight&lt;/code&gt; columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(arr_delay &amp;gt; 0) %&amp;gt;%
  group_by(dest, origin, carrier, flight) %&amp;gt;%
  summarise(arr_delay = sum(arr_delay)) %&amp;gt;%
  group_by(dest) %&amp;gt;%
  mutate(
    arr_delay_prop = arr_delay / sum(arr_delay)
  ) %&amp;gt;%
  arrange(dest, desc(arr_delay_prop)) %&amp;gt;%
  select(carrier, flight, origin, dest, arr_delay_prop)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;dest&amp;#39;, &amp;#39;origin&amp;#39;, &amp;#39;carrier&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,834 x 5
## # Groups:   dest [103]
##    carrier flight origin dest  arr_delay_prop
##    &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
##  1 B6        1505 JFK    ABQ           0.567 
##  2 B6          65 JFK    ABQ           0.433 
##  3 B6        1191 JFK    ACK           0.475 
##  4 B6        1491 JFK    ACK           0.414 
##  5 B6        1291 JFK    ACK           0.0898
##  6 B6        1195 JFK    ACK           0.0208
##  7 EV        4309 EWR    ALB           0.174 
##  8 EV        4271 EWR    ALB           0.137 
##  9 EV        4117 EWR    ALB           0.0951
## 10 EV        4088 EWR    ALB           0.0865
## # ... with 8,824 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-8&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later &amp;gt;flights are delayed to allow earlier flights to leave. Using &lt;code&gt;lag()&lt;/code&gt; explore how the delay of a flight is related to the &amp;gt;delay of the immediately preceding flight.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;This calculates the departure delay of the preceding flight from the same airport.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lagged_delays &amp;lt;- flights %&amp;gt;%
  arrange(origin, month, day, dep_time) %&amp;gt;%
  group_by(origin) %&amp;gt;%
  mutate(dep_delay_lag = lag(dep_delay)) %&amp;gt;%
  filter(!is.na(dep_delay), !is.na(dep_delay_lag))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This plots the relationship between the mean delay of a flight for all values of the previous flight.
For delays less than two hours, the relationship between the delay of the preceding flight and the current flight is nearly a line.
After that the relationship becomes more variable, as long-delayed flights are interspersed with flights leaving on-time.
After about 8-hours, a delayed flight is likely to be followed by a flight leaving on time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lagged_delays %&amp;gt;%
  group_by(dep_delay_lag) %&amp;gt;%
  summarise(dep_delay_mean = mean(dep_delay)) %&amp;gt;%
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 1500, by = 120)) +
  labs(y = &amp;quot;Departure Delay&amp;quot;, x = &amp;quot;Previous Departure Delay&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-63-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The overall relationship looks similar in all three origin airports.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lagged_delays %&amp;gt;%
  group_by(origin, dep_delay_lag) %&amp;gt;%
  summarise(dep_delay_mean = mean(dep_delay)) %&amp;gt;%
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +
  geom_point() +
  facet_wrap(~ origin, ncol=1) +
  labs(y = &amp;quot;Departure Delay&amp;quot;, x = &amp;quot;Previous Departure Delay&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;origin&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-64-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-9&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.6&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Look at each destination. Can you find flights that are suspiciously fast?
(i.e. flights that represent a potential data entry error).
Compute the air time of a flight relative to the shortest flight to that destination.
Which flights were most delayed in the air?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;When calculating this answer we should only compare flights within the same (origin, destination) pair.&lt;/p&gt;
&lt;p&gt;To find unusual observations, we need to first put them on the same scale.
I will &lt;a href=&#34;https://en.wikipedia.org/wiki/Standard_score&#34;&gt;standardize&lt;/a&gt;
values by subtracting the mean from each and then dividing each by the standard deviation.
&lt;span class=&#34;math display&#34;&gt;\[
\mathsf{standardized}(x) = \frac{x - \mathsf{mean}(x)}{\mathsf{sd}(x)} .
\]&lt;/span&gt;
A standardized variable is often called a &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-score.
The units of the standardized variable are standard deviations from the mean.
This will put the flight times from different routes on the same scale.
The larger the magnitude of the standardized variable for an observation, the more unusual the observation is.
Flights with negative values of the standardized variable are faster than the
mean flight for that route, while those with positive values are slower than
the mean flight for that route.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;standardized_flights &amp;lt;- flights %&amp;gt;%
  filter(!is.na(air_time)) %&amp;gt;%
  group_by(dest, origin) %&amp;gt;%
  mutate(
    air_time_mean = mean(air_time),
    air_time_sd = sd(air_time),
    n = n()
  ) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(air_time_standard = (air_time - air_time_mean) / (air_time_sd + 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I add 1 to the denominator and numerator to avoid dividing by zero.
Note that the &lt;code&gt;ungroup()&lt;/code&gt; here is not necessary. However, I will be using
this data frame later. Through experience, I have found that I have fewer bugs
when I keep a data frame grouped for only those verbs that need it.
If I did not &lt;code&gt;ungroup()&lt;/code&gt; this data frame, the &lt;code&gt;arrange()&lt;/code&gt; used later would
not work as expected. It is better to err on the side of using &lt;code&gt;ungroup()&lt;/code&gt;
when unnecessary.&lt;/p&gt;
&lt;p&gt;The distribution of the standardized air flights has long right tail.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(standardized_flights, aes(x = air_time_standard)) +
  geom_density()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 4 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-66-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unusually fast flights are those flights with the smallest standardized values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;standardized_flights %&amp;gt;%
  arrange(air_time_standard) %&amp;gt;%
  select(
    carrier, flight, origin, dest, month, day,
    air_time, air_time_mean, air_time_standard
  ) %&amp;gt;%
  head(10) %&amp;gt;%
  print(width = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 9
##    carrier flight origin dest  month   day air_time air_time_mean
##    &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
##  1 DL        1499 LGA    ATL       5    25       65         114. 
##  2 EV        4667 EWR    MSP       7     2       93         151. 
##  3 EV        4292 EWR    GSP       5    13       55          93.2
##  4 EV        3805 EWR    BNA       3    23       70         115. 
##  5 EV        4687 EWR    CVG       9    29       62          96.1
##  6 B6        2002 JFK    BUF      11    10       38          57.1
##  7 DL        1902 LGA    PBI       1    12      105         146. 
##  8 DL         161 JFK    SEA       7     3      275         329. 
##  9 EV        5486 LGA    PIT       4    28       40          57.7
## 10 B6          30 JFK    ROC       3    25       35          51.9
##    air_time_standard
##                &amp;lt;dbl&amp;gt;
##  1             -4.56
##  2             -4.46
##  3             -4.20
##  4             -3.73
##  5             -3.60
##  6             -3.38
##  7             -3.34
##  8             -3.34
##  9             -3.15
## 10             -3.10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I used &lt;code&gt;width = Inf&lt;/code&gt; to ensure that all columns will be printed.&lt;/p&gt;
&lt;p&gt;The fastest flight is DL1499 from LGA to
ATL which departed on
2013-05-25 at 17:09.
It has an air time of 65 minutes, compared to an average
flight time of 114 minutes for its route.
This is 4.6 standard deviations below
the average flight on its route.&lt;/p&gt;
&lt;p&gt;It is important to note that this does not necessarily imply that there was a data entry error.
We should check these flights to see whether there was some reason for the difference.
It may be that we are missing some piece of information that explains these unusual times.&lt;/p&gt;
&lt;p&gt;A potential issue with the way that we standardized the flights is that the mean and standard deviation used to calculate are sensitive to outliers and outliers is what we are looking for.
Instead of standardizing variables with the mean and variance, we could use the median
as a measure of central tendency and the interquartile range (IQR) as a measure of spread.
The median and IQR are more &lt;a href=&#34;https://en.wikipedia.org/wiki/Robust_statistics&#34;&gt;resistant to outliers&lt;/a&gt; than the mean and standard deviation.
The following method uses the median and inter-quartile range, which are less sensitive to outliers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;standardized_flights2 &amp;lt;- flights %&amp;gt;%
  filter(!is.na(air_time)) %&amp;gt;%
  group_by(dest, origin) %&amp;gt;%
  mutate(
    air_time_median = median(air_time),
    air_time_iqr = IQR(air_time),
    n = n(),
    air_time_standard = (air_time - air_time_median) / air_time_iqr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The distribution of the standardized air flights using this new definition
also has long right tail of slow flights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(standardized_flights2, aes(x = air_time_standard)) +
  geom_density()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 4 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-70-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unusually fast flights are those flights with the smallest standardized values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;standardized_flights2 %&amp;gt;%
  arrange(air_time_standard) %&amp;gt;%
  select(
    carrier, flight, origin, dest, month, day, air_time,
    air_time_median, air_time_standard
  ) %&amp;gt;%
  head(10) %&amp;gt;%
  print(width = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 9
## # Groups:   dest, origin [10]
##    carrier flight origin dest  month   day air_time air_time_median
##    &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
##  1 EV        4667 EWR    MSP       7     2       93             149
##  2 DL        1499 LGA    ATL       5    25       65             112
##  3 US        2132 LGA    BOS       3     2       21              37
##  4 B6          30 JFK    ROC       3    25       35              51
##  5 B6        2002 JFK    BUF      11    10       38              57
##  6 EV        4292 EWR    GSP       5    13       55              92
##  7 EV        4249 EWR    SYR       3    15       30              39
##  8 EV        4580 EWR    BTV       6    29       34              46
##  9 EV        3830 EWR    RIC       7     2       35              53
## 10 EV        4687 EWR    CVG       9    29       62              95
##    air_time_standard
##                &amp;lt;dbl&amp;gt;
##  1             -3.5 
##  2             -3.36
##  3             -3.2 
##  4             -3.2 
##  5             -3.17
##  6             -3.08
##  7             -3   
##  8             -3   
##  9             -3   
## 10             -3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of these answers have relied only on using a distribution of comparable observations to find unusual observations.
In this case, the comparable observations were flights from the same origin to the same destination.
Apart from our knowledge that flights from the same origin to the same destination should have similar air times, we have not used any other domain-specific knowledge.
But we know much more about this problem.
The most obvious piece of knowledge we have is that we know that flights cannot travel back in time, so there should never be a flight with a negative airtime.
But we also know that aircraft have maximum speeds.
While different aircraft have different &lt;a href=&#34;https://en.wikipedia.org/wiki/Cruise_(aeronautics)&#34;&gt;cruising speeds&lt;/a&gt;, commercial airliners
typically cruise at air speeds around 547–575 mph.
Calculating the ground speed of aircraft is complicated by the way in which winds, especially the influence of wind, especially jet streams, on the ground-speed of flights.
A strong tailwind can increase ground-speed of the aircraft by &lt;a href=&#34;https://www.wired.com/story/norwegian-air-transatlantic-speed-record/&#34;&gt;200 mph&lt;/a&gt;.
Apart from the retired &lt;a href=&#34;https://en.wikipedia.org/wiki/Concorde&#34;&gt;Concorde&lt;/a&gt;.
For example, in 2018, &lt;a href=&#34;https://www.wired.com/story/norwegian-air-transatlantic-speed-record/&#34;&gt;a transatlantic flight&lt;/a&gt;
traveled at 770 mph due to a strong jet stream tailwind.
This means that any flight traveling at speeds greater than 800 mph is implausible,
and it may be worth checking flights traveling at greater than 600 or 700 mph.
Ground speed could also be used to identify aircraft flying implausibly slow.
Joining flights data with the air craft type in the &lt;code&gt;planes&lt;/code&gt; table and getting
information about typical or top speeds of those aircraft could provide a more
detailed way to identify implausibly fast or slow flights.
Additional data on high altitude wind speeds at the time of the flight would further help.&lt;/p&gt;
&lt;p&gt;Knowing the substance of the data analysis at hand is one of the most important
tools of a data scientist. The tools of statistics are a complement, not a
substitute, for that knowledge.&lt;/p&gt;
&lt;p&gt;With that in mind, Let’s plot the distribution of the ground speed of flights.
The modal flight in this data has a ground speed of between 400 and 500 mph.
The distribution of ground speeds has a large left tail of slower flights below
400 mph constituting the majority.
There are very few flights with a ground speed over 500 mph.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  mutate(mph = distance / (air_time / 60)) %&amp;gt;%
  ggplot(aes(x = mph)) +
  geom_histogram(binwidth = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/week-10/index_files/figure-html/unnamed-chunk-72-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The fastest flight is the same one identified as the largest outlier earlier.
Its ground speed was 703 mph.
This is fast for a commercial jet, but not impossible.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  mutate(mph = distance / (air_time / 60)) %&amp;gt;%
  arrange(desc(mph)) %&amp;gt;%
  select(mph, flight, carrier, flight, month, day, dep_time) %&amp;gt;%
  head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 6
##     mph flight carrier month   day dep_time
##   &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;
## 1  703.   1499 DL          5    25     1709
## 2  650.   4667 EV          7     2     1558
## 3  648    4292 EV          5    13     2040
## 4  641.   3805 EV          3    23     1914
## 5  591.   1902 DL          1    12     1559&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One explanation for unusually fast flights is that they are “making up time” in the air by flying faster.
Commercial aircraft do not fly at their top speed since the airlines are also concerned about fuel consumption.
But, if a flight is delayed on the ground, it may fly faster than usual in order to avoid a late arrival.
So, I would expect that some of the unusually fast flights were delayed on departure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  mutate(mph = distance / (air_time / 60)) %&amp;gt;%
  arrange(desc(mph)) %&amp;gt;%
  select(
    origin, dest, mph, year, month, day, dep_time, flight, carrier,
    dep_delay, arr_delay
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 x 11
##    origin dest    mph  year month   day dep_time flight carrier dep_delay
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
##  1 LGA    ATL    703.  2013     5    25     1709   1499 DL              9
##  2 EWR    MSP    650.  2013     7     2     1558   4667 EV             45
##  3 EWR    GSP    648   2013     5    13     2040   4292 EV             15
##  4 EWR    BNA    641.  2013     3    23     1914   3805 EV              4
##  5 LGA    PBI    591.  2013     1    12     1559   1902 DL             -1
##  6 JFK    SJU    564   2013    11    17      650    315 DL             -5
##  7 JFK    SJU    557.  2013     2    21     2355    707 B6             -3
##  8 JFK    STT    556.  2013    11    17      759    936 AA             -1
##  9 JFK    SJU    554.  2013    11    16     2003    347 DL             38
## 10 JFK    SJU    554.  2013    11    16     2349   1503 B6            -10
## # ... with 336,766 more rows, and 1 more variable: arr_delay &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Five of the top ten flights had departure delays, and three of those were
able to make up that time in the air and arrive ahead of schedule.&lt;/p&gt;
&lt;p&gt;Overall, there were a few flights that seemed unusually fast, but they all
fall into the realm of plausibility and likely are not data entry problems.
[Ed. Please correct me if I am missing something]&lt;/p&gt;
&lt;!--
Similarly, the longest [regularly scheduled flight](https://en.wikipedia.org/wiki/Longest_flights#Record_flights) is Newark
to Signapore with a duration of 18 hours 30--45 minutes.
Thus, we should never observe any commercial flight longer than 19 hours in our
data.
--&gt;
&lt;p&gt;The second part of the question asks us to compare flights to the fastest flight
on a route to find the flights most delayed in the air. I will calculate the
amount a flight is delayed in air in two ways.
The first is the absolute delay, defined as the number of minutes longer than the fastest flight on that route,&lt;code&gt;air_time - min(air_time)&lt;/code&gt;.
The second is the relative delay, which is the percentage increase in air time relative to the time of the fastest flight
along that route, &lt;code&gt;(air_time - min(air_time)) / min(air_time) * 100&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;air_time_delayed &amp;lt;-
  flights %&amp;gt;%
  group_by(origin, dest) %&amp;gt;%
  mutate(
    air_time_min = min(air_time, na.rm = TRUE),
    air_time_delay = air_time - air_time_min,
    air_time_delay_pct = air_time_delay / air_time_min * 100
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in min(air_time, na.rm = TRUE): no non-missing arguments to min;
## returning Inf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The most delayed flight in air in minutes was DL841
from JFK to SFO which departed on
2013-07-28 at 17:27. It took
189 minutes longer than the flight with the shortest
air time on its route.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;air_time_delayed %&amp;gt;%
  arrange(desc(air_time_delay)) %&amp;gt;%
  select(
    air_time_delay, carrier, flight,
    origin, dest, year, month, day, dep_time,
    air_time, air_time_min
  ) %&amp;gt;%
  head() %&amp;gt;%
  print(width = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
## # Groups:   origin, dest [5]
##   air_time_delay carrier flight origin dest   year month   day dep_time air_time
##            &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;
## 1            189 DL         841 JFK    SFO    2013     7    28     1727      490
## 2            165 DL         426 JFK    LAX    2013    11    22     1812      440
## 3            163 AA         575 JFK    EGE    2013     1    28     1806      382
## 4            147 DL          17 JFK    LAX    2013     7    10     1814      422
## 5            145 UA         745 LGA    DEN    2013     9    10     1513      331
## 6            143 UA         587 EWR    LAS    2013    11    22     2142      399
##   air_time_min
##          &amp;lt;dbl&amp;gt;
## 1          301
## 2          275
## 3          219
## 4          275
## 5          186
## 6          256&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The most delayed flight in air as a percentage of the fastest flight along that
route was US2136
from LGA to BOS departing on 2013-06-17 at 16:52.
It took 410% longer than the
flight with the shortest air time on its route.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;air_time_delayed %&amp;gt;%
  arrange(desc(air_time_delay)) %&amp;gt;%
  select(
    air_time_delay_pct, carrier, flight,
    origin, dest, year, month, day, dep_time,
    air_time, air_time_min
  ) %&amp;gt;%
  head() %&amp;gt;%
  print(width = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
## # Groups:   origin, dest [5]
##   air_time_delay_pct carrier flight origin dest   year month   day dep_time
##                &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;
## 1               62.8 DL         841 JFK    SFO    2013     7    28     1727
## 2               60   DL         426 JFK    LAX    2013    11    22     1812
## 3               74.4 AA         575 JFK    EGE    2013     1    28     1806
## 4               53.5 DL          17 JFK    LAX    2013     7    10     1814
## 5               78.0 UA         745 LGA    DEN    2013     9    10     1513
## 6               55.9 UA         587 EWR    LAS    2013    11    22     2142
##   air_time air_time_min
##      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1      490          301
## 2      440          275
## 3      382          219
## 4      422          275
## 5      331          186
## 6      399          256&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-10&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.7&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;Find all destinations that are flown by at least two carriers.
Use that information to rank the carriers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;To restate this question, we are asked to rank airlines by the number of destinations that they fly to, considering only those airports that are flown to by two or more airlines.
There are two steps to calculating this ranking.
First, find all airports serviced by two or more carriers.
Then, rank carriers by the number of those destinations that they service.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
   # find all airports with &amp;gt; 1 carrier
   group_by(dest) %&amp;gt;%
   mutate(n_carriers = n_distinct(carrier)) %&amp;gt;%
   filter(n_carriers &amp;gt; 1) %&amp;gt;%
   # rank carriers by numer of destinations
   group_by(carrier) %&amp;gt;%
   summarize(n_dest = n_distinct(dest)) %&amp;gt;%
   arrange(desc(n_dest))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 16 x 2
##    carrier n_dest
##    &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;
##  1 EV          51
##  2 9E          48
##  3 UA          42
##  4 DL          39
##  5 B6          35
##  6 AA          19
##  7 MQ          19
##  8 WN          10
##  9 OO           5
## 10 US           5
## 11 VX           4
## 12 YV           3
## 13 FL           2
## 14 AS           1
## 15 F9           1
## 16 HA           1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The carrier &lt;code&gt;&#34;EV&#34;&lt;/code&gt; flies to the most destinations, considering only airports flown to by two or more carriers. What airline does the &lt;code&gt;&#34;EV&#34;&lt;/code&gt; carrier code correspond to?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(airlines, carrier == &amp;quot;EV&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   carrier name                    
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;                   
## 1 EV      ExpressJet Airlines Inc.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unless you know the airplane industry, it is likely that you don’t recognize &lt;a href=&#34;https://en.wikipedia.org/wiki/ExpressJet&#34;&gt;ExpressJet&lt;/a&gt;; I certainly didn’t.
It is a regional airline that partners with major airlines to fly from hubs (larger airports) to smaller airports.
This means that many of the shorter flights of major carriers are operated by ExpressJet.
This business model explains why ExpressJet services the most destinations.&lt;/p&gt;
&lt;p&gt;Among the airlines that fly to only one destination from New York are Alaska Airlines
and Hawaiian Airlines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(airlines, carrier %in% c(&amp;quot;AS&amp;quot;, &amp;quot;F9&amp;quot;, &amp;quot;HA&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   carrier name                  
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;                 
## 1 AS      Alaska Airlines Inc.  
## 2 F9      Frontier Airlines Inc.
## 3 HA      Hawaiian Airlines Inc.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-11&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.7.1.8&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;For each plane, count the number of flights before the first delay of greater than 1 hour.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The question does not specify arrival or departure delay.
I consider &lt;code&gt;dep_delay&lt;/code&gt; in this answer, though similar code could be used for &lt;code&gt;arr_delay&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  # sort in increasing order
  select(tailnum, year, month,day, dep_delay) %&amp;gt;%
  filter(!is.na(dep_delay)) %&amp;gt;%
  arrange(tailnum, year, month, day) %&amp;gt;%
  group_by(tailnum) %&amp;gt;%
  # cumulative number of flights delayed over one hour
  mutate(cumulative_hr_delays = cumsum(dep_delay &amp;gt; 60)) %&amp;gt;%
  # count the number of flights == 0
  summarise(total_flights = sum(cumulative_hr_delays &amp;lt; 1)) %&amp;gt;%
  arrange(total_flights)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,037 x 2
##    tailnum total_flights
##    &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
##  1 D942DN              0
##  2 N10575              0
##  3 N11106              0
##  4 N11109              0
##  5 N11187              0
##  6 N11199              0
##  7 N12967              0
##  8 N13550              0
##  9 N136DL              0
## 10 N13903              0
## # ... with 4,027 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;We could address this issue using a statistical model, but that is outside
the scope of this text.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The &lt;code&gt;count()&lt;/code&gt; function is introduced in &lt;a href=&#34;https://r4ds.had.co.nz/transform.html#counts&#34;&gt;Chapter 5.6&lt;/a&gt;. It returns the count of
rows by group. In this case, the number of rows in &lt;code&gt;flights&lt;/code&gt; for each
&lt;code&gt;tailnum&lt;/code&gt;. The data frame that &lt;code&gt;count()&lt;/code&gt; returns has columns for the
groups, and a column &lt;code&gt;n&lt;/code&gt;, which contains that count.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidysynth Demonstration</title>
      <link>https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/</link>
      <pubDate>Sun, 07 Feb 2021 19:56:23 -0700</pubDate>
      <guid>https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Synthetic control methodologies come in many flavors. Most commonly, Scott Mourtgos and I use “Bayesian Structural Time Series,” but there are others. One exciting new package brings synth models to the &lt;code&gt;tidyverse&lt;/code&gt;. &lt;a href=&#34;https://github.com/edunford&#34;&gt;Eric Dunford&lt;/a&gt; just released his &lt;a href=&#34;https://github.com/edunford/tidysynth&#34;&gt;new package &lt;code&gt;tidysynth&lt;/code&gt;&lt;/a&gt;, and I wanted to give it a spin.&lt;/p&gt;
&lt;p&gt;To demonstrate the package, the vignette uses data from &lt;a href=&#34;https://economics.mit.edu/files/11859&#34;&gt;Abadie et al. (2010)&lt;/a&gt;, which tests the effects of an anti-smoking proposition on cigarette consumption.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidysynth)

data(&amp;quot;smoking&amp;quot;)

smoking %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1,209
## Columns: 7
## $ state     &amp;lt;chr&amp;gt; &amp;quot;Rhode Island&amp;quot;, &amp;quot;Tennessee&amp;quot;, &amp;quot;Indiana&amp;quot;, &amp;quot;Nevada&amp;quot;, &amp;quot;Louisi...
## $ year      &amp;lt;dbl&amp;gt; 1970, 1970, 1970, 1970, 1970, 1970, 1970, 1970, 1970, 197...
## $ cigsale   &amp;lt;dbl&amp;gt; 123.9, 99.8, 134.6, 189.5, 115.9, 108.4, 265.7, 93.8, 100...
## $ lnincome  &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ beer      &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ age15to24 &amp;lt;dbl&amp;gt; 0.1831579, 0.1780438, 0.1765159, 0.1615542, 0.1851852, 0....
## $ retprice  &amp;lt;dbl&amp;gt; 39.3, 39.9, 30.6, 38.9, 34.3, 38.4, 31.4, 37.3, 36.7, 28....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main computations happen within just a few pipes (ahh, the beauty of &lt;code&gt;tidy&lt;/code&gt;!).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out &amp;lt;-
  
  smoking %&amp;gt;%
  
  # initial the synthetic control object
  synthetic_control(outcome = cigsale, # outcome
                    unit = state, # unit index in the panel data
                    time = year, # time index in the panel data
                    i_unit = &amp;quot;California&amp;quot;, # unit where the intervention occurred
                    i_time = 1988, # time period when the intervention occurred
                    generate_placebos=T # generate placebo synthetic controls (for inference)
                    ) %&amp;gt;%
  
  # Generate the aggregate predictors used to fit the weights
  
  # average log income, retail price of cigarettes, and proportion of the
  # population between 15 and 24 years of age from 1980 - 1988
  generate_predictor(time_window = 1980:1988,
                     ln_income = mean(lnincome, na.rm = T),
                     ret_price = mean(retprice, na.rm = T),
                     youth = mean(age15to24, na.rm = T)) %&amp;gt;%
  
  # average beer consumption in the donor pool from 1984 - 1988
  generate_predictor(time_window = 1984:1988,
                     beer_sales = mean(beer, na.rm = T)) %&amp;gt;%
  
  # Lagged cigarette sales 
  generate_predictor(time_window = 1975,
                     cigsale_1975 = cigsale) %&amp;gt;%
  generate_predictor(time_window = 1980,
                     cigsale_1980 = cigsale) %&amp;gt;%
  generate_predictor(time_window = 1988,
                     cigsale_1988 = cigsale) %&amp;gt;%
  
  
  # Generate the fitted weights for the synthetic control
  generate_weights(optimization_window = 1970:1988, # time to use in the optimization task
                   margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options
  ) %&amp;gt;%
  
  # Generate the synthetic control
  generate_control()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything is working like it should, the synthetic control should closely match the observed trend in the pre-intervention period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_trends()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy003-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One can easily see that the post-propostion period is deviating downward. But to capture the actual quantitative differences between the observed and synthetic models, we can use &lt;code&gt;plot_differences()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_differences()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy004-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We might also want to know which (and how) units and variables were weighted by the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_weights()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy005-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Smooth! The package also includes a host of &lt;code&gt;grab_&lt;/code&gt; functions to quickly retrieve parts of the tidy output. For example, a balance table can show us how comparable the synthetic control is to the observed covariates of the treated unit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% grab_balance_table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 4
##   variable     California synthetic_California donor_sample
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;                &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 ln_income        10.1                  9.84         9.83 
## 2 ret_price        89.4                 89.4         87.3  
## 3 youth             0.174                0.174        0.173
## 4 beer_sales       24.3                 24.3         23.7  
## 5 cigsale_1975    127.                 127.         137.   
## 6 cigsale_1980    120.                 120.         138.   
## 7 cigsale_1988     90.1                 90.8        114.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything looks good there. One of the main uses for synthetic control models is for inference. In other words, can we infer causality for the somewhat dramatic change between the pre- and post-intervention periods? The package developer has included some very nice features to help with inference. From the package developer:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For inference, the method relies on repeating the method for every donor in the donor pool exactly as was done for the treated unit — i.e. generating placebo synthetic controls. By setting &lt;code&gt;generate_placebos = TRUE&lt;/code&gt; when initializing the synth pipeline with &lt;code&gt;synthetic_control()&lt;/code&gt;, placebo cases are automatically generated when constructing the synthetic control of interest. This makes it easy to explore how unique difference between the observed and synthetic unit is when compared to the placebos.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_placebos()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy007-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You might wonder why the plot above is only plotting a few of the donor cases. This is because the plain function of &lt;code&gt;plot_placebos()&lt;/code&gt; automatically drops those cases where the data has a poor fit to the model. This is a fairly large difference between this package, which uses a frequentist approach, and BSTS, which obviously uses a Bayesian approach. Still, the package developer has a &lt;code&gt;prune = FALSE&lt;/code&gt; argument you can use to see all the cases, regardless of data –&amp;gt; model fit.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that the plot_placebos() function automatically prunes any placebos that poorly fit the data in the pre-intervention period. The reason for doing so is purely visual: those units tend to throw off the scale when plotting the placebos. To prune, the function looks at the pre-intervention period mean squared prediction error (MSPE) (i.e. a metric that reflects how well the synthetic control maps to the observed outcome time series in pre-intervention period). If a placebo control has a MSPE that is two times beyond the target case (e.g. “California”), then it’s dropped. To turn off this behavior, set prune = FALSE.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_placebos(prune = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy008-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some researchers prefer a frequentist approach, and one of the advantages of this approach is that we can derive Fisher’s Exact P-values &lt;a href=&#34;https://economics.mit.edu/files/11859&#34;&gt;based on work from Abadie et al., (2010)&lt;/a&gt;. Interpretation is straightforward:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If the intervention had no effect, then the post-period and pre-period should continue to map onto one another fairly well, yielding a ratio close to 1. If the placebo units fit the data similarly, then we can’t reject the hull hypothesis that there is no effect brought about by the intervention.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;This ratio can be easily plotted using plot_mspe_ratio(), offering insight into the rarity of the case where the intervention actually occurred.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% plot_mspe_ratio()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-02-07-tidysynth-demonstration/index_files/figure-html/remedy009-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For those who want to publish their results, reviewers and readers are going to want a table of results. The &lt;code&gt;tidysynth&lt;/code&gt; package has you covered.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_out %&amp;gt;% grab_signficance()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 39 x 8
##    unit_name  type  pre_mspe post_mspe mspe_ratio  rank fishers_exact_p~ z_score
##    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 California Trea~     3.94     390.       99.0      1           0.0256  5.13  
##  2 Georgia    Donor     3.48     174.       49.8      2           0.0513  2.33  
##  3 Virginia   Donor     5.86     171.       29.2      3           0.0769  1.16  
##  4 Indiana    Donor    18.4      415.       22.6      4           0.103   0.787 
##  5 West Virg~ Donor    14.3      287.       20.1      5           0.128   0.646 
##  6 Connectic~ Donor    27.3      335.       12.3      6           0.154   0.202 
##  7 Nebraska   Donor     6.47      54.3       8.40     7           0.179  -0.0189
##  8 Missouri   Donor     9.19      77.0       8.38     8           0.205  -0.0199
##  9 Texas      Donor    24.5      160.        6.54     9           0.231  -0.125 
## 10 Idaho      Donor    53.2      340.        6.39    10           0.256  -0.133 
## # ... with 29 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I really appreciate the work that’s gone into this package. It highlights the value of the &lt;code&gt;tidyverse&lt;/code&gt; with human-readable code, and straightforward piping to make for very functional analysis with limited work. Great job to the developer!&lt;/p&gt;
&lt;p&gt;I suggest reading further, as the package is apparently under active development. I also don’t go into the many &lt;code&gt;grab_&lt;/code&gt; functions that allow for the researcher to quickly “grab” elements of the model.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##   Function             Description                                              
##   &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt;                                                    
## 1 grab_outcome()       Extract the outcome variable generated by synthetic_cont~
## 2 grab_predictors()    Extract the aggregate-level covariates generated by gene~
## 3 grab_unit_weights()  Extract the unit weights generated by generate_weights().
## 4 grab_predictor_weig~ Extract the predictor variable weights generated by gene~
## 5 grab_loss()          Extract the RMSE loss of the optimized weights generated~
## 6 grab_synthetic_cont~ Extract the synthetic control generated using generate_c~
## 7 grab_signficance()   Generate inferential statistics comparing the rarity of ~
## 8 grab_balance_table() Compare the distributions of the aggregate-level predict~&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Git Marker</title>
      <link>https://ianadamsresearch.com/post/2021-01-21-git-marker/</link>
      <pubDate>Thu, 21 Jan 2021 20:36:17 -0700</pubDate>
      <guid>https://ianadamsresearch.com/post/2021-01-21-git-marker/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve struggled &lt;em&gt;mightily&lt;/em&gt; with Github over the years. I kind of got the idea, but the practice of it always left me frustrated, and the time-sink necessary to figure it all out was always just out of reach.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve always manually deployed this website through Netlify. That actually works just fine, but it&amp;rsquo;s easy to lose a lot of time as you deploy &amp;ndash;&amp;gt; find a mistake &amp;ndash;&amp;gt; back to Rstudio to fix things &amp;ndash;&amp;gt; deploy, and on and on.&lt;/p&gt;
&lt;p&gt;I have finally figured it out, at least enough to deploy consistently and safely. One of the big hangups I found was that Rstudio&amp;rsquo;s git commit does &lt;strong&gt;not&lt;/strong&gt; work well with bigger sized files. When dealing with &lt;code&gt;blogdown&lt;/code&gt;, the &amp;ldquo;public&amp;rdquo; folder that gets built, and that you use to manually deploy, was a problem. Upon initial commit, it was hanging Rstudio and would not proceed. That would lead to a &amp;ldquo;lock&amp;rdquo; file in the git process, leaving me unable to proceed. It took a while to figure out that using the Github Desktop app actually works a lot smoother. For small commits I still use Rstudio, but if I&amp;rsquo;m forking over a larger respository and building a local public folder, I&amp;rsquo;ll use Github Desktop to take care of the commit and push.&lt;/p&gt;
&lt;p&gt;But really, this whole post is just a breadcrumb for myself to remember when I switched over to deploying the website from Github. It&amp;rsquo;s such a nice quality of life improvement!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Latex Equations From Model Objects the Equatiomatic Package</title>
      <link>https://ianadamsresearch.com/post/2021-01-18-latex-equations-from-model-objects-the-equatiomatic-package/</link>
      <pubDate>Mon, 18 Jan 2021 19:27:18 -0700</pubDate>
      <guid>https://ianadamsresearch.com/post/2021-01-18-latex-equations-from-model-objects-the-equatiomatic-package/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/2021-01-18-latex-equations-from-model-objects-the-equatiomatic-package/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;As I was building a recent preprint, and trying to translate a long Bayesian formula (courtesy the big brain of &lt;a href=&#34;https://smourtgos.netlify.app/&#34;&gt;Scott Mourtgos&lt;/a&gt;) into properly specified LaTeX, I thought there has to be a better way. As usual, my decision to &lt;a href=&#34;https://github.com/andrewheiss&#34;&gt;follow Andrew Heiss’ github&lt;/a&gt; paid off, as I saw he has been authoring the &lt;code&gt;equatiomatic&lt;/code&gt; package. The project is maintained by Daniel Anderson, and you can &lt;a href=&#34;https://datalorax.github.io/equatiomatic/&#34;&gt;check it out yourself here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The beauty of &lt;code&gt;equatiomatic&lt;/code&gt; is clear - it takes your model object in R and translates it into beautifully rendered LaTeX equations.&lt;/p&gt;
&lt;p&gt;Thought I’d quickly demo the package using some easy data I had laying around.&lt;/p&gt;
&lt;div id=&#34;walking-through-equatiomatic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Walking Through &lt;code&gt;equatiomatic&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First get the package installed and loaded:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# package install
# install.packages(&amp;quot;equatiomatic&amp;quot;, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;)

# load up
library(equatiomatic)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m using some data from my most recent publication in &lt;em&gt;Public Administration Review&lt;/em&gt;, which tests competing theories of body-worn camera (BWC) activation. We ask: Is variation in BWC activations more explained by officer attitudes towards the cameras, by officer demographics, or by job function. I won’t repeat the whole analysis here, but you can &lt;a href=&#34;https://doi.org/10.1111/puar.13339&#34;&gt;find out by visiting the article&lt;/a&gt;!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

activations &amp;lt;- read_csv(&amp;quot;activations.csv&amp;quot;)

head(activations)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 26
##   totalactivations Activ_Plus_One_~ years_LEO Female  rank BWC_time forcecount
##              &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1               54             4.01         4      0     1        5          0
## 2               79             4.38        10      0     1        3          0
## 3              138             4.93         4      0     1        5          1
## 4               11             2.48        11      0     1        5          0
## 5              148             5.00        20      0     1        5          0
## 6              198             5.29         3      0     1        4          1
## # ... with 19 more variables: totalprimarycalls &amp;lt;dbl&amp;gt;, arrests &amp;lt;dbl&amp;gt;,
## #   Line_Officer &amp;lt;dbl&amp;gt;, BWCapproval_new &amp;lt;dbl&amp;gt;, POS_LATENT &amp;lt;dbl&amp;gt;,
## #   BWC_understand &amp;lt;dbl&amp;gt;, BWC_freedom &amp;lt;dbl&amp;gt;, BWC_decision &amp;lt;dbl&amp;gt;,
## #   BWC_manipulate &amp;lt;dbl&amp;gt;, BWC_modify &amp;lt;dbl&amp;gt;, BWC_lessforce &amp;lt;dbl&amp;gt;,
## #   BWC_assault &amp;lt;dbl&amp;gt;, BWC_complaint &amp;lt;dbl&amp;gt;, BWC_personal &amp;lt;dbl&amp;gt;,
## #   BWC_embarrass &amp;lt;dbl&amp;gt;, BWC_hatred &amp;lt;dbl&amp;gt;, BWC_fair &amp;lt;dbl&amp;gt;, BWC_protect &amp;lt;dbl&amp;gt;,
## #   BWC_wellbeing &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s build a quick (and misspecified here) version of one of the main models of interest in the paper:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;job_function &amp;lt;- lm(totalactivations ~ forcecount + totalprimarycalls + arrests + Line_Officer, activations)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we give the results of that model to &lt;code&gt;equatiomatic&lt;/code&gt; and let it extract and build:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;equatiomatic::extract_eq(job_function,
                         wrap = TRUE,        # Long equation needs to wrap 
                         terms_per_line = 2) # Max two equation terms per line&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $$
## \begin{aligned}
## \operatorname{totalactivations} &amp;amp;= \alpha + \beta_{1}(\operatorname{forcecount})\ + \\
## &amp;amp;\quad \beta_{2}(\operatorname{totalprimarycalls}) + \beta_{3}(\operatorname{arrests})\ + \\
## &amp;amp;\quad \beta_{4}(\operatorname{Line\_Officer}) + \epsilon
## \end{aligned}
## $$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can take the output directly to Rmarkdown using the given LaTeX!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\operatorname{totalactivations} &amp;amp;= \alpha + \beta_{1}(\operatorname{forcecount})\ + \\
&amp;amp;\quad \beta_{2}(\operatorname{totalprimarycalls}) + \beta_{3}(\operatorname{arrests})\ + \\
&amp;amp;\quad \beta_{4}(\operatorname{Line\_Officer}) + \epsilon
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Absolutely gorgeous! But it gets better, we can include the coefficients instead of funny Greek letters!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;equatiomatic::extract_eq(job_function,
                         use_coefs = TRUE,   # Use coefficients instead of beta
                         wrap = TRUE,        # Long equation needs to wrap 
                         terms_per_line = 2) # Max two equation terms per line&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $$
## \begin{aligned}
## \operatorname{totalactivations} &amp;amp;= 6.19 + 10.66(\operatorname{forcecount})\ + \\
## &amp;amp;\quad 0.65(\operatorname{totalprimarycalls}) + 3.91(\operatorname{arrests})\ + \\
## &amp;amp;\quad 18.78(\operatorname{Line\_Officer}) + \epsilon
## \end{aligned}
## $$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, copy/paste over the LaTeX given by equatiomatic, and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\operatorname{totalactivations} &amp;amp;= 6.19 + 10.66(\operatorname{forcecount})\ + \\
&amp;amp;\quad 0.65(\operatorname{totalprimarycalls}) + 3.91(\operatorname{arrests})\ + \\
&amp;amp;\quad 18.78(\operatorname{Line\_Officer}) + \epsilon
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By the way, the package isn’t limited to linear regressions, and already has support for logistic and probit regressions with &lt;code&gt;glm()&lt;/code&gt;, and ordered logistic regressions. Hit up the package home to follow development.&lt;/p&gt;
&lt;p&gt;I am completely impressed by this young package so far, and can’t wait to see what else is coming!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Which Model do I use?</title>
      <link>https://ianadamsresearch.com/courses/pubpl-6002/which-model/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/courses/pubpl-6002/which-model/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/which-model/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/which-model/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://ianadamsresearch.com/courses/pubpl-6002/which-model/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This is a very constrained, simple table to help students decide what type of statistical modeling is appropriate for their research question and data set.&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:table&#34;&gt;Table 1: &lt;/span&gt;Which Model Do I Use?
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Comparing
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Dependent (outcome) Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Independent (explanatory) variable
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Parametric Test (normally distributed data)
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Non-parametric test (ordinal or skewed data)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr grouplength=&#34;4&#34;&gt;
&lt;td colspan=&#34;5&#34; style=&#34;border-bottom: 1px solid;&#34;&gt;
&lt;strong&gt;Single Comparison Tests&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
Averages of two independent groups
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Nominal (Binary)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Independent t-test
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mann-Whitney test/ Wilcoxon rank sum
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
Averages of 3+ independent groups
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Nominal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
One-way ANOVA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kruskal-Wallis test
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
The average difference between paired (matched) samples e.g. test scores before and after a class
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Time or Condition variable
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paired t-test
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wilcoxon signed rank test
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
The 3+ measurements on the same subject
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Time or Condition variable
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Repeated measures ANOVA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Friedman test
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;6&#34;&gt;
&lt;td colspan=&#34;5&#34; style=&#34;border-bottom: 1px solid;&#34;&gt;
&lt;strong&gt;Association Tests&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
Relationship between 2 continuous variables
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pearson’s Correlation Coefficient
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Spearman’s Correlation Coefficient
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
What is value of DV when value of IV changes?
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scale
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Any
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Simple Linear Regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Transform the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
What is value of DV when value of IV changes?
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Nominal (Binary)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Any
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Logistic regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
What is value of DV when value of IV changes?
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Nominal (Count)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Any
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Poisson Regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
What is value of DV when value of IV changes?
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Nominal (Count, overdispersed)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Any
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Negative Binomial Regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;&#34; indentlevel=&#34;1&#34;&gt;
Assessing the relationship between two categorical variables
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Categorical
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Categorical
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chi-squared test
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Public Policy Data Sources</title>
      <link>https://ianadamsresearch.com/post/2021-01-12-public-policy-data-sources/</link>
      <pubDate>Tue, 12 Jan 2021 10:53:17 -0700</pubDate>
      <guid>https://ianadamsresearch.com/post/2021-01-12-public-policy-data-sources/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/2021-01-12-public-policy-data-sources/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;general-data-sources&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;General Data Sources&lt;/h1&gt;
&lt;p&gt;The questions posed in public policy research are astoundingly varied. Crime, medicine, environmental, and political questions are all valid domains. Given that variety, it is no surprise that the data sources tapped by public policy scholars are similarly varied.&lt;/p&gt;
&lt;p&gt;With that in mind, the following list should be considered only a start. All of the sources below have been used by scholars and practitioners to investigate interesting questions from across public policy.&lt;/p&gt;
&lt;div id=&#34;us-census&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;US Census&lt;/h2&gt;
&lt;p&gt;The Census Bureau’s mission is to serve as the nation’s leading provider of quality data about its people and economy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://data.census.gov/cedsci/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inter-university-consortium-for-political-and-social-research-icpsr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inter-University Consortium for Political and Social Research (ICPSR)&lt;/h2&gt;
&lt;p&gt;(Personal favorite!) An international consortium of more than 750 academic institutions and research organizations, Inter-university Consortium for Political and Social Research (ICPSR) provides leadership and training in data access, curation, and methods of analysis for the social science research community.&lt;/p&gt;
&lt;p&gt;ICPSR maintains a data archive of more than 250,000 files of research in the social and behavioral sciences. It hosts 21 specialized collections of data in education, aging, criminal justice, substance abuse, terrorism, and other fields.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.icpsr.umich.edu/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;world-development-indicators-wdi-online&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;World Development Indicators (WDI) Online&lt;/h2&gt;
&lt;p&gt;The primary World Bank collection of development indicators, compiled from officially-recognized international sources. It presents the most current and accurate global development data available, and includes national, regional and global estimates&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://datacatalog.worldbank.org/dataset/world-development-indicators&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;council-of-european-social-science-data-archives-cessda-portal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Council of European Social Science Data Archives (CESSDA) Portal&lt;/h2&gt;
&lt;p&gt;Research data and metadata, including sociological surveys, election studies, longitudinal studies, opinion polls, and census data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nsd.uib.no/cessda/home.html&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;google-database-search&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Google Database Search&lt;/h2&gt;
&lt;p&gt;Dataset Search is a search engine for datasets.Using a simple keyword search, users can discover datasets hosted in thousands of repositories across the Web. The nice thing about this one is it can find data in many of the others listed here!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://datasetsearch.research.google.com/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;world-bank-research-data-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;World Bank Research Data Sets&lt;/h2&gt;
&lt;p&gt;Datasets for the World bank. Free and open access to global development data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://data.worldbank.org/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;us-government-data.gov&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;US Government “Data.gov”&lt;/h2&gt;
&lt;p&gt;Data, tools, and resources to conduct research, develop web and mobile applications, design data visualizations, and more.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://data.gov/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;iqss-institute-for-qualitative-social-science-at-harvard-dataverse-network&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IQSS (Institute for Qualitative Social Science at Harvard) Dataverse Network&lt;/h2&gt;
&lt;p&gt;Also known as the “Harvard Dataverse,” and is a repository for research data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dataverse.harvard.edu/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;american-national-election-studies-anes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;American National Election Studies (ANES)&lt;/h2&gt;
&lt;p&gt;Data on voting, public opinion, and political participation&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.electionstudies.org/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;general-social-survey-gss&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General Social Survey (GSS)&lt;/h2&gt;
&lt;p&gt;The GSS has been a reliable source of data to help researchers, students, and journalists monitor and explain trends in American behaviors, demographics, and opinions.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gss.norc.org/Get-The-Data&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pew-research-center-for-people-and-the-press&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pew Research Center for People and the Press&lt;/h2&gt;
&lt;p&gt;Pew Research Center is a nonpartisan fact tank that informs the public about the issues, attitudes and trends shaping the world.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pewresearch.org/download-datasets/&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;state-data-center-sdc-program-from-us-census&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;State Data Center (SDC) Program from US Census&lt;/h2&gt;
&lt;p&gt;The State Data Center (SDC) program is one of the Census Bureau’s longest and most successful partnerships. The partnership was created to make data available locally.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.census.gov/about/partners/sdc.html&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fun With the Scholar Package</title>
      <link>https://ianadamsresearch.com/post/2021-01-11-fun-with-the-scholar-package/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/2021-01-11-fun-with-the-scholar-package/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/2021-01-11-fun-with-the-scholar-package/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I saw the &lt;code&gt;scholar&lt;/code&gt; package &lt;a href=&#34;https://github.com/jkeirstead/scholar&#34;&gt;has a new maintainer on Github&lt;/a&gt;, so thought I’d do a quick run through of what’s available in the vignette. I was happy to see some updates, I think this is one of those fun but useful packages for people to learn about. Plus, it lets everyone make a little study of their favorite little solipsistic research subjects.&lt;/p&gt;
&lt;p&gt;Make sure you have the updated version of &lt;code&gt;scholar&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.package(&amp;quot;scholar&amp;quot;)

library(scholar)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Setup the basic information by changing up the &lt;code&gt;id&lt;/code&gt; argument, just visit &lt;a href=&#34;https://scholar.google.com&#34;&gt;Google Scholar&lt;/a&gt;, click on the “My Profile” link, and copy the last character string from the url (minus everything after the &amp;amp; sign). Paste that to the &lt;code&gt;id&lt;/code&gt; object below!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the id for author
id &amp;lt;- &amp;#39;g9lY5RUAAAAJ&amp;#39;

# Get profile and print name
l &amp;lt;- get_profile(id)
l$name &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Ian T. Adams&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get his citation history, i.e. citations to his work in a given year 
get_citation_history(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   year cites
## 1 2018     5
## 2 2019    40
## 3 2020    73
## 4 2021     1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get his publications (a large data frame)
get_publications(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                                                                                                           title
## 1                                                                                   Police body-worn cameras: Effects on officers’ burnout and perceived organizational support
## 2                                                                                                      Visibility is a trap: The ethics of police body-worn cameras and control
## 3                                                                                  Is emotional labor easier in collectivist or individualist cultures? An east–west comparison
## 4                                                                                               “That’s What the Money’s for”: Alienation and Emotional Labor in Public Service
## 5                                                                                          Police body-worn cameras: development of the perceived intensity of monitoring scale
## 6                                                                             Assessing public perceptions of police use-of-force: Legal reasonableness and community standards
## 7                                                                                                                           Understanding emotional labor at the cultural level
## 8                                The rhetoric of de-policing: Evaluating open-ended survey responses from police officers with machine learning-based structural topic modeling
## 9                                                         It&amp;#39;s not depersonalization, It&amp;#39;s emotional labor: Examining surface acting and use-of-force with evidence from the US
## 10                                                                                                                                                        Hidden in plain sight
## 11                                                               Hidden in Plain Sight: Contrasting Emotional Labor and Burnout in Civilian and Sworn Law Enforcement Employees
## 12                                                                                                   The Effect of Prosecutorial Actions on Deterrence: A County-Level Analysis
## 13                                                                                      Contrasting Emotional Labor and Burnout in Civilian and Sworn Law Enforcement Personnel
## 14                                                                                                 Emotional Labor in Emergency Dispatch: Gauging Effects of Training Protocols
## 15 Andrew G. Ferguson, The Rise of Big Data Policing: Surveillance, Race, and the Future of Law Enforcement (New York, NY: NYU Press, 2017). 272 pp. $28.00 (hardcover), ISBN …
## 16                                                                                                                                                  The Rhetoric of De-Policing
## 17                                                            How Values Shape Program Perceptions: The “Organic Ethos” and Producers’ Assessments of US Organic Policy Impacts
## 18                                                                                  Emotional labour in non-governmental organisations: narrative analysis and theory expansion
## 19                                                                                                                                                                       The UK
## 20                                                                                                               Trending Interconnectedness: The Value of Comparative Analysis
## 21                                                                                             High-Stakes Administrative Discretion: What Drives Body-Worn Camera Activations?
## 22                                                                                                                              International Journal of Law, Crime and Justice
##                                 author
## 1                 I Adams, S Mastracci
## 2                 I Adams, S Mastracci
## 3                 S Mastracci, I Adams
## 4                 S Mastracci, I Adams
## 5                 I Adams, S Mastracci
## 6                SM Mourtgos, IT Adams
## 7               SH Mastracci, IT Adams
## 8                SM Mourtgos, IT Adams
## 9               SH Mastracci, IT Adams
## 10              IT Adams, SH Mastracci
## 11              IT Adams, SH Mastracci
## 12               SM Mourtgos, IT Adams
## 13              IT Adams, SH Mastracci
## 14              SH Mastracci, IT Adams
## 15                            IT Adams
## 16               SM Mourtgos, IT Adams
## 17      DP Carter, SL Mosier, IT Adams
## 18              SH Mastracci, IT Adams
## 19      SH Mastracci, IT Adams, N Kang
## 20              SH Mastracci, IT Adams
## 21 IT Adams, SM Mourtgos, SH Mastracci
## 22              SH Mastracci, IT Adams
##                                                                        journal
## 1                                                             Police quarterly
## 2                                               Administrative Theory &amp;amp; Praxis
## 3                                                  Public Personnel Management
## 4                                               Administrative Theory &amp;amp; Praxis
## 5                                                      Criminal Justice Review
## 6                                                            Justice Quarterly
## 7  The Palgrave Handbook of Global Perspectives on Emotional Labor in Public …
## 8                                                  Journal of Criminal Justice
## 9                              International Journal of Law, Crime and Justice
## 10                        Emotional Labour in Criminal Justice and Criminology
## 11                        Emotional Labour in Criminal Justice and Criminology
## 12                                              Criminal Justice Policy Review
## 13                                          Policing: An International Journal
## 14                                     Annals of Emergency Dispatch &amp;amp; Response
## 15                                                Public Administration Review
## 16                                                                            
## 17                                                   Review of Policy Research
## 18                      International Journal of Work Organisation and Emotion
## 19 The Palgrave Handbook of Global Perspectives on Emotional Labor in Public …
## 20 The Palgrave Handbook of Global Perspectives on Emotional Labor in Public …
## 21                                                Public Administration Review
## 22                                                                            
##             number cites year                  cid        pubid
## 1     22 (1), 5-30    46 2019  8532835669277965898 RHpTSmoSYBkC
## 2  39 (4), 313-328    28 2017 11458448965364077389 ZeXyd9-uunAC
## 3  48 (3), 325-344    16 2019  3113275916335416875 BqipwSGYUEgC
## 4  40 (4), 304-319     9 2018 17350818719678078979 M3NEmzRMIkIC
## 5  44 (3), 386-405     7 2019 17636589692170586414 J_g5lzvAfSwC
## 6  37 (5), 869-899     6 2020  9895552701426227567 g5m5HwL7SMYC
## 7                      4 2019  1546338871969866120 2P1L_qKh6hAC
## 8      64 (C), 1-1     3 2019 12823963095676900727 35N4QoGY0k4C
## 9       61, 100358     1 2020 13462011810362789692 HoB7MX3m0LUC
## 10             185     0 2020                 &amp;lt;NA&amp;gt; yD5IFk8b50cC
## 11         185-195     0 2020                 &amp;lt;NA&amp;gt; dfsIfKJdRG4C
## 12 31 (4), 479-499     0 2020                 &amp;lt;NA&amp;gt; ns9cj8rnVeAC
## 13                     0 2020                 &amp;lt;NA&amp;gt; 3s1wT3WcHBgC
## 14     7 (3), 5-10     0 2020                 &amp;lt;NA&amp;gt; zA6iFVUQeVQC
## 15 79 (5), 791-793     0 2019                 &amp;lt;NA&amp;gt; lSLTfruPkqcC
## 16                     0 2019                 &amp;lt;NA&amp;gt; pqnbT2bcN3wC
## 17 36 (3), 296-317     0 2019                 &amp;lt;NA&amp;gt; RGFaLdJalmkC
## 18    10 (1), 1-18     0 2019                 &amp;lt;NA&amp;gt; u_35RYKgDlwC
## 19                     0 2019                 &amp;lt;NA&amp;gt; M05iB0D1s5AC
## 20                     0 2019                 &amp;lt;NA&amp;gt; ldfaerwXgEUC
## 21                     0   NA                 &amp;lt;NA&amp;gt; a0OBvERweLwC
## 22                     0   NA                 &amp;lt;NA&amp;gt; 4OULZ7Gr8RgC&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get number of articles
get_num_articles(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Number of different journals published in
get_num_distinct_journals(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Retrieve year of oldest publication
get_oldest_article(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2017&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Number of publications in &amp;quot;top&amp;quot; journals
get_num_top_journals(id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Need a little dose of imposter syndrome today? Dr. Hawking had 497 citations &lt;em&gt;in his first career year&lt;/em&gt;. You can compare scholars based on their &lt;code&gt;id&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare yourself and Stephen Hawking
ids &amp;lt;- c(&amp;#39;g9lY5RUAAAAJ&amp;#39;, &amp;#39;qj74uXkAAAAJ&amp;#39;) 

# Get a data frame comparing the number of citations to their work in
# a given year 
compare_scholars(ids)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              id year cites total            name
## 1  g9lY5RUAAAAJ 2017    28    28    Ian T. Adams
## 2  g9lY5RUAAAAJ 2018     9    37    Ian T. Adams
## 3  g9lY5RUAAAAJ 2019    76   113    Ian T. Adams
## 4  g9lY5RUAAAAJ 2020     7   120    Ian T. Adams
## 5  g9lY5RUAAAAJ   NA     0   120    Ian T. Adams
## 6  qj74uXkAAAAJ 1970  1991  1991 Stephen Hawking
## 7  qj74uXkAAAAJ 1971  1182  3173 Stephen Hawking
## 8  qj74uXkAAAAJ 1972  1393  4566 Stephen Hawking
## 9  qj74uXkAAAAJ 1973 16927 21493 Stephen Hawking
## 10 qj74uXkAAAAJ 1974  6809 28302 Stephen Hawking
## 11 qj74uXkAAAAJ 1976  6502 34804 Stephen Hawking
## 12 qj74uXkAAAAJ 1977  4804 39608 Stephen Hawking
## 13 qj74uXkAAAAJ 1982  2299 41907 Stephen Hawking
## 14 qj74uXkAAAAJ 1983  9915 51822 Stephen Hawking
## 15 qj74uXkAAAAJ 2009  7949 59771 Stephen Hawking
## 16 qj74uXkAAAAJ 2010  3538 63309 Stephen Hawking&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compare their career trajectories, based on year of first citation
compare_scholar_careers(ids)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              id year cites career_year            name
## 1  g9lY5RUAAAAJ 2018     5           0    Ian T. Adams
## 2  g9lY5RUAAAAJ 2019    40           1    Ian T. Adams
## 3  g9lY5RUAAAAJ 2020    73           2    Ian T. Adams
## 4  g9lY5RUAAAAJ 2021     1           3    Ian T. Adams
## 5  qj74uXkAAAAJ 1982   497           0 Stephen Hawking
## 6  qj74uXkAAAAJ 1983   608           1 Stephen Hawking
## 7  qj74uXkAAAAJ 1984   803           2 Stephen Hawking
## 8  qj74uXkAAAAJ 1985   837           3 Stephen Hawking
## 9  qj74uXkAAAAJ 1986   953           4 Stephen Hawking
## 10 qj74uXkAAAAJ 1987   836           5 Stephen Hawking
## 11 qj74uXkAAAAJ 1988   872           6 Stephen Hawking
## 12 qj74uXkAAAAJ 1989  1205           7 Stephen Hawking
## 13 qj74uXkAAAAJ 1990  1145           8 Stephen Hawking
## 14 qj74uXkAAAAJ 1991  1228           9 Stephen Hawking
## 15 qj74uXkAAAAJ 1992  1290          10 Stephen Hawking
## 16 qj74uXkAAAAJ 1993  1612          11 Stephen Hawking
## 17 qj74uXkAAAAJ 1994  1667          12 Stephen Hawking
## 18 qj74uXkAAAAJ 1995  1708          13 Stephen Hawking
## 19 qj74uXkAAAAJ 1996  1764          14 Stephen Hawking
## 20 qj74uXkAAAAJ 1997  1645          15 Stephen Hawking
## 21 qj74uXkAAAAJ 1998  2135          16 Stephen Hawking
## 22 qj74uXkAAAAJ 1999  2160          17 Stephen Hawking
## 23 qj74uXkAAAAJ 2000  2113          18 Stephen Hawking
## 24 qj74uXkAAAAJ 2001  2118          19 Stephen Hawking
## 25 qj74uXkAAAAJ 2002  2386          20 Stephen Hawking
## 26 qj74uXkAAAAJ 2003  2446          21 Stephen Hawking
## 27 qj74uXkAAAAJ 2004  2491          22 Stephen Hawking
## 28 qj74uXkAAAAJ 2005  2751          23 Stephen Hawking
## 29 qj74uXkAAAAJ 2006  2877          24 Stephen Hawking
## 30 qj74uXkAAAAJ 2007  3221          25 Stephen Hawking
## 31 qj74uXkAAAAJ 2008  3444          26 Stephen Hawking
## 32 qj74uXkAAAAJ 2009  3539          27 Stephen Hawking
## 33 qj74uXkAAAAJ 2010  3590          28 Stephen Hawking
## 34 qj74uXkAAAAJ 2011  4096          29 Stephen Hawking
## 35 qj74uXkAAAAJ 2012  4067          30 Stephen Hawking
## 36 qj74uXkAAAAJ 2013  4144          31 Stephen Hawking
## 37 qj74uXkAAAAJ 2014  4627          32 Stephen Hawking
## 38 qj74uXkAAAAJ 2015  4394          33 Stephen Hawking
## 39 qj74uXkAAAAJ 2016  4611          34 Stephen Hawking
## 40 qj74uXkAAAAJ 2017  5023          35 Stephen Hawking
## 41 qj74uXkAAAAJ 2018  5530          36 Stephen Hawking
## 42 qj74uXkAAAAJ 2019  5812          37 Stephen Hawking
## 43 qj74uXkAAAAJ 2020  6206          38 Stephen Hawking
## 44 qj74uXkAAAAJ 2021    96          39 Stephen Hawking&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Want to feel bad about yourself (part 2)? Use the &lt;a href=&#34;https://www.nature.com/nature/articles/489201a&#34;&gt;prediction algorithm from Acuna et al.&lt;/a&gt; to see where you’ll be when you finally land that adjunct position!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Predict h-index of original method author, Daniel Acuna
id &amp;lt;- &amp;#39;g9lY5RUAAAAJ&amp;#39;
predict &amp;lt;- predict_h_index(id)

plot(predict)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/2021-01-11-fun-with-the-scholar-package/index_files/figure-html/predict-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Website migrated</title>
      <link>https://ianadamsresearch.com/post/website-migrated/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/website-migrated/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/website-migrated/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This is a post to breadcrumb the migration of the previous website. Turns out that updating the hugo package, the blogdown package, the academic theme, and installing the Rstudio preview build all in the same day was a good way to blow up the previous iteration.&lt;/p&gt;
&lt;p&gt;Note that because of a change in the file structure under the new &lt;code&gt;hugo&lt;/code&gt;, the image links from previous posts are going to break. When I have the time and interest, I’ll go back and fix.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;The ease with which I can blow up a hugo/academic/blogdown website is equalled only by the utter incompetence I am capable of when trying to fix it.&lt;/p&gt;&amp;mdash; Ian T. Adams (@ian_t_adams) &lt;a href=&#34;https://twitter.com/ian_t_adams/status/1344353682591084544?ref_src=twsrc%5Etfw&#34;&gt;December 30, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
    <item>
      <title>Chapter 3</title>
      <link>https://ianadamsresearch.com/courses/pubpl-6002/chapter-3/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/courses/pubpl-6002/chapter-3/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;One of the wonderful features of the R statistical universe is the number of free, high-quality instructional materials available. Throughout the remainder of the course, we will be learning and working from the R for Data Science book (you’ll see this book shorthanded as R4DS in this course and all over the web), by two giants of the R space: Hadley Wickham and Garrett Grolemund . This is a free book, available here . If you prefer a hardcopy, you can order one from a number of sources as well, including at Amazon.&lt;/p&gt;
&lt;p&gt;As you read through the assigned chapters, the authors have included a variety of practical exercises to introduce you to R, with a focus on the “tidyverse,” a collection of statistical packages that make exploring, analyzing, visualizing, and communicating data a more enjoyable, replicable, and easy-to-learn process. Some of these exercises will be assigned, but we also highly recommend you complete the exercises as you read through the book! These exercises are quite short, and usually have the coded answers built right into the book, so you can copy/paste right into RStudio and see the solution.&lt;/p&gt;
&lt;div id=&#34;data-visualization-exercises&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Visualization Exercises&lt;/h2&gt;
&lt;p&gt;Always remember to load your tidyverse library!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.4     v dplyr   1.0.2
## v tidyr   1.1.2     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-steps&#34; class=&#34;section level2 r4ds-section&#34;&gt;
&lt;h2&gt;First steps&lt;/h2&gt;
&lt;div id=&#34;exercise-3.2.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.2.1&#34;&gt;
&lt;h3&gt;Exercise 3.2.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Run &lt;code&gt;ggplot(data = mpg)&lt;/code&gt; what do you see?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This code creates an empty plot. The &lt;code&gt;ggplot()&lt;/code&gt; function creates the background of the plot, but since no layers were specified with geom function, nothing is drawn.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.2.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.2.2&#34;&gt;
&lt;h3&gt;Exercise 3.2.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;How many rows are in &lt;code&gt;mpg&lt;/code&gt;? How many columns?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;There are 234 rows and 11 columns in the &lt;code&gt;mpg&lt;/code&gt; data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(mpg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 234&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ncol(mpg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;glimpse()&lt;/code&gt; function also displays the number of rows and columns in a data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(mpg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 234
## Columns: 11
## $ manufacturer &amp;lt;chr&amp;gt; &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;...
## $ model        &amp;lt;chr&amp;gt; &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4 quattro&amp;quot;...
## $ displ        &amp;lt;dbl&amp;gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0,...
## $ year         &amp;lt;int&amp;gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, ...
## $ cyl          &amp;lt;int&amp;gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, ...
## $ trans        &amp;lt;chr&amp;gt; &amp;quot;auto(l5)&amp;quot;, &amp;quot;manual(m5)&amp;quot;, &amp;quot;manual(m6)&amp;quot;, &amp;quot;auto(av)&amp;quot;, &amp;quot;a...
## $ drv          &amp;lt;chr&amp;gt; &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;,...
## $ cty          &amp;lt;int&amp;gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17...
## $ hwy          &amp;lt;int&amp;gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25...
## $ fl           &amp;lt;chr&amp;gt; &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;,...
## $ class        &amp;lt;chr&amp;gt; &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;,...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.2.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.2.3&#34;&gt;
&lt;h3&gt;Exercise 3.2.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does the &lt;code&gt;drv&lt;/code&gt; variable describe? Read the help for &lt;code&gt;?mpg&lt;/code&gt; to find out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The &lt;code&gt;drv&lt;/code&gt; variable is a categorical variable which categorizes cars into front-wheels, rear-wheels, or four-wheel drive.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;&#34;f&#34;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Front-wheel_drive&#34;&gt;front-wheel drive&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;&#34;r&#34;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Automobile_layout#Rear-wheel-drive_layouts&#34;&gt;rear-wheel drive&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;&#34;4&#34;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Four-wheel_drive&#34;&gt;four-wheel drive&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.2.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.2.4&#34;&gt;
&lt;h3&gt;Exercise 3.2.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Make a scatter plot of &lt;code&gt;hwy&lt;/code&gt; vs. &lt;code&gt;cyl&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = cyl, y = hwy)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.2.5&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.2.5&#34;&gt;
&lt;h3&gt;Exercise 3.2.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What happens if you make a scatter plot of &lt;code&gt;class&lt;/code&gt; vs &lt;code&gt;drv&lt;/code&gt;? Why is the plot not useful?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The resulting scatterplot has only a few points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = class, y = drv)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A scatter plot is not a useful display of these variables since both &lt;code&gt;drv&lt;/code&gt; and &lt;code&gt;class&lt;/code&gt; are categorical variables. Since categorical variables typically take a small number of values, there are a limited number of unique combinations of (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) values that can be displayed. In this data, &lt;code&gt;drv&lt;/code&gt; takes 3 values and &lt;code&gt;class&lt;/code&gt; takes 7 values, meaning that there are only 21 values that could be plotted on a scatterplot of &lt;code&gt;drv&lt;/code&gt; vs. &lt;code&gt;class&lt;/code&gt;. In this data, there 12 values of (&lt;code&gt;drv&lt;/code&gt;, &lt;code&gt;class&lt;/code&gt;) are observed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;count(mpg, drv, class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 3
##    drv   class          n
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;
##  1 4     compact       12
##  2 4     midsize        3
##  3 4     pickup        33
##  4 4     subcompact     4
##  5 4     suv           51
##  6 f     compact       35
##  7 f     midsize       38
##  8 f     minivan       11
##  9 f     subcompact    22
## 10 r     2seater        5
## 11 r     subcompact     9
## 12 r     suv           11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple scatter plot does not show how many observations there are for each (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) value. As such, scatterplots work best for plotting a continuous x and a continuous y variable, and when all (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) values are unique.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The following code uses functions introduced in a later section. Come back to this after reading section &lt;a href=&#34;https://r4ds.had.co.nz/exploratory-data-analysis.html#two-categorical-variables&#34;&gt;7.5.2&lt;/a&gt;, which introduces methods for plotting two categorical variables. The first is &lt;code&gt;geom_count()&lt;/code&gt; which is similar to a scatterplot but uses the size of the points to show the number of observations at an (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = class, y = drv)) +
  geom_count()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The second is &lt;code&gt;geom_tile()&lt;/code&gt; which uses a color scale to show the number of observations with each (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mpg %&amp;gt;%
  count(class, drv) %&amp;gt;%
  ggplot(aes(x = class, y = drv)) +
    geom_tile(mapping = aes(fill = n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the previous plot, there are many missing tiles. These missing tiles represent unobserved combinations of &lt;code&gt;class&lt;/code&gt; and &lt;code&gt;drv&lt;/code&gt; values. These missing values are not unknown, but represent values of (&lt;code&gt;class&lt;/code&gt;, &lt;code&gt;drv&lt;/code&gt;) where &lt;code&gt;n = 0&lt;/code&gt;. The &lt;code&gt;complete()&lt;/code&gt; function in the tidyr package adds new rows to a data frame for missing combinations of columns. The following code adds rows for missing combinations of &lt;code&gt;class&lt;/code&gt; and &lt;code&gt;drv&lt;/code&gt; and uses the &lt;code&gt;fill&lt;/code&gt; argument to set &lt;code&gt;n = 0&lt;/code&gt; for those new rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mpg %&amp;gt;%
  count(class, drv) %&amp;gt;%
  complete(class, drv, fill = list(n = 0)) %&amp;gt;%
  ggplot(aes(x = class, y = drv)) +
    geom_tile(mapping = aes(fill = n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;aesthetic-mappings&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3.3 Aesthetic mappings&lt;/h1&gt;
&lt;div id=&#34;exercise-3.3.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.1&#34;&gt;
&lt;h3&gt;Exercise 3.3.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What’s gone wrong with this code? Why are the points not blue?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, colour = &amp;quot;blue&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The argument&lt;code&gt;colour = &#34;blue&#34;&lt;/code&gt; is included within the &lt;code&gt;mapping&lt;/code&gt; argument, and as such, it is treated as an aesthetic, which is a mapping between a variable and a value. In the expression, &lt;code&gt;colour = &#34;blue&#34;&lt;/code&gt;, &lt;code&gt;&#34;blue&#34;&lt;/code&gt; is interpreted as a categorical variable which only takes a single value &lt;code&gt;&#34;blue&#34;&lt;/code&gt;. If this is confusing, consider how &lt;code&gt;colour = 1:234&lt;/code&gt; and &lt;code&gt;colour = 1&lt;/code&gt; are interpreted by &lt;code&gt;aes()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The following code does produces the expected result.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy), colour = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.3.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.2&#34;&gt;
&lt;h3&gt;Exercise 3.3.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Which variables in &lt;code&gt;mpg&lt;/code&gt; are categorical? Which variables are continuous? (Hint: type &lt;code&gt;?mpg&lt;/code&gt; to read the documentation for the dataset). How can you see this information when you run &lt;code&gt;mpg&lt;/code&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The following list contains the categorical variables in &lt;code&gt;mpg&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;manufacturer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;drv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following list contains the continuous variables in &lt;code&gt;mpg&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;displ&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;year&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cyl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cty&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hwy&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the printed data frame, angled brackets at the top of each column provide type of each variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mpg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 234 x 11
##    manufacturer model    displ  year   cyl trans   drv     cty   hwy fl    class
##    &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
##  1 audi         a4         1.8  1999     4 auto(l~ f        18    29 p     comp~
##  2 audi         a4         1.8  1999     4 manual~ f        21    29 p     comp~
##  3 audi         a4         2    2008     4 manual~ f        20    31 p     comp~
##  4 audi         a4         2    2008     4 auto(a~ f        21    30 p     comp~
##  5 audi         a4         2.8  1999     6 auto(l~ f        16    26 p     comp~
##  6 audi         a4         2.8  1999     6 manual~ f        18    26 p     comp~
##  7 audi         a4         3.1  2008     6 auto(a~ f        18    27 p     comp~
##  8 audi         a4 quat~   1.8  1999     4 manual~ 4        18    26 p     comp~
##  9 audi         a4 quat~   1.8  1999     4 auto(l~ 4        16    25 p     comp~
## 10 audi         a4 quat~   2    2008     4 manual~ 4        20    28 p     comp~
## # ... with 224 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those with &lt;code&gt;&amp;lt;chr&amp;gt;&lt;/code&gt; above their columns are categorical, while those with &lt;code&gt;&amp;lt;dbl&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;int&amp;gt;&lt;/code&gt; are continuous. The exact meaning of these types will be discussed in &lt;a href=&#34;https://jrnold.github.io/r4ds-exercise-solutions/vectors.html&#34;&gt;“Chapter 15: Vectors”&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;glimpse()&lt;/code&gt; is another function that concisely displays the type of each column in the data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(mpg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 234
## Columns: 11
## $ manufacturer &amp;lt;chr&amp;gt; &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;, &amp;quot;audi&amp;quot;...
## $ model        &amp;lt;chr&amp;gt; &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4&amp;quot;, &amp;quot;a4 quattro&amp;quot;...
## $ displ        &amp;lt;dbl&amp;gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0,...
## $ year         &amp;lt;int&amp;gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, ...
## $ cyl          &amp;lt;int&amp;gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, ...
## $ trans        &amp;lt;chr&amp;gt; &amp;quot;auto(l5)&amp;quot;, &amp;quot;manual(m5)&amp;quot;, &amp;quot;manual(m6)&amp;quot;, &amp;quot;auto(av)&amp;quot;, &amp;quot;a...
## $ drv          &amp;lt;chr&amp;gt; &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;4&amp;quot;,...
## $ cty          &amp;lt;int&amp;gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17...
## $ hwy          &amp;lt;int&amp;gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25...
## $ fl           &amp;lt;chr&amp;gt; &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;, &amp;quot;p&amp;quot;,...
## $ class        &amp;lt;chr&amp;gt; &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;, &amp;quot;compact&amp;quot;,...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those lists, I considered any variable that was non-numeric was considered categorical and any variable that was numeric was considered continuous. This largely corresponds to the heuristics &lt;code&gt;ggplot()&lt;/code&gt; uses for will interpreting variables as discrete or continuous.&lt;/p&gt;
&lt;p&gt;However, this definition of continuous vs. categorical misses several important cases. Of the numeric variables, &lt;code&gt;year&lt;/code&gt; and &lt;code&gt;cyl&lt;/code&gt; (cylinders) clearly take on discrete values. The variables &lt;code&gt;cty&lt;/code&gt; and &lt;code&gt;hwy&lt;/code&gt; are stored as integers (&lt;code&gt;int&lt;/code&gt;) so they only take on a discrete values. Even though &lt;code&gt;displ&lt;/code&gt; has In some sense, due to measurement and computational constraints all numeric variables are discrete (). But unlike the categorical variables, it is possible to add and subtract these numeric variables in a meaningful way. The typology of &lt;a href=&#34;https://en.wikipedia.org/wiki/Level_of_measurement&#34;&gt;levels of measurement&lt;/a&gt; is one such typology of data types.&lt;/p&gt;
&lt;p&gt;In this case the R data types largely encode the semantics of the variables; e.g. integer variables are stored as integers, categorical variables with no order are stored as character vectors and so on. However, that is not always the case. Instead, the data could have stored the categorical &lt;code&gt;class&lt;/code&gt; variable as an integer with values 1–7, where the documentation would note that 1 = “compact”, 2 = “midsize”, and so on.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Even though this integer vector could be added, multiplied, subtracted, and divided, those operations would be meaningless.&lt;/p&gt;
&lt;p&gt;Fundamentally, categorizing variables as “discrete”, “continuous”, “ordinal”, “nominal”, “categorical”, etc. is about specifying what operations can be performed on the variables. Discrete variables support counting and calculating the mode. Variables with an ordering support sorting and calculating quantiles. Variables that have an interval scale support addition and subtraction and operations such as taking the mean that rely on these primitives. In this way, the types of data or variables types is an information class system, something that is beyond the scope of R4DS but discussed in &lt;a href=&#34;http://adv-r.had.co.nz/OO-essentials.html#s3&#34;&gt;&lt;em&gt;Advanced R&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.3.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.3&#34;&gt;
&lt;h3&gt;Exercise 3.3.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The variable &lt;code&gt;cty&lt;/code&gt;, city highway miles per gallon, is a continuous variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, colour = cty)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Instead of using discrete colors, the continuous variable uses a scale that varies from a light to dark blue color.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, size = cty)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When mapped to size, the sizes of the points vary continuously as a function of their size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, shape = cty)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error: A continuous variable can not be mapped to shape&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When a continuous value is mapped to shape, it gives an error. Though we could split a continuous variable into discrete categories and use a shape aesthetic, this would conceptually not make sense. A numeric variable has an order, but shapes do not. It is clear that smaller points correspond to smaller values, or once the color scale is given, which colors correspond to larger or smaller values. But it is not clear whether a square is greater or less than a circle.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.3.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.4&#34;&gt;
&lt;h3&gt;Exercise 3.3.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What happens if you map the same variable to multiple aesthetics?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, colour = hwy, size = displ)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above plot, &lt;code&gt;hwy&lt;/code&gt; is mapped to both location on the y-axis and color, and &lt;code&gt;displ&lt;/code&gt; is mapped to both location on the x-axis and size. The code works and produces a plot, even if it is a bad one. Mapping a single variable to multiple aesthetics is redundant. Because it is redundant information, in most cases avoid mapping a single variable to multiple aesthetics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.3.5&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.5&#34;&gt;
&lt;h3&gt;Exercise 3.3.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does the stroke aesthetic do? What shapes does it work with? (Hint: use &lt;code&gt;?geom_point&lt;/code&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Stroke changes the size of the border for shapes (21-25). These are filled shapes in which the color and size of the border can differ from that of the filled interior of the shape.&lt;/p&gt;
&lt;p&gt;For example&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mtcars, aes(wt, mpg)) +
  geom_point(shape = 21, colour = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;, size = 5, stroke = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex.3.3.1.5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.3.6&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.3.6&#34;&gt;
&lt;h3&gt;Exercise 3.3.6&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What happens if you map an aesthetic to something other than a variable name, like &lt;code&gt;aes(colour = displ &amp;lt; 5)&lt;/code&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, colour = displ &amp;lt; 5)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex.3.3.1.6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Aesthetics can also be mapped to expressions like &lt;code&gt;displ &amp;lt; 5&lt;/code&gt;. The &lt;code&gt;ggplot()&lt;/code&gt; function behaves as if a temporary variable was added to the data with values equal to the result of the expression. In this case, the result of &lt;code&gt;displ &amp;lt; 5&lt;/code&gt; is a logical variable which takes values of &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This also explains why, in &lt;a href=&#34;#exercise-3.3.1&#34;&gt;Exercise 3.3.1&lt;/a&gt;, the expression &lt;code&gt;colour = &#34;blue&#34;&lt;/code&gt; created a categorical variable with only one category: “blue”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;facets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Facets&lt;/h2&gt;
&lt;div id=&#34;exercise-3.5.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.1&#34;&gt;
&lt;h3&gt;Exercise 3.5.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What happens if you facet on a continuous variable?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;Let’s see.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point() +
  facet_grid(. ~ cty)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex.3.5.1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The continuous variable is converted to a categorical variable, and the plot contains a facet for each distinct value.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.5.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.2&#34;&gt;
&lt;h3&gt;Exercise 3.5.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What do the empty cells in plot with &lt;code&gt;facet_grid(drv ~ cyl)&lt;/code&gt; mean? How do they relate to this plot?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = drv, y = cyl))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = hwy, y = cty)) +
  facet_grid(drv ~ cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The empty cells (facets) in this plot are combinations of &lt;code&gt;drv&lt;/code&gt; and &lt;code&gt;cyl&lt;/code&gt; that have no observations. These are the same locations in the scatter plot of &lt;code&gt;drv&lt;/code&gt; and &lt;code&gt;cyl&lt;/code&gt; that have no points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = drv, y = cyl))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.5.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.3&#34;&gt;
&lt;h3&gt;Exercise 3.5.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What plots does the following code make? What does &lt;code&gt;.&lt;/code&gt; do?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The symbol &lt;code&gt;.&lt;/code&gt; ignores that dimension when faceting. For example, &lt;code&gt;drv ~ .&lt;/code&gt; facet by values of &lt;code&gt;drv&lt;/code&gt; on the y-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ .)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex.3.5.1.4.a-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While, &lt;code&gt;. ~ cyl&lt;/code&gt; will facet by values of &lt;code&gt;cyl&lt;/code&gt; on the x-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(. ~ cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex.3.5.1.4.b-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.5.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.4&#34;&gt;
&lt;h3&gt;Exercise 3.5.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Take the first faceted plot in this section:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_wrap(~class, nrow = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;In the following plot the &lt;code&gt;class&lt;/code&gt; variable is mapped to color.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = class))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Advantages of encoding &lt;code&gt;class&lt;/code&gt; with facets instead of color include the ability to encode more distinct categories. For me, it is difficult to distinguish between the colors of &lt;code&gt;&#34;midsize&#34;&lt;/code&gt; and &lt;code&gt;&#34;minivan&#34;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Given human visual perception, the max number of colors to use when encoding unordered categorical (qualitative) data is nine, and in practice, often much less than that. Displaying observations from different categories on different scales makes it difficult to directly compare values of observations across categories. However, it can make it easier to compare the shape of the relationship between the x and y variables across categories.&lt;/p&gt;
&lt;p&gt;Disadvantages of encoding the &lt;code&gt;class&lt;/code&gt; variable with facets instead of the color aesthetic include the difficulty of comparing the values of observations between categories since the observations for each category are on different plots. Using the same x- and y-scales for all facets makes it easier to compare values of observations across categories, but it is still more difficult than if they had been displayed on the same plot. Since encoding class within color also places all points on the same plot, it visualizes the unconditional relationship between the x and y variables; with facets, the unconditional relationship is no longer visualized since the points are spread across multiple plots.&lt;/p&gt;
&lt;p&gt;The benefit of encoding a variable with facetting over encoding it with color increase in both the number of points and the number of categories. With a large number of points, there is often overlap. It is difficult to handle overlapping points with different colors color. Jittering will still work with color. But jittering will only work well if there are few points and the classes do not overlap much, otherwise, the colors of areas will no longer be distinct, and it will be hard to pick out the patterns of different categories visually. Transparency (&lt;code&gt;alpha&lt;/code&gt;) does not work well with colors since the mixing of overlapping transparent colors will no longer represent the colors of the categories. Binning methods already use color to encode the density of points in the bin, so color cannot be used to encode categories.&lt;/p&gt;
&lt;p&gt;As the number of categories increases, the difference between colors decreases, to the point that the color of categories will no longer be visually distinct.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.5.5&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.5&#34;&gt;
&lt;h3&gt;Exercise 3.5.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Read &lt;code&gt;?facet_wrap&lt;/code&gt;. What does &lt;code&gt;nrow&lt;/code&gt; do? What does &lt;code&gt;ncol&lt;/code&gt; do? What other options control the layout of the individual panels? Why doesn’t &lt;code&gt;facet_grid()&lt;/code&gt; have &lt;code&gt;nrow&lt;/code&gt; and &lt;code&gt;ncol&lt;/code&gt; variables?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The arguments &lt;code&gt;nrow&lt;/code&gt; (&lt;code&gt;ncol&lt;/code&gt;) determines the number of rows (columns) to use when laying out the facets. It is necessary since &lt;code&gt;facet_wrap()&lt;/code&gt; only facets on one variable.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;nrow&lt;/code&gt; and &lt;code&gt;ncol&lt;/code&gt; arguments are unnecessary for &lt;code&gt;facet_grid()&lt;/code&gt; since the number of unique values of the variables specified in the function determines the number of rows and columns.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.5.6&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.5.6&#34;&gt;
&lt;h3&gt;Exercise 3.5.6&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;When using &lt;code&gt;facet_grid()&lt;/code&gt; you should usually put the variable with more unique levels in the columns. Why?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;There will be more space for columns if the plot is laid out horizontally (landscape).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;geometric-objects&#34; class=&#34;section level2 r4ds-section&#34;&gt;
&lt;h2&gt;Geometric objects&lt;/h2&gt;
&lt;div id=&#34;exercise-3.6.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.1&#34;&gt;
&lt;h3&gt;Exercise 3.6.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What geom would you use to draw a line chart? A boxplot? A histogram? An area chart?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;ul&gt;
&lt;li&gt;line chart: &lt;code&gt;geom_line()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;boxplot: &lt;code&gt;geom_boxplot()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;histogram: &lt;code&gt;geom_histogram()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;area chart: &lt;code&gt;geom_area()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.6.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.2&#34;&gt;
&lt;h3&gt;Exercise 3.6.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/ex-3-6-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;This code produces a scatter plot with &lt;code&gt;displ&lt;/code&gt; on the x-axis, &lt;code&gt;hwy&lt;/code&gt; on the y-axis, and the points colored by &lt;code&gt;drv&lt;/code&gt;. There will be a smooth line, without standard errors, fit through each &lt;code&gt;drv&lt;/code&gt; group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.6.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.3&#34;&gt;
&lt;h3&gt;Exercise 3.6.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does &lt;code&gt;show.legend = FALSE&lt;/code&gt; do? What happens if you remove it? Why do you think I used it earlier in the chapter?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The theme option &lt;code&gt;show.legend = FALSE&lt;/code&gt; hides the legend box.&lt;/p&gt;
&lt;p&gt;Consider this example earlier in the chapter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_smooth(
    mapping = aes(x = displ, y = hwy, colour = drv),
    show.legend = FALSE
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In that plot, there is no legend. Removing the &lt;code&gt;show.legend&lt;/code&gt; argument or setting &lt;code&gt;show.legend = TRUE&lt;/code&gt; will result in the plot having a legend displaying the mapping between colors and &lt;code&gt;drv&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, colour = drv))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the chapter, the legend is suppressed because with three plots, adding a legend to only the last plot would make the sizes of plots different. Different sized plots would make it more difficult to see how arguments change the appearance of the plots. The purpose of those plots is to show the difference between no groups, using a &lt;code&gt;group&lt;/code&gt; aesthetic, and using a &lt;code&gt;color&lt;/code&gt; aesthetic, which creates implicit groups. In that example, the legend isn’t necessary since looking up the values associated with each color isn’t necessary to make that point.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.6.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.4&#34;&gt;
&lt;h3&gt;Exercise 3.6.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does the &lt;code&gt;se&lt;/code&gt; argument to &lt;code&gt;geom_smooth()&lt;/code&gt; do?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;It adds standard error bands to the lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth(se = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default &lt;code&gt;se = TRUE&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.6.5&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.5&#34;&gt;
&lt;h3&gt;Exercise 3.6.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Will these two graphs look different? Why/why not?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point() +
  geom_smooth()

ggplot() +
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;No. Because both &lt;code&gt;geom_point()&lt;/code&gt; and &lt;code&gt;geom_smooth()&lt;/code&gt; will use the same data and mappings. They will inherit those options from the &lt;code&gt;ggplot()&lt;/code&gt; object, so the mappings don’t need to specified again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point() +
  geom_smooth()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.6.6&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.6.6&#34;&gt;
&lt;h3&gt;Exercise 3.6.6&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Recreate the R code necessary to generate the following graphs.&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;insert the figures from the book later&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The following code will generate those plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point() +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(group = drv), se = FALSE) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point(aes(colour = drv)) +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point(aes(colour = drv)) +
  geom_smooth(aes(linetype = drv), se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-36-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point(size = 4, color = &amp;quot;white&amp;quot;) +
  geom_point(aes(colour = drv))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;statistical-transformations&#34; class=&#34;section level2 r4ds-section&#34;&gt;
&lt;h2&gt;Statistical transformations&lt;/h2&gt;
&lt;div id=&#34;exercise-3.7.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.7.1&#34;&gt;
&lt;h3&gt;Exercise 3.7.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What is the default geom associated with &lt;code&gt;stat_summary()&lt;/code&gt;? How could you rewrite the previous plot to use that geom function instead of the stat function?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The “previous plot” referred to in the question is the following.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The arguments &lt;code&gt;fun.ymin&lt;/code&gt;, &lt;code&gt;fun.ymax&lt;/code&gt;, and &lt;code&gt;fun.y&lt;/code&gt; have been deprecated and replaced with &lt;code&gt;fun.min&lt;/code&gt;, &lt;code&gt;fun.max&lt;/code&gt;, and &lt;code&gt;fun&lt;/code&gt; in ggplot2 v 3.3.0.&lt;/p&gt;
&lt;p&gt;The default geom for &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/stat_summary.html&#34;&gt;&lt;code&gt;stat_summary()&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;geom_pointrange()&lt;/code&gt;. The default stat for &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/geom_linerange.html&#34;&gt;&lt;code&gt;geom_pointrange()&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;identity()&lt;/code&gt; but we can add the argument &lt;code&gt;stat = &#34;summary&#34;&lt;/code&gt; to use &lt;code&gt;stat_summary()&lt;/code&gt; instead of &lt;code&gt;stat_identity()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_pointrange(
    mapping = aes(x = cut, y = depth),
    stat = &amp;quot;summary&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No summary function supplied, defaulting to `mean_se()`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The resulting message says that &lt;code&gt;stat_summary()&lt;/code&gt; uses the &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;sd&lt;/code&gt; to calculate the middle point and endpoints of the line. However, in the original plot the min and max values were used for the endpoints. To recreate the original plot we need to specify values for &lt;code&gt;fun.min&lt;/code&gt;, &lt;code&gt;fun.max&lt;/code&gt;, and &lt;code&gt;fun&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_pointrange(
    mapping = aes(x = cut, y = depth),
    stat = &amp;quot;summary&amp;quot;,
    fun.min = min,
    fun.max = max,
    fun = median
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.7.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.7.2&#34;&gt;
&lt;h3&gt;Exercise 3.7.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does &lt;code&gt;geom_col()&lt;/code&gt; do? How is it different to &lt;code&gt;geom_bar()&lt;/code&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The &lt;code&gt;geom_col()&lt;/code&gt; function has different default stat than &lt;code&gt;geom_bar()&lt;/code&gt;. The default stat of &lt;code&gt;geom_col()&lt;/code&gt; is &lt;code&gt;stat_identity()&lt;/code&gt;, which leaves the data as is. The &lt;code&gt;geom_col()&lt;/code&gt; function expects that the data contains &lt;code&gt;x&lt;/code&gt; values and &lt;code&gt;y&lt;/code&gt; values which represent the bar height.&lt;/p&gt;
&lt;p&gt;The default stat of &lt;code&gt;geom_bar()&lt;/code&gt; is &lt;code&gt;stat_count()&lt;/code&gt;. The &lt;code&gt;geom_bar()&lt;/code&gt; function only expects an &lt;code&gt;x&lt;/code&gt; variable. The stat, &lt;code&gt;stat_count()&lt;/code&gt;, preprocesses input data by counting the number of observations for each value of &lt;code&gt;x&lt;/code&gt;. The &lt;code&gt;y&lt;/code&gt; aesthetic uses the values of these counts.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.7.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.7.3&#34;&gt;
&lt;h3&gt;Exercise 3.7.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The following tables lists the pairs of geoms and stats that are almost always used in concert.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;Complementary geoms and stats&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;geom&lt;/th&gt;
&lt;th&gt;stat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_bar()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_count()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_bin2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_bin_2d()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_contour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_contour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_contour()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_contour()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_count()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_sum()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_density()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_density()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_dotplot()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_bindot()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_function()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_function()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_sf()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_sf()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_sf()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_sf()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_violin()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_ydensity()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_bin_hex()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_qq_line()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_qq_line()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_qq()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_qq()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;geom_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;stat_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These pairs of geoms and stats tend to have their names in common, such &lt;code&gt;stat_smooth()&lt;/code&gt; and &lt;code&gt;geom_smooth()&lt;/code&gt; and be documented on the same help page. The pairs of geoms and stats that are used in concert often have each other as the default stat (for a geom) or geom (for a stat).&lt;/p&gt;
&lt;p&gt;The following tables contain the geoms and stats in &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/&#34;&gt;ggplot2&lt;/a&gt; and their defaults as of version 3.3.0. Many geoms have &lt;code&gt;stat_identity()&lt;/code&gt; as the default stat.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;ggplot2 geom layers and their default stats.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;geom&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;default stat&lt;/th&gt;
&lt;th&gt;shared docs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_abline()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_area()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_bar()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_count()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_bin2d()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_blank()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_col()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_count()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sum()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_countour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_countour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_countour()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_countour()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_crossbar()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_curve()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_density_2d_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density_2d_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_density()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_dotplot()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bindot()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_errorbar()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_errorbarh()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_freqpoly()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_function()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_function()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_histogram()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_hline()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_jitter()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_label()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_line()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_linerange()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_map()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_path()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_pointrange()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_polygon()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_qq_line()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_qq_line()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_qq()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_qq()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_raster()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_rect()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_ribbon()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_rug()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_segment()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_sf_label()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sf_coordinates()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_sf_text()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sf_coordinates()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_sf()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sf()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_spoke()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_step()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_text()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_tile()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_violin()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_ydensity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_vline()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;caption&gt;ggplot2 stat layers and their default geoms.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;stat&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;default geom&lt;/th&gt;
&lt;th&gt;shared docs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_tile()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_bin()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_bar()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_boxplot()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_count()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_bar()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_countour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_contour_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_countour()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_contour()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density_2d_filled()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_density_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_density()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_area()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_ecdf()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_step()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_ellipse()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_path()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_function()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_function()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_function()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_path()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_identity()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_qq_line()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_path()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_qq()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_quantile()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sf_coordinates()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sf()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_rect()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_smooth()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_sum()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_summary_2d()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_tile()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_summary_bin()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_pointrange()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_summary_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_hex()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_summary()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_pointrange()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_unique()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_point()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;stat_ydensity()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;geom_violin()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.7.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.7.4&#34;&gt;
&lt;h3&gt;Exercise 3.7.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What variables does &lt;code&gt;stat_smooth()&lt;/code&gt; compute? What parameters control its behavior?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The function &lt;code&gt;stat_smooth()&lt;/code&gt; calculates the following variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt;: predicted value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ymin&lt;/code&gt;: lower value of the confidence interval&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ymax&lt;/code&gt;: upper value of the confidence interval&lt;/li&gt;
&lt;li&gt;&lt;code&gt;se&lt;/code&gt;: standard error&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The “Computed Variables” section of the &lt;code&gt;stat_smooth()&lt;/code&gt; documentation contains these variables.&lt;/p&gt;
&lt;p&gt;The parameters that control the behavior of &lt;code&gt;stat_smooth()&lt;/code&gt; include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;method&lt;/code&gt;: This is the method used to compute the smoothing line. If &lt;code&gt;NULL&lt;/code&gt;, a default method is used based on the sample size: &lt;code&gt;stats::loess()&lt;/code&gt; when there are less than 1,000 observations in a group, and &lt;code&gt;mgcv::gam()&lt;/code&gt; with &lt;code&gt;formula = y ~ s(x, bs = &#34;CS)&lt;/code&gt; otherwise. Alternatively, the user can provide a character vector with a function name, e.g. &lt;code&gt;&#34;lm&#34;&lt;/code&gt;, &lt;code&gt;&#34;loess&#34;&lt;/code&gt;, or a function, e.g. &lt;code&gt;MASS::rlm&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;formula&lt;/code&gt;: When providing a custom &lt;code&gt;method&lt;/code&gt; argument, the formula to use. The default is &lt;code&gt;y ~ x&lt;/code&gt;. For example, to use the line implied by &lt;code&gt;lm(y ~ x + I(x ^ 2) + I(x ^ 3))&lt;/code&gt;, use &lt;code&gt;method = &#34;lm&#34;&lt;/code&gt; or &lt;code&gt;method = lm&lt;/code&gt; and &lt;code&gt;formula = y ~ x + I(x ^ 2) + I(x ^ 3)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;method.arg()&lt;/code&gt;: Arguments other than than the formula, which is already specified in the &lt;code&gt;formula&lt;/code&gt; argument&lt;code&gt;, to pass to the function in&lt;/code&gt;method`.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;se&lt;/code&gt;: If &lt;code&gt;TRUE&lt;/code&gt;, display standard error bands, if &lt;code&gt;FALSE&lt;/code&gt; only display the line.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;na.rm&lt;/code&gt;: If &lt;code&gt;FALSE&lt;/code&gt;, missing values are removed with a warning, if &lt;code&gt;TRUE&lt;/code&gt; the are silently removed. The default is &lt;code&gt;FALSE&lt;/code&gt; in order to make debugging easier. If missing values are known to be in the data, then can be ignored, but if missing values are not anticipated this warning can help catch errors.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TODO:&lt;/strong&gt; Plots with examples illustrating the uses of these arguments.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.7.5&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.7.5&#34;&gt;
&lt;h3&gt;Exercise 3.7.5&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;In our proportion bar chart, we need to set &lt;code&gt;group = 1&lt;/code&gt; Why? In other words, what is the problem with these two graphs?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;If &lt;code&gt;group = 1&lt;/code&gt; is not included, then all the bars in the plot will have the same height, a height of 1. The function &lt;code&gt;geom_bar()&lt;/code&gt; assumes that the groups are equal to the &lt;code&gt;x&lt;/code&gt; values since the stat computes the counts within the group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut, y = ..prop..))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-41-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The problem with these two plots is that the proportions are calculated within the groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut, y = ..prop..))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-42-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-42-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The following code will produce the intended stacked bar charts for the case with no &lt;code&gt;fill&lt;/code&gt; aesthetic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With the &lt;code&gt;fill&lt;/code&gt; aesthetic, the heights of the bars need to be normalized.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = diamonds) + 
  geom_bar(aes(x = cut, y = ..count.. / sum(..count..), fill = color))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-44-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;position-adjustments&#34; class=&#34;section level2 r4ds-section&#34;&gt;
&lt;h2&gt;Position adjustments&lt;/h2&gt;
&lt;div id=&#34;exercise-3.8.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.8.1&#34;&gt;
&lt;h3&gt;Exercise 3.8.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What is the problem with this plot? How could you improve it?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-45-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;There is overplotting because there are multiple observations for each combination of &lt;code&gt;cty&lt;/code&gt; and &lt;code&gt;hwy&lt;/code&gt; values.&lt;/p&gt;
&lt;p&gt;I would improve the plot by using a jitter position adjustment to decrease overplotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point(position = &amp;quot;jitter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-46-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The relationship between &lt;code&gt;cty&lt;/code&gt; and &lt;code&gt;hwy&lt;/code&gt; is clear even without jittering the points but jittering shows the locations where there are more observations.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.8.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.8.2&#34;&gt;
&lt;h3&gt;Exercise 3.8.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What parameters to &lt;code&gt;geom_jitter()&lt;/code&gt; control the amount of jittering?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;From the &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/geom_jitter.html&#34;&gt;&lt;code&gt;geom_jitter()&lt;/code&gt;&lt;/a&gt; documentation, there are two arguments to jitter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;width&lt;/code&gt; controls the amount of horizontal displacement, and&lt;/li&gt;
&lt;li&gt;&lt;code&gt;height&lt;/code&gt; controls the amount of vertical displacement.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The defaults values of &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; will introduce noise in both directions. Here is what the plot looks like with the default values of &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point(position = position_jitter())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, we can change these parameters. Here are few a examples to understand how these parameters affect the amount of jittering. When&lt;code&gt;width = 0&lt;/code&gt; there is no horizontal jitter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter(width = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-48-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;width = 20&lt;/code&gt;, there is too much horizontal jitter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter(width = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;height = 0&lt;/code&gt;, there is no vertical jitter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter(height = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-50-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;height = 15&lt;/code&gt;, there is too much vertical jitter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter(height = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-51-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;width = 0&lt;/code&gt; and &lt;code&gt;height = 0&lt;/code&gt;, there is neither horizontal or vertical jitter, and the plot produced is identical to the one produced with &lt;code&gt;geom_point()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter(height = 0, width = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-52-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that the &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; arguments are in the units of the data. Thus &lt;code&gt;height = 1&lt;/code&gt; (&lt;code&gt;width = 1&lt;/code&gt;) corresponds to different relative amounts of jittering depending on the scale of the &lt;code&gt;y&lt;/code&gt; (&lt;code&gt;x&lt;/code&gt;) variable. The default values of &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; are defined to be 80% of the &lt;code&gt;resolution()&lt;/code&gt; of the data, which is the smallest non-zero distance between adjacent values of a variable. When &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are discrete variables, their resolutions are both equal to 1, and &lt;code&gt;height = 0.4&lt;/code&gt; and &lt;code&gt;width = 0.4&lt;/code&gt; since the jitter moves points in both positive and negative directions.&lt;/p&gt;
&lt;p&gt;The default values of &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; in &lt;code&gt;geom_jitter()&lt;/code&gt; are non-zero, so unless both &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; are explicitly set set 0, there will be some jitter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-53-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.8.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.8.3&#34;&gt;
&lt;h3&gt;Exercise 3.8.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Compare and contrast &lt;code&gt;geom_jitter()&lt;/code&gt; with &lt;code&gt;geom_count()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The geom &lt;code&gt;geom_jitter()&lt;/code&gt; adds random variation to the locations points of the graph. In other words, it “jitters” the locations of points slightly. This method reduces overplotting since two points with the same location are unlikely to have the same random variation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-54-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, the reduction in overlapping comes at the cost of slightly changing the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; values of the points.&lt;/p&gt;
&lt;p&gt;The geom &lt;code&gt;geom_count()&lt;/code&gt; sizes the points relative to the number of observations. Combinations of (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;) values with more observations will be larger than those with fewer observations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_count()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-55-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;geom_count()&lt;/code&gt; geom does not change &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; coordinates of the points. However, if the points are close together and counts are large, the size of some points can itself create overplotting. For example, in the following example, a third variable mapped to color is added to the plot. In this case, &lt;code&gt;geom_count()&lt;/code&gt; is less readable than &lt;code&gt;geom_jitter()&lt;/code&gt; when adding a third variable as a color aesthetic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = class)) +
  geom_jitter()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-56-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = class)) +
  geom_count()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-57-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Combining &lt;code&gt;geom_count()&lt;/code&gt; with jitter, which is specified with the &lt;code&gt;position&lt;/code&gt; argument to &lt;code&gt;geom_count()&lt;/code&gt; rather than its own geom, helps overplotting a little.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = class)) +
  geom_count(position = &amp;quot;jitter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-58-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But as this example shows, unfortunately, there is no universal solution to overplotting. The costs and benefits of different approaches will depend on the structure of the data and the goal of the data scientist.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.8.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.8.4&#34;&gt;
&lt;h3&gt;Exercise 3.8.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What’s the default position adjustment for &lt;code&gt;geom_boxplot()&lt;/code&gt;? Create a visualization of the &lt;code&gt;mpg&lt;/code&gt; dataset that demonstrates it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The default position for &lt;code&gt;geom_boxplot()&lt;/code&gt; is &lt;code&gt;&#34;dodge2&#34;&lt;/code&gt;, which is a shortcut for &lt;code&gt;position_dodge2&lt;/code&gt;. This position adjustment does not change the vertical position of a geom but moves the geom horizontally to avoid overlapping other geoms. See the documentation for &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/position_dodge.html&#34;&gt;&lt;code&gt;position_dodge2()&lt;/code&gt;&lt;/a&gt; for additional discussion on how it works.&lt;/p&gt;
&lt;p&gt;When we add &lt;code&gt;colour = class&lt;/code&gt; to the box plot, the different levels of the &lt;code&gt;drv&lt;/code&gt; variable are placed side by side, i.e., dodged.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, aes(x = drv, y = hwy, colour = class)) +
  geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-59-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If &lt;code&gt;position_identity()&lt;/code&gt; is used the boxplots overlap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, aes(x = drv, y = hwy, colour = class)) +
  geom_boxplot(position = &amp;quot;identity&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-60-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coordinate-systems&#34; class=&#34;section level2 r4ds-section&#34;&gt;
&lt;h2&gt;Coordinate systems&lt;/h2&gt;
&lt;div id=&#34;exercise-3.9.1&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.9.1&#34;&gt;
&lt;h3&gt;Exercise 3.9.1&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;Turn a stacked bar chart into a pie chart using &lt;code&gt;coord_polar()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;A pie chart is a stacked bar chart with the addition of polar coordinates. Take this stacked bar chart with a single category.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = factor(1), fill = drv)) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-61-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now add &lt;code&gt;coord_polar(theta=&#34;y&#34;)&lt;/code&gt; to create pie chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = factor(1), fill = drv)) +
  geom_bar(width = 1) +
  coord_polar(theta = &amp;quot;y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-62-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The argument &lt;code&gt;theta = &#34;y&#34;&lt;/code&gt; maps &lt;code&gt;y&lt;/code&gt; to the angle of each section. If &lt;code&gt;coord_polar()&lt;/code&gt; is specified without &lt;code&gt;theta = &#34;y&#34;&lt;/code&gt;, then the resulting plot is called a bulls-eye chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(x = factor(1), fill = drv)) +
  geom_bar(width = 1) +
  coord_polar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-63-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.9.2&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.9.2&#34;&gt;
&lt;h3&gt;Exercise 3.9.2&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does &lt;code&gt;labs()&lt;/code&gt; do? Read the documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The &lt;code&gt;labs&lt;/code&gt; function adds axis titles, plot titles, and a caption to the plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  geom_boxplot() +
  coord_flip() +
  labs(y = &amp;quot;Highway MPG&amp;quot;,
       x = &amp;quot;Class&amp;quot;,
       title = &amp;quot;Highway MPG by car class&amp;quot;,
       subtitle = &amp;quot;1999-2008&amp;quot;,
       caption = &amp;quot;Source: http://fueleconomy.gov&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-64-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The arguments to &lt;code&gt;labs()&lt;/code&gt; are optional, so you can add as many or as few of these as are needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  geom_boxplot() +
  coord_flip() +
  labs(y = &amp;quot;Highway MPG&amp;quot;,
       x = &amp;quot;Year&amp;quot;,
       title = &amp;quot;Highway MPG by car class&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-65-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;labs()&lt;/code&gt; function is not the only function that adds titles to plots. The &lt;code&gt;xlab()&lt;/code&gt;, &lt;code&gt;ylab()&lt;/code&gt;, and x- and y-scale functions can add axis titles. The &lt;code&gt;ggtitle()&lt;/code&gt; function adds plot titles.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.9.3&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.9.3&#34;&gt;
&lt;h3&gt;Exercise 3.9.3&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What’s the difference between &lt;code&gt;coord_quickmap()&lt;/code&gt; and &lt;code&gt;coord_map()&lt;/code&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The &lt;code&gt;coord_map()&lt;/code&gt; function uses map projections to project the three-dimensional Earth onto a two-dimensional plane. By default, &lt;code&gt;coord_map()&lt;/code&gt; uses the &lt;a href=&#34;https://en.wikipedia.org/wiki/Mercator_projection&#34;&gt;Mercator projection&lt;/a&gt;. This projection is applied to all the geoms in the plot. The &lt;code&gt;coord_quickmap()&lt;/code&gt; function uses an approximate but faster map projection. This approximation ignores the curvature of Earth and adjusts the map for the latitude/longitude ratio. The &lt;code&gt;coord_quickmap()&lt;/code&gt; project is faster than &lt;code&gt;coord_map()&lt;/code&gt; both because the projection is computationally easier, and unlike &lt;code&gt;coord_map()&lt;/code&gt;, the coordinates of the individual geoms do not need to be transformed.&lt;/p&gt;
&lt;p&gt;See the &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/coord_map.html&#34;&gt;coord_map()&lt;/a&gt; documentation for more information on these functions and some examples.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-3.9.4&#34; class=&#34;section level3 unnumbered exercise&#34; data-number=&#34;3.9.4&#34;&gt;
&lt;h3&gt;Exercise 3.9.4&lt;/h3&gt;
&lt;div class=&#34;question&#34;&gt;
&lt;p&gt;What does the plot below tell you about the relationship between city and highway mpg? Why is &lt;code&gt;coord_fixed()&lt;/code&gt; important? What does &lt;code&gt;geom_abline()&lt;/code&gt; do?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;answer&#34;&gt;
&lt;p&gt;The function &lt;code&gt;coord_fixed()&lt;/code&gt; ensures that the line produced by &lt;code&gt;geom_abline()&lt;/code&gt; is at a 45-degree angle. A 45-degree line makes it easy to compare the highway and city mileage to the case in which city and highway MPG were equal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point() +
  geom_abline()
p + coord_fixed()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-66-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we didn’t include &lt;code&gt;coord_fixed()&lt;/code&gt;, then the line would no longer have an angle of 45 degrees.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/courses/PUBPL-6002/2020-12-28-chapter-3/index.en_files/figure-html/unnamed-chunk-67-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;On average, humans are best able to perceive differences in angles relative to 45 degrees. See &lt;span class=&#34;citation&#34;&gt;@Cleveland1993&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;@Cleveland1994&lt;/span&gt;,&lt;span class=&#34;citation&#34;&gt;@Cleveland1993a&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;@ClevelandMcGillMcGill1988&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;@HeerAgrawala2006&lt;/span&gt; for discussion on how the aspect ratio of a plot affects perception of the values it encodes, evidence that 45-degrees is generally the optimal aspect ratio, and methods to calculate the optimal aspect ratio of a plot. The function &lt;code&gt;ggthemes::bank_slopes()&lt;/code&gt; will calculate the optimal aspect ratio to bank slopes to 45-degrees.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Internally, this is what the &lt;code&gt;factor&lt;/code&gt; class, which is covered in &lt;a href=&#34;https://r4ds.had.co.nz/factors.html&#34;&gt;Chapter 15&lt;/a&gt;, does.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Intro and Setup Materials</title>
      <link>https://ianadamsresearch.com/courses/pubpl-6002/intro-and-setup-materials/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/courses/pubpl-6002/intro-and-setup-materials/</guid>
      <description>&lt;p&gt;If you are still not sure how to get started with R, Rstudio, and tidyverse, see if the following information helps. It was written by &lt;a href=&#34;https://jennybryan.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Jennifer (Jenny) Bryan&lt;/a&gt; for her &lt;a href=&#34;https://stat545.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;STAT 545 class&lt;/a&gt;, and in addition to the following start-up information, you may want to bookmark her class page as a reference throughout the rest of the semester!&lt;/p&gt;
&lt;h2 id=&#34;r-and-rstudio&#34;&gt;R and RStudio&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;a href=&#34;https://www.r-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R, a free software environment for statistical computing and graphics&lt;/a&gt; from &lt;a href=&#34;https://cran.r-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;, the Comprehensive R Archive Network. I &lt;strong&gt;highly recommend&lt;/strong&gt; you install a precompiled binary distribution for your operating system &amp;ndash; use the links up at the top of the CRAN page linked above!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install RStudio&amp;rsquo;s IDE (stands for &lt;em&gt;integrated development environment&lt;/em&gt;), a powerful user interface for R. Get the Open Source Edition of RStudio Desktop.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I &lt;strong&gt;highly recommend&lt;/strong&gt; you run the &lt;a href=&#34;https://rstudio.com/products/rstudio/download/preview/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Preview version&lt;/a&gt;. I find these quite stable and you&amp;rsquo;ll get the cool new features! Update to new Preview versions often.&lt;/li&gt;
&lt;li&gt;Of course, there are also official releases available &lt;a href=&#34;https://rstudio.com/products/rstudio/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;RStudio comes with a &lt;strong&gt;text editor&lt;/strong&gt;, so there is no immediate need to install a separate stand-alone editor.&lt;/li&gt;
&lt;li&gt;RStudio can &lt;strong&gt;interface with Git(Hub)&lt;/strong&gt;. However, you must do all the Git(Hub) set up [described elsewhere][https://happygitwithr.com/] before you can take advantage of this.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you have a pre-existing installation of R and/or RStudio, we &lt;strong&gt;highly recommend&lt;/strong&gt; that you reinstall both and get as current as possible. It can be considerably harder to run old software than new.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you upgrade R, you will need to update any packages you have installed. The command below should get you started, though you may need to specify more arguments if, e.g., you have been using a non-default library for your packages.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;update.packages(ask = FALSE, checkBuilt = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; this will only look for updates on CRAN. So if you use a package that lives &lt;em&gt;only&lt;/em&gt; on GitHub or if you want a development version from GitHub, you will need to  update manually, e.g. via &lt;code&gt;devtools::install_github()&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-testing&#34;&gt;Testing testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Do whatever is appropriate for your OS to launch RStudio. You should get a window similar to the screenshot you see &lt;a href=&#34;https://d33wubrfki0l68.cloudfront.net/baf6318c88cf5c4052fe84246c78b556b0e19885/ff5d5/wp-content/uploads/2014/04/rstudio-ubuntu.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, but yours will be more boring because you haven&amp;rsquo;t written any code or made any figures yet!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Put your cursor in the pane labelled Console, which is where you interact with the live R process. Create a simple object with code like &lt;code&gt;x &amp;lt;- 2 * 4&lt;/code&gt; (followed by enter or return). Then inspect the &lt;code&gt;x&lt;/code&gt; object by typing &lt;code&gt;x&lt;/code&gt; followed by enter or return. You should see the value 8 print to screen. If yes, you&amp;rsquo;ve succeeded in installing R and RStudio.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;add-on-packages&#34;&gt;Add-on packages&lt;/h2&gt;
&lt;p&gt;R is an extensible system and many people share useful code they have developed as a &lt;em&gt;package&lt;/em&gt; via CRAN and GitHub. To install a package from CRAN, for example the &lt;a href=&#34;https://cran.r-project.org/web/packages/dplyr/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dplyr&lt;/a&gt; package for data manipulation, here is one way to do it in the R console (there are others).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;dplyr&amp;quot;, dependencies = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By including &lt;code&gt;dependencies = TRUE&lt;/code&gt;, we are being explicit and extra-careful to install any additional packages the target package, dplyr in the example above, needs to have around.&lt;/p&gt;
&lt;p&gt;You could use the above method to install the following packages, all of which we will use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tidyr.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tidyr package webpage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ggplot2-book.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ggplot2 package webpage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that if you install the tidyverse, it includes many of the other packages above!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#39;tidyverse&#39;, dependencies = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;
&lt;p&gt;The above will get your basic setup ready but here are some links if you are interested in reading a bit further.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://support.rstudio.com/hc/en-us&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to Use RStudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/200552336-Getting-Help-with-R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RStudio&amp;rsquo;s leads for learning R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/doc/FAQ/R-FAQ.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/doc/manuals/r-release/R-admin.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R Installation and Administration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Add_002don-packages&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;More about add-on packages in the R Installation and Administration Manual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SPSS Cheat Sheet</title>
      <link>https://ianadamsresearch.com/courses/pubpl-6002/spss-cheat/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/courses/pubpl-6002/spss-cheat/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/courses/pubpl-6002/spss-cheat/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;div id=&#34;spss-cheat-sheet&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;SPSS Cheat Sheet&lt;/h1&gt;
&lt;p&gt;This contains some of the most common SPSS procedures for basic data analysis.&lt;/p&gt;
&lt;div id=&#34;data-cleaning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Cleaning&lt;/h2&gt;
&lt;div id=&#34;missing-data-counts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Missing Data Counts&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyse&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptive Statistics&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Frequencies&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the variable(s)&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Continue&lt;/code&gt; and then &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Missing data counts will be at the top of the resulting output.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;edit-variable-name&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Edit Variable Name&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Transform&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Recode into Same Variables...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the variable to transform and move it into the right column.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Old and New Values...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Under &lt;code&gt;Old Value&lt;/code&gt;, enter either a specific value you would like to replace or a set of values you would
like to replace.&lt;/li&gt;
&lt;li&gt;Under &lt;code&gt;New Value&lt;/code&gt;, enter what the replacement value should be.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Add&lt;/code&gt; under &lt;code&gt;New Value&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Continue&lt;/code&gt; and then &lt;code&gt;OK&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create a Variable&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Transform&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Compute Variable...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Type and Label...&lt;/code&gt; to set the variable type, then click &lt;code&gt;Continue&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Enter the value for the variable. If it is a string, include the value in quotes.&lt;/li&gt;
&lt;li&gt;Or just enter a formula for the variable based on the existing variables.&lt;/li&gt;
&lt;li&gt;Click“&lt;code&gt;OK&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;delete-a-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Delete a Variable&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Right-click on the column header&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Clear&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; This does not produce a syntax in the Output window. The syntax for deleting a variable is here, in case you
are saving your syntax:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DELETE VARIABLES [list of variables, separated by spaces].&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;drop-observations-based-on-some-condition-keep-observations-meeting-the-opposite&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Drop observations based on some condition (Keep observations meeting the opposite)&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Data&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Select Cases...&lt;/code&gt; &amp;gt;&amp;gt; Select &lt;code&gt;If condition is satisfied&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;If...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter the condition based on which observations you would like to keep, then click &lt;code&gt;Continue&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;Delete unselected cases&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can specify multiple conditions at the same time by separating them with &lt;code&gt;AND&lt;/code&gt; or &lt;code&gt;OR.&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;merging-datasets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Merging datasets&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Data&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Merge Files&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Add Variables...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Note that the datasets you are merging must already be saved as SPSS (.sav) format files. In addition,
the variables you are matching on must have the same name across datasets.&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;An external SPSS statistics data file&lt;/code&gt;, browse for your file, and select it.&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;Match cases on key variables&lt;/code&gt;, click on the matching variable, and add it to &lt;code&gt;Key Variables&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;appending-datasets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Appending datasets&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Data&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Merge Files&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Add Cases...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Note that the datasets you are merging must already be saved as SPSS (.sav) format files. In addition,
the variables you are matching on must have the same name across datasets.&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;An external SPSS statistics data file&lt;/code&gt;, browse for your file, and select it.&lt;/li&gt;
&lt;li&gt;All variables already in both datasets will appear in &lt;code&gt;Variables in New Active Dataset&lt;/code&gt;, and variables
not in both datasets will be in &lt;code&gt;Unpaired Variables&lt;/code&gt;. Move all unpaired variables you want into the
right column.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;OK&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;descriptive-statistics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Descriptive Statistics&lt;/h2&gt;
&lt;div id=&#34;central-tendency-mean-median-and-mode-for-continuous-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Central tendency: mean, median, and mode (for continuous variable)&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptive Statistics&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Frequencies&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the continuous variable(s)&lt;/li&gt;
&lt;li&gt;Uncheck &lt;code&gt;Display frequency tables&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Statistics...&lt;/code&gt; and check the desired central tendency measures&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Continue&lt;/code&gt; and then &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;central-tendency-mode-and-frequency-table-for-categorical-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Central tendency: mode and frequency table (for categorical variable)&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptive Statistics&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Frequencies&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the categorical variable(s)&lt;/li&gt;
&lt;li&gt;Check &lt;code&gt;Display frequency tables&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Format&lt;/code&gt; and select &lt;code&gt;Descending counts&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Continue&lt;/code&gt; and then &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The top item in the frequency table is the mode. Note that if multiple categorical variables are selected, a
separate frequency table will be created for each variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variability-standard-deviation-variance-and-range-for-continuous-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variability: Standard deviation, variance, and range (for continuous variable)&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptive Statistics&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptives&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the continuous variable(s)&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Options&lt;/code&gt; and select the desired measures of spread&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Continue&lt;/code&gt; and then &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;common-analyses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Common Analyses&lt;/h2&gt;
&lt;div id=&#34;correlations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlations&lt;/h3&gt;
&lt;div id=&#34;pearson-correlation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Pearson correlation:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Correlate&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Bivariate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select Pearson under Correlation Coefficients box, select the variables, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;spearman-correlation-coefficient&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Spearman correlation coefficient:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Correlate&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Bivariate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select Spearman under Correlation Coefficient box, select the variables, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linear Regression&lt;/h3&gt;
&lt;div id=&#34;simple-linear-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simple Linear Regression:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Regression&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Linear&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter IV and DV, Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-linear-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Multiple Linear Regression:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Regression&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Linear&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select IVs and DV, Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;t-test&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;T-Test&lt;/h3&gt;
&lt;div id=&#34;single-sample-t-test&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Single-Sample T-test:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Compare Means&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;One-Sample T-test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter variables, click OK&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;independent-samples-t-test&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Independent Samples T-test:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Compare Means&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Independent Samples T test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter DV (Test Variable) and IV (Grouping variable), Define Groups, and enter the values of the two levels of the IV, click &lt;code&gt;continue&lt;/code&gt;, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;paired-samples-t-test&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Paired Samples T-Test:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Compare Means&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Paired Samples T Test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click on two paired variables to move to Current Selections area, then click right arrowto move to Paired Variables Section, Click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;anovas&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ANOVAs&lt;/h3&gt;
&lt;div id=&#34;oneway-anova&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Oneway ANOVA:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Compare Means&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;One-Way ANOVA&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter IV in Factor box, Enter DV to Dependent List box, click &lt;code&gt;Options&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Descriptive&lt;/code&gt; to get means in output Click continue, click OK&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;factorial-anova-2x2-2x2x3-etc.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Factorial Anova (2x2, 2x2x3, etc.):&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;General Linear Model&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Univariate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select DV for Dependent Variable blank and IVs for the Fixed Factors box, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;repeated-measures-anova&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Repeated Measures ANOVA:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;Analyze&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;General Linear Model&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;Repeated Measures&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter factors and number of levels &amp;gt;&amp;gt; click &lt;code&gt;Add&lt;/code&gt; &amp;gt;&amp;gt; once all factors are entered click &lt;code&gt;define&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Define variables using the arrows, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;mixed-design-anova&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Mixed-Design ANOVA:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Follow same steps as repeated measures&lt;/li&gt;
&lt;li&gt;Add between-subjects factor to “Between-Subjects Factor” box, click &lt;code&gt;OK&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Effect of Body-Worn Camera Activation and Auditing Policies on Perceptions of Monitoring Fairness</title>
      <link>https://ianadamsresearch.com/post/powerpoint-embed-testing/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/powerpoint-embed-testing/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The Department of Political Science at the University of Utah periodically holds political research colloquiums (PRC) for graduate students and faculty to present early and current research findings. This is my presentation at the PRC held Oct. 30, 2020. I describe early findings from one of my dissertation chapters. This research uses a randomized vignette experiment to investigate the effects of various body-worn camera activation and review/audit policies on how officers perceive the fairness of monitoring.&lt;/p&gt;
&lt;iframe src=&#34;https://onedrive.live.com/embed?cid=88E07230498FF330&amp;amp;resid=88E07230498FF330%21215407&amp;amp;authkey=AOUeIPrXrVFFZpg&amp;amp;em=2&amp;amp;wdAr=1.7777777777777777&#34; width=&#34;962px&#34; height=&#34;565px&#34; frameborder=&#34;0&#34;&gt;
This is an embedded &lt;a target=&#34;_blank&#34; href=&#34;https://office.com&#34;&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=&#34;_blank&#34; href=&#34;https://office.com/webapps&#34;&gt;Office&lt;/a&gt;.
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Zotero Workflow for Graduate Students and Researchers</title>
      <link>https://ianadamsresearch.com/post/2020-10-23-zotero-workflow-for-researchers/zotero-workflow-for-graduate-students-and-researchers/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/2020-10-23-zotero-workflow-for-researchers/zotero-workflow-for-graduate-students-and-researchers/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/post/2020-10-23-zotero-workflow-for-researchers/zotero-workflow-for-graduate-students-and-researchers/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Presented as part of the “Uncovering the Hidden Curriculum” workshop, hosted by the Department of Political Science at the University of Utah, October 23, 2020. Thank you to Devon Cantwell for helping make this happen!&lt;/p&gt;
&lt;iframe src=&#34;https://onedrive.live.com/embed?cid=88E07230498FF330&amp;amp;resid=88E07230498FF330%21215332&amp;amp;authkey=AH1XwiA-7rd2reo&amp;amp;em=2&amp;amp;wdAr=1.7777777777777777&#34; width=&#34;1500px&#34; height=&#34;565px&#34; frameborder=&#34;0&#34;&gt;
This is an embedded &lt;a target=&#34;_blank&#34; href=&#34;https://office.com&#34;&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=&#34;_blank&#34; href=&#34;https://office.com/webapps&#34;&gt;Office&lt;/a&gt;.
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>What Police Believe</title>
      <link>https://ianadamsresearch.com/post/what-police-believe/what-police-believe/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/what-police-believe/what-police-believe/</guid>
      <description>


&lt;p&gt;Last week I saw a &lt;a href=&#34;https://www.vox.com/policy-and-politics/2020/7/7/21293259/police-racism-violence-ideology-george-floyd&#34;&gt;Vox article making the Twitter rounds&lt;/a&gt;. Written by Zach Beauchamp, the article purports to have the inside track on an “ideology of American policing,” one that “justifies racist violence” in the minds of police officers. Startling stuff.&lt;/p&gt;
&lt;p&gt;Before you hear from me, go check out the article. First though, ask yourself: How many active police officers do you think the author spoke with, based on the headline?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/What-Police-Believe/2020-07-14-what-police-believe.en_files/vox_headline.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I initially looked forward to reading the article. I am a former officer, and now a scholar who devotes a great deal of time thinking about and researching police attitudes and beliefs. From what &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0047235219302867&#34;&gt;officers’ own words can tell us about their propensity to “de-police”&lt;/a&gt; to how officers &lt;a href=&#34;https://journals.sagepub.com/doi/10.1177/0734016819846219&#34;&gt;perceive the “intensity” of monitoring from body-worn cameras&lt;/a&gt;, I approach officers as human beings with something to say, and with something worth hearing.&lt;/p&gt;
&lt;p&gt;My initial hopes for the article were not fulfilled. The article begins with promises of a “deep dive” but ends up misjudging the depth of the pool. It soon became clear where the author went wrong: He forgot to listen to cops.
Writing an article that promises insight into a group of human beings, but then &lt;em&gt;not interviewing one person who is from that group&lt;/em&gt;, is almost guaranteed to result in a failure to communicate effectively about that group.&lt;/p&gt;
&lt;p&gt;But don’t take my word for it, here’s how Beauchamp reports he conducted his research:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/What-Police-Believe/2020-07-14-what-police-believe.en_files/vox_how.JPG&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;dinkheller-administrative-heat&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dinkheller &amp;amp; Administrative Heat&lt;/h2&gt;
&lt;p&gt;One of the critical linchpins of Beauchamp’s case is that this “ideology of American policing” starts in the academy with a showing of the “Dinkheller” video. Being familiar with that video, and somewhat knowledgeable about how it can be framed for police recruits, Beauchamp’s reductionist vision of it was quite startling.&lt;/p&gt;
&lt;p&gt;I first encountered the Dinkheller video at the academy as a young recruit. The purpose as I remember it was in the context of how administrative “heat” can cause officers to hesitate when they absolutely should not. No one can perfectly attest to what caused Dinkheller to hesitate taking action even in the face of the most violent and predictable outcomes. Five separate law enforcement officers confirmed one version of events, centered on the idea that Dinkheller was distressed about his trouble with the Sheriff over a previous demeanor complaint on a traffic stop. Here is some support for that idea, &lt;a href=&#34;https://www.cnn.com/interactive/2017/politics/state/kyle-dinkheller-police-video/&#34;&gt;from CNN’s coverage of the incident&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“In the late ’90s, some rank-and-file deputies believed [Sheriff Webb] wouldn’t stand by them in a crisis. This was partly due to an incident that involved Kyle Dinkheller just a few months before he died.
Kyle was on his way to a crash scene with his lights flashing when he came upon a vehicle whose driver wouldn’t move aside. Because state law requires civilians to yield in those situations, Kyle spoke harshly to the man, who turned out to be a good friend of the sheriff. The man complained to Webb, who told Kyle to write a letter of apology. Kyle initially refused to write the letter. He told fellow deputies that the sheriff ordered him to write it or face severe consequences.
Kyle wrote the letter. His colleagues say the sheriff made him re-write it and deliver it by hand. The incident weighed on him. When he saw Deputy Skip Lowery at the gas pumps, Kyle would say things like,”Y’all write any letters of apology today?” Two days before he died, in a friendly visit to the home of Special Agent Alan Watson of the Georgia Bureau of Investigation, Kyle mentioned the apology. His colleagues are convinced it was somewhere in the back of his mind during his final traffic stop. He knew he was being watched, and he’d learned that being right was not always enough.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;experts-and-practitioners&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Experts and Practitioners&lt;/h2&gt;
&lt;p&gt;Why isn’t this theme reflected in the Vox article? What’s missing from Beauchamp’s reporting? Well…officers. Though the article describes “a deep dive into the motivations and beliefs of police,” a less flashy but more honest appraisal of the approach would be: a collection of academic opinions without the mess of dealing with the views of practitioners.&lt;/p&gt;
&lt;p&gt;To his credit, Beauchamp calls on the words of highly respected academics, including Eugene Paoline, who, along with William Terrill, authored &lt;a href=&#34;https://doi.org/10.1080/0735648X.2011.609740&#34;&gt;“Listen to Me! Police Officers Views of Appropriate Use of Force,”&lt;/a&gt; a compelling argument for listening to the voices of actual, working law enforcement officers. The article also includes thoughts from Peter Moskos, a former officer, current professor at Jon Jay College of Criminal Justice, and author of the exceptional &lt;a href=&#34;https://www.amazon.com/Cop-Hood-Policing-Baltimores-District/dp/0691143862/ref=sr_1_1?dchild=1&amp;amp;keywords=cop+in+the+hood+book&amp;amp;qid=1594745311&amp;amp;sr=8-1&#34;&gt;&lt;em&gt;Cop in the Hood&lt;/em&gt;&lt;/a&gt; (really, you should read it).&lt;/p&gt;
&lt;p&gt;So what’s the complaint then? Didn’t Beauchamp do what he set out to do? He interviewed experts and former police. Doesn’t that get you “inside the ideology of American policing”? No, it doesn’t. Despite the excellent academic contributions, Beauchamp misses the mark fairly widely by not listening to officers who are actively serving their communities. It is clear what Beauchamp missed: the gap between expert opinion, and officers’ perceptions (if you bother to ask them directly). While I’m writing in response to a journalist, this is also a reminder to myself, and others who study policing - be wary of letting our own voices carry louder than those we report on and research. All the interesting variation is in the voices and experiences of those we study; our overlays of theory and interpretation strip out that variation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;beauchamps-claim&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beauchamp’s Claim&lt;/h2&gt;
&lt;p&gt;Beauchamp spends ample time unpacking expert and academic views on the Dinkheller video. Like Professor Moskos correctly says, this is a video that most every officer knows, but not many outside policing or the study of it do. &lt;strong&gt;Warning&lt;/strong&gt; – it’s not a pleasant video (contains disturbing audio and video of an officer being murdered): &lt;a href=&#34;https://www.youtube.com/watch?v=mssNOhv1UMc&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=mssNOhv1UMc&lt;/a&gt;. If the video is too much (and it is for me), &lt;a href=&#34;https://en.wikipedia.org/wiki/Murder_of_Kyle_Dinkheller&#34;&gt;you can read about the incident here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Beauchamp makes this claim about the purpose of showing the Dinkheller video to police recruits:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/What-Police-Believe/2020-07-14-what-police-believe.en_files/dinkheller_purpose.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From Beauchamp’s reporting, however, all we know is his interpretation, based on a handful of experts and former officers, but not a single, actual, bonafide officer. Is that what they think the purpose of the video is? The easiest way to find out is to ask. So I did.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;officers-views&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Officers’ Views&lt;/h2&gt;
&lt;p&gt;I called six current officers whom I know personally. They range from very close friends who would raise my children if needed, to professional contacts in other parts of the country. I promised them I wouldn’t use names, but just their rank, approximate years on the job, and current assignment. Here’s what they said about the Dinkheller video. I asked them if they remembered the video, and if so, what was the purpose of the video. This is obviously not a random sample.&lt;/p&gt;
&lt;p&gt;These are their immediate, off-the-cuff responses that I typed directly into the document as we spoke:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Officer, ~20 years, narcotics officer: That video was about doing what you have to do. It was a constable, right? He was jammed up by his chief on something else, like a use-of-force. Then when it came time, he hesitated. The purpose I guess was to teach us not to let an administrator get us killed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Officer, &amp;lt; 3 years, patrol officer: I actually don’t remember that video.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Officer, ~15 years, traffic enforcement: That was about not letting a dude do what he did. You don’t let a guy back into the car after all that. It ain’t gonna end well, ever.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lieutenant, ~15 years, major crimes: Oh yeah, I remember it. It was about how you can’t let someone disobey your lawful commands over and over. If you do, there’s always going to be a bad outcome. Unfortunately for that officer, the outcome was death. Young officers need to know what to look out for, and take action when it’s necessary.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Major, ~25 years, training academy director: I don’t know if we still use that video, I’d have to check with my trainers to see. These days we introduce the recruits to those types of videos much later. That video is hard for even you and I to watch. When I did use that video in the past, it was for the flags. What flags can we point to where the officer could have made a different decision? That man struck the officer, and then he allowed him to get back into the truck and retrieve a rifle. That should not have happened. I want my recruits to have the confidence to stop him from getting back into the vehicle.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Officer, ~20 years, patrol and use-of-force trainer: Man, the Dinkheller video was horrific. The indicators of non-compliance are all there. You’ll see odd behaviors in the extreme. Most traffic stops are extremely predictable. When we see things outside of the norm, that’s when we need to pay attention. It would be foolish not to show officers what the out-of-the-ordinary looks like. The Dinkheller video is not an example of the normal traffic stop, it’s the video that shows what’s not normal, what an officer needs to pay attention to. When you see the indicators, the hands in the pockets, the strange behavior, the noncompliance, you need to immediately hop on that. When you disregard those, when you hesitate, when you ignore the physiological effects like the voice stress, the repetitive commands – that tells you Dinkheller has lost control. As a trainer I need to put people into stressful scenarios. For me as an officer and a trainer, I need to recognize “this is not good, this is waaaay outside the bounds of good, I need to do something.” Teaching recruits how to deal with fear is imperative. Clearly recognizing the warning signs is part of that. That only comes from training and experience. There’s no way around that.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;themes-from-police&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Themes from Police&lt;/h2&gt;
&lt;p&gt;So, what do police actually believe about the Dinkheller video? We have four themes:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Not exposed to the video, or video not in use. This is a particular problem for Beauchamp’s thesis that the Dinkheller video is forming an ideology that “justifies racist violence.”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The purpose of the video is to teach recruits the “flags” that might mean their lives are in danger. Refusing to remove his hands from his pockets [0:22], dancing around yelling “Fuck you Goddamnit, here I am, shoot my fucking ass!” [0:29], shouting “Fucking do it man!” [0:46], physically attacking the officer [1:00], getting back into the vehicle [1:10], retrieving an M1 rifle from the truck [1:20], aiming the rifle at the officer [1:20 – 1:55], and finally firing at the officer beginning at [1:56].&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The purpose of the video was to reinforce the danger of not enforcing an officer’s legal commands. Repeated indifference to an officer’s commands is a danger signal that officers should pay attention to. Act when your eyes are telling you there is a problem.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The purpose of the video was to instill in officers that they should not let previous administrative burdens become a death sentence. It is fascinating that multiple officers, from different parts of the country, remember this theme from their training days. The gap in trust between officers and administrators runs deep, and this is some evidence that even recruits are exposed to the distrust from a very early stage in their careers. In some ways this would support Beauchamp’s conclusions, in that there are important exposures in academy training that shape officers’ views of policing. However, amending Beauchamp’s thesis in this &lt;em&gt;post-hoc&lt;/em&gt; manner is speculative at best, because his reporting does not reflect this important bit of information.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What’s striking about these themes taken together is the notable absence of the animating thesis for Beauchamp’s article, which is: “The purpose of the Dinkheller video…is to teach officers that any situation could escalate to violence. Cop killers lurk around every corner.” Dramatic language, but not language supported by officers’ words, either in the article (because they weren’t asked), or in my quick sample. Quite contrary to the article’s thesis that the Dinkheller video teaches officers that &lt;em&gt;unexpected danger is around every corner&lt;/em&gt;, officers see the video as teaching them &lt;em&gt;expected dangers are right in front of you&lt;/em&gt;. That is some valuable insight, and was entirely available to Beauchamp, had he bothered to ask.&lt;/p&gt;
&lt;p&gt;The other obvious deficiency that these six officers expose in Beauchamp’s reporting is that there is no singular ideology. This should not be surprising. With at least 800,000 officers in the US, and 18,000 law enforcement agencies, ascribing a singular ideology is tenuous at best. Doing so contributes to visions of law enforcement officers as less than fully human, as robotic and featureless cogs in a unitary system. Anyone who has researched officers knows that’s an unfair conclusion. Even worse, in the context of reporting, it is an inaccurate one. One way to avoid that kind of caricature is to spend time - a lot of time - with the people on whom you report.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;doing-better&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Doing Better&lt;/h2&gt;
&lt;p&gt;Former officers and scholars, myself included, are valuable resources for insights about how officers view the world. The trap that Beauchamp fell into is assuming those insights are the same as officers’ own. This is a pernicious problem in journalism about police. Check your favorite paper and count how many times some version of “Police say…” is used. How many were followed with the views of 1) line officers, who were 2) not representing the department as a public information officer or spokesperson?&lt;/p&gt;
&lt;p&gt;Doing better means listening to more people. Not experts on people, but the people themselves. Doing better allows you to avoid misjudging the depth of an issue, and revealing variation you could not otherwise have accessed. I only made a handful of calls, and Beauchamp only spoke with “more than a dozen” sources, but the variety of interesting themes is already too complicated and interesting to reduce down to an “ideology of American policing” as claimed in the Vox piece. Variation is good, rough reductionism helps no one.&lt;/p&gt;
&lt;p&gt;Journalists and journalism generally, and Vox specifically, can do better. I enjoy the policy dives that Vox provides in all kinds of areas. Like many, I rely on their reportage to get an accurate picture of worlds I don’t otherwise have access to. How accurate would an article be titled “What Teachers Really Believe,” if we found out not a single teacher was used? I suspect some teacher’s might object, especially if their actual views were not represented, and they would be right to do so.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidying STM with tidytext</title>
      <link>https://ianadamsresearch.com/post/tidy-stm/tidying-stm-with-tidytext/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/tidy-stm/tidying-stm-with-tidytext/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Libraries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidytext)
library(ggthemes)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(scales)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;load-previous-stm-objects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load Previous STM Objects&lt;/h2&gt;
&lt;p&gt;I have previously run &lt;code&gt;stm&lt;/code&gt; models for topics ranging from 3 to 25. Based on the fit indices, a six-topic model was selected. I am not showing that analysis here, but instead loading the saved &lt;code&gt;stm&lt;/code&gt; objects (the model and the ‘out’ object).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidy-the-stm-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tidy the stm model&lt;/h2&gt;
&lt;p&gt;I am using the &lt;code&gt;tidytext&lt;/code&gt; package from Julia Silge, which she &lt;a href=&#34;https://juliasilge.com/blog/evaluating-stm/&#34;&gt;demonstrates in a blog post here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;td_beta &amp;lt;- tidy(modelfit6)
td_beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,416 x 3
##    topic term        beta
##    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;
##  1     1 abil    9.13e-61
##  2     2 abil    6.07e-55
##  3     3 abil    1.51e- 2
##  4     4 abil    2.98e-54
##  5     5 abil    3.66e-63
##  6     6 abil    2.39e-58
##  7     1 account 1.57e-91
##  8     2 account 1.37e-25
##  9     3 account 4.28e-66
## 10     4 account 6.47e-63
## # ... with 1,406 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;td_gamma &amp;lt;- tidy(modelfit6, matrix = &amp;quot;gamma&amp;quot;,
                 document_names = rownames(out$meta))

td_gamma&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,266 x 3
##    document topic   gamma
##    &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 1            1 0.00343
##  2 2            1 0.00462
##  3 3            1 0.0861 
##  4 4            1 0.0467 
##  5 5            1 0.0106 
##  6 6            1 0.00306
##  7 7            1 0.00419
##  8 8            1 0.0511 
##  9 9            1 0.00356
## 10 10           1 0.144  
## # ... with 1,256 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-topic-relevance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot Topic Relevance&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_terms &amp;lt;- td_beta %&amp;gt;%
  arrange(beta) %&amp;gt;%
  group_by(topic) %&amp;gt;%
  top_n(7, beta) %&amp;gt;%
  arrange(-beta) %&amp;gt;%
  select(topic, term) %&amp;gt;%
  summarise(terms = list(term)) %&amp;gt;%
  mutate(terms = map(terms, paste, collapse = &amp;quot;, &amp;quot;)) %&amp;gt;% 
  unnest()

gamma_terms &amp;lt;- td_gamma %&amp;gt;%
  group_by(topic) %&amp;gt;%
  summarise(gamma = mean(gamma)) %&amp;gt;%
  arrange(desc(gamma)) %&amp;gt;%
  left_join(top_terms, by = &amp;quot;topic&amp;quot;) %&amp;gt;%
  mutate(topic = paste0(&amp;quot;Topic &amp;quot;, topic),
         topic = reorder(topic, gamma))

gamma_terms %&amp;gt;%
  top_n(6, gamma) %&amp;gt;%
  ggplot(aes(topic, gamma, label = terms, fill = topic)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0.85, nudge_y = 0.0005, size = 3) +
  coord_flip() +
  theme_hc() +
  theme(plot.title = element_text(size = 14)) +
  labs(x = NULL, y = expression(gamma),
       title = &amp;quot;Top Six Topics by Prevalence in the Officer Responses&amp;quot;,
       subtitle = &amp;quot;With the top words that contribute to each topic&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Tidy-STM/2020-06-23-tidying-stm-with-tidytext.en_files/figure-html/remedy003-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;table-of-topic-proportions-with-top-terms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Table of Topic Proportions with Top Terms&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(knitr)
gamma_terms %&amp;gt;%
  select(topic, gamma, terms) %&amp;gt;%
  kable(digits = 3, 
        col.names = c(&amp;quot;Topic&amp;quot;, &amp;quot;Expected topic proportion&amp;quot;, &amp;quot;Top 6 terms&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Topic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Expected topic proportion&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Top 6 terms&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.240&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;complaint, protect, public, fals, make, tool, time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.214&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;affect, way, chang, made, turn, situat, also&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.192&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;camera, job, help, bodi, wear, captur, action&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.149&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;offic, peopl, work, worri, one, say, good&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.117&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;use, video, will, call, without, review, someth&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Topic 1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.088&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;know, person, feel, wear, like, supervisor, think&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Randomizing Vignette Factorial Designs in Survey Research with Qualtrics</title>
      <link>https://ianadamsresearch.com/post/qualtrics/randomizing-vignettes-in-survey-research-with-qualtrics/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/qualtrics/randomizing-vignettes-in-survey-research-with-qualtrics/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In survey research, we sometimes want to present varying conditions in a short descriptive text, often called a vignette, and measure the effects of those conditions on an outcome of interest.&lt;/p&gt;
&lt;p&gt;For example, say we have been hired by DinoCreations Inc. to gauge the public’s willingness to spend tax dollars on our brand new Island Adventure theme park, complete with living dinosaurs created from ancient DNA held within amber! We want to know if varying the dinosaurs type and size in a vignette results in statistically significant differences in potential patrons willingness to visit. We have two types of dinosaurs, and they come in three sizes. Will our potential guests be more likely to purchase a vacation package dependent on the type and size of dinosaurs we advertise with?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/mean.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are multiple ways we could do this. For example, we could just type out each of the six vignette (2x3) and have those randomly display to respondents. However, some vignette designs have a lot more conditions to evaluate. Here, I’ll demonstrate a simple 2x3 vignette factorial design, but the method can easily be modified for larger designs. The survey platform Qualtrics makes this easy, using embedded data and the randomizer in survey flows.&lt;/p&gt;
&lt;div id=&#34;placeholder-descriptive-text&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Placeholder Descriptive Text&lt;/h2&gt;
&lt;p&gt;Following months of research, we have determined that there are TWO types of dinosaurs (T-rex and Stegosaurus), and each dinosaur comes in three sizes (big, humongous, and ginormous). Lucky for us, this is a perfect opportunity to put a 2x3 factorial vignette design into play!&lt;/p&gt;
&lt;p&gt;For now, let’s create a place holder question in the survey. Our vignette will be about dinosaurs, and we are interested in willingness to visit our new Dinocreations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/placeholder.JPG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;building-the-randomizer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Building the Randomizer&lt;/h2&gt;
&lt;p&gt;Next we need to build a randomizer inside the survey flow. Once inside the survey flow, click the “add below” text inside the survey block, then click the “randomizer” tag.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/randomizer.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we want to add the type of information this randomizer will handle, in this case, “type” of dinosaur. Click “Add a new element here,” using the “embedded data” type, and assign “type” as the element name. Then assign a type of dinosaur, I chose “terrifying Tyrannasaurus Rex.” Then repeat this step, and assign a different type of dinosaur, in this case an “adorable Stegosaurus.” Finally, &lt;strong&gt;make sure you tell the randomizer to randomly present only 1 of these options&lt;/strong&gt;. Click the “evenly present options” if you want there to be a randomized and equal chance for your survey respondents to see each choice (so here, a 1:2 chance, but for size, a 1:3 chance).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/type_pic.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we want to build another randomizer, this time to vary the size of the dinosaur in our vignette. Using the same steps as above, we will add a size randomizer that uses three elements of big, humongous, and ginormous, and then &lt;strong&gt;make sure only one of these options is presented&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/pic_size.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the final step in the survey flow, we want to make sure both randomizers are &lt;strong&gt;ABOVE&lt;/strong&gt; the vignette question. This assures that the appropriate information is placed into our survey vignette question.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/survey_flow_final.JPG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-the-vignette-and-inserting-piped-text&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Back to the vignette, and inserting piped text&lt;/h2&gt;
&lt;p&gt;Save and close the survey flow interface. Now we need to use the “piped text” interface to get our vignette put together. We have decided to concentrate on customers who will be leaving on their honeymoon soon. The plain text in this box is text that EVERY survey respondent will see, while the SIZE and TYPE placeholders will need to be modified to import the embedded data we defined in the survey flow steps above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/pic_honeymoon.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To use the piped text funcionality, highlight SIZE, and then click the “piped text” tab directly above:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/pip_piped.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Then, click the “embedded data” option, and type in “size” (without the quotation marks) and hit enter. Repeat this step for the TYPE placeholder, with the “type” embedded data. After you delete the placeholders, you should have something that looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/final%20vignette%20setup.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, let’s see if our survey is working. Use the “preview” button at the top of the page. Check it a few times to make sure the randomization is working. Here, in two consecutive previews, I can already see the randomization is working!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/stego_gino.JPG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ianadamsresearch.com/post/Qualtrics/2020-05-23-randomizing-vignettes-in-survey-research-with-qualtrics.en_files/trex_humon_pic.JPG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Analyzing the results is outside of the scope of this post, but there are plenty of guides for that. Now go forth and randomize your vignettes!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing Netlify hosting with R Markdown</title>
      <link>https://ianadamsresearch.com/post/markdown-testing/testing-netlify-hosting-with-r-markdown/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/markdown-testing/testing-netlify-hosting-with-r-markdown/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This report was generated on 2020-12-30, as a demo of &lt;code&gt;textclean&lt;/code&gt; from &lt;a href=&#34;https://github.com/trinker/textclean#check-text&#34; class=&#34;uri&#34;&gt;https://github.com/trinker/textclean#check-text&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is an &lt;a href=&#34;http://rmarkdown.rstudio.com&#34;&gt;R Markdown&lt;/a&gt; Notebook. When you execute code within the notebook, the results appear beneath the code.&lt;/p&gt;
&lt;div id=&#34;fast-example-with-created-examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fast example with created examples&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(&amp;quot;i like&amp;quot;, &amp;quot;&amp;lt;p&amp;gt;i want. &amp;lt;/p&amp;gt;. thet them ther .&amp;quot;, &amp;quot;I am ! that|&amp;quot;, &amp;quot;&amp;quot;, NA, 
    &amp;quot;&amp;amp;quot;they&amp;amp;quot; they,were there&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;   &amp;quot;, &amp;quot;?&amp;quot;, &amp;quot;3;&amp;quot;, &amp;quot;I like goud eggs!&amp;quot;, 
    &amp;quot;bi\xdfchen Z\xfcrcher&amp;quot;, &amp;quot;i 4like...&amp;quot;, &amp;quot;\\tgreat&amp;quot;,  &amp;quot;She said \&amp;quot;yes\&amp;quot;&amp;quot;)
Encoding(x) &amp;lt;- &amp;quot;latin1&amp;quot;
x &amp;lt;- as.factor(x)
check_text(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## =============
## NON CHARACTER
## =============
## 
## The text variable is not a character column (likely `factor`):
## 
## 
## *Suggestion: Consider using `as.character` or `stringsAsFactors = FALSE` when reading in
##              Also, consider rerunning `check_text` after fixing
## 
## 
## =====
## DIGIT
## =====
## 
## The following observations contain digits/numbers:
## 
## 10, 13
## 
## This issue affected the following text:
## 
## 10: 3;
## 13: i 4like...
## 
## *Suggestion: Consider using `replace_number`
## 
## 
## ========
## EMOTICON
## ========
## 
## The following observations contain emoticons:
## 
## 6
## 
## This issue affected the following text:
## 
## 6: &amp;amp;quot;they&amp;amp;quot; they,were there
## 
## *Suggestion: Consider using `replace_emoticons`
## 
## 
## =====
## EMPTY
## =====
## 
## The following observations contain empty text cells (all white space):
## 
## 1
## 
## This issue affected the following text:
## 
## 1: i like
## 
## *Suggestion: Consider running `drop_empty_row`
## 
## 
## =======
## ESCAPED
## =======
## 
## The following observations contain escaped back spaced characters:
## 
## 14
## 
## This issue affected the following text:
## 
## 14: \tgreat
## 
## *Suggestion: Consider using `replace_white`
## 
## 
## ====
## HTML
## ====
## 
## The following observations contain HTML markup:
## 
## 2, 6
## 
## This issue affected the following text:
## 
## 2: &amp;lt;p&amp;gt;i want. &amp;lt;/p&amp;gt;. thet them ther .
## 6: &amp;amp;quot;they&amp;amp;quot; they,were there
## 
## *Suggestion: Consider running `replace_html`
## 
## 
## ==========
## INCOMPLETE
## ==========
## 
## The following observations contain incomplete sentences (e.g., uses ending punctuation like &amp;#39;...&amp;#39;):
## 
## 13
## 
## This issue affected the following text:
## 
## 13: i 4like...
## 
## *Suggestion: Consider using `replace_incomplete`
## 
## 
## =============
## MISSING VALUE
## =============
## 
## The following observations contain missing values:
## 
## 5
## 
## *Suggestion: Consider running `drop_NA`
## 
## 
## ========
## NO ALPHA
## ========
## 
## The following observations contain elements with no alphabetic (a-z) letters:
## 
## 4, 7, 8, 9, 10
## 
## This issue affected the following text:
## 
## 4: 
## 7: .
## 8:    
## 9: ?
## 10: 3;
## 
## *Suggestion: Consider cleaning the raw text or running `filter_row`
## 
## 
## ==========
## NO ENDMARK
## ==========
## 
## The following observations contain elements with missing ending punctuation:
## 
## 1, 3, 4, 6, 8, 10, 12, 14, 15
## 
## This issue affected the following text:
## 
## 1: i like
## 3: I am ! that|
## 4: 
## 6: &amp;amp;quot;they&amp;amp;quot; they,were there
## 8:    
## 10: 3;
## 12: bißchen Zürcher
## 14: \tgreat
## 15: She said &amp;quot;yes&amp;quot;
## 
## *Suggestion: Consider cleaning the raw text or running `add_missing_endmark`
## 
## 
## ====================
## NO SPACE AFTER COMMA
## ====================
## 
## The following observations contain commas with no space afterwards:
## 
## 6
## 
## This issue affected the following text:
## 
## 6: &amp;amp;quot;they&amp;amp;quot; they,were there
## 
## *Suggestion: Consider running `add_comma_space`
## 
## 
## =========
## NON ASCII
## =========
## 
## The following observations contain non-ASCII text:
## 
## 12
## 
## This issue affected the following text:
## 
## 12: bißchen Zürcher
## 
## *Suggestion: Consider running `replace_non_ascii`
## 
## 
## ==================
## NON SPLIT SENTENCE
## ==================
## 
## The following observations contain unsplit sentences (more than one sentence per element):
## 
## 2, 3
## 
## This issue affected the following text:
## 
## 2: &amp;lt;p&amp;gt;i want. &amp;lt;/p&amp;gt;. thet them ther .
## 3: I am ! that|
## 
## *Suggestion: Consider running `textshape::split_sentence`&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;and-if-all-is-well-the-user-should-be-greeted-by-a-cow&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;And if all is well the user should be greeted by a cow:&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y &amp;lt;- c(&amp;quot;A valid sentence.&amp;quot;, &amp;quot;yet another!&amp;quot;)
check_text(y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  ------------- 
## No problems found!
## This text is virtuosic! 
##  ---------------- 
##   \   ^__^ 
##    \  (oo)\ ________ 
##       (__)\         )\ /\ 
##            ||------w|
##            ||      ||&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;row-filtering&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Row Filtering&lt;/h2&gt;
&lt;p&gt;It is useful to drop/remove empty rows or unwanted rows (for example the researcher dialogue from a transcript). The &lt;code&gt;drop_empty_row&lt;/code&gt; &amp;amp; &lt;code&gt;drop_row&lt;/code&gt; do empty row do just this. First I’ll demo the removal of empty rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## create a data set wit empty rows
(dat &amp;lt;- rbind.data.frame(DATA[, c(1, 4)], matrix(rep(&amp;quot; &amp;quot;, 4), 
    ncol =2, dimnames=list(12:13, colnames(DATA)[c(1, 4)]))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        person                                 state
## 1         sam         Computer is fun. Not too fun.
## 2        greg               No it&amp;#39;s not, it&amp;#39;s dumb.
## 3     teacher                    What should we do?
## 4         sam                  You liar, it stinks!
## 5        greg               I am telling the truth!
## 6       sally                How can we be certain?
## 7        greg                      There is no way.
## 8         sam                       I distrust you.
## 9       sally           What are you talking about?
## 10 researcher         Shall we move on?  Good then.
## 11       greg I&amp;#39;m hungry.  Let&amp;#39;s eat.  You already?
## 12                                                 
## 13&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_empty_row(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        person                                 state
## 1         sam         Computer is fun. Not too fun.
## 2        greg               No it&amp;#39;s not, it&amp;#39;s dumb.
## 3     teacher                    What should we do?
## 4         sam                  You liar, it stinks!
## 5        greg               I am telling the truth!
## 6       sally                How can we be certain?
## 7        greg                      There is no way.
## 8         sam                       I distrust you.
## 9       sally           What are you talking about?
## 10 researcher         Shall we move on?  Good then.
## 11       greg I&amp;#39;m hungry.  Let&amp;#39;s eat.  You already?&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we drop out rows. The &lt;code&gt;drop_row&lt;/code&gt; function takes a data set, a column (named or numeric position) and regex terms to search for. The &lt;code&gt;terms&lt;/code&gt; argument takes regex(es) allowing for partial matching. &lt;code&gt;terms&lt;/code&gt; is case sensitive but can be changed via the &lt;code&gt;ignore.case&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_row(dataframe = DATA, column = &amp;quot;person&amp;quot;, terms = c(&amp;quot;sam&amp;quot;, &amp;quot;greg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       person sex adult                         state code
## 1    teacher   m     1            What should we do?   K3
## 2      sally   f     0        How can we be certain?   K6
## 3      sally   f     0   What are you talking about?   K9
## 4 researcher   f     1 Shall we move on?  Good then.  K10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_row(DATA, 1, c(&amp;quot;sam&amp;quot;, &amp;quot;greg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       person sex adult                         state code
## 1    teacher   m     1            What should we do?   K3
## 2      sally   f     0        How can we be certain?   K6
## 3      sally   f     0   What are you talking about?   K9
## 4 researcher   f     1 Shall we move on?  Good then.  K10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;keep_row(DATA, 1, c(&amp;quot;sam&amp;quot;, &amp;quot;greg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   person sex adult                                 state code
## 1    sam   m     0         Computer is fun. Not too fun.   K1
## 2   greg   m     0               No it&amp;#39;s not, it&amp;#39;s dumb.   K2
## 3    sam   m     0                  You liar, it stinks!   K4
## 4   greg   m     0               I am telling the truth!   K5
## 5   greg   m     0                      There is no way.   K7
## 6    sam   m     0                       I distrust you.   K8
## 7   greg   m     0 I&amp;#39;m hungry.  Let&amp;#39;s eat.  You already?  K11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_row(DATA, &amp;quot;state&amp;quot;, c(&amp;quot;Comp&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        person sex adult                                 state code
## 1        greg   m     0               No it&amp;#39;s not, it&amp;#39;s dumb.   K2
## 2     teacher   m     1                    What should we do?   K3
## 3         sam   m     0                  You liar, it stinks!   K4
## 4        greg   m     0               I am telling the truth!   K5
## 5       sally   f     0                How can we be certain?   K6
## 6        greg   m     0                      There is no way.   K7
## 7         sam   m     0                       I distrust you.   K8
## 8       sally   f     0           What are you talking about?   K9
## 9  researcher   f     1         Shall we move on?  Good then.  K10
## 10       greg   m     0 I&amp;#39;m hungry.  Let&amp;#39;s eat.  You already?  K11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_row(DATA, &amp;quot;state&amp;quot;, c(&amp;quot;I &amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       person sex adult                                 state code
## 1        sam   m     0         Computer is fun. Not too fun.   K1
## 2       greg   m     0               No it&amp;#39;s not, it&amp;#39;s dumb.   K2
## 3    teacher   m     1                    What should we do?   K3
## 4        sam   m     0                  You liar, it stinks!   K4
## 5      sally   f     0                How can we be certain?   K6
## 6       greg   m     0                      There is no way.   K7
## 7      sally   f     0           What are you talking about?   K9
## 8 researcher   f     1         Shall we move on?  Good then.  K10
## 9       greg   m     0 I&amp;#39;m hungry.  Let&amp;#39;s eat.  You already?  K11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;drop_row(DATA, &amp;quot;state&amp;quot;, c(&amp;quot;you&amp;quot;), ignore.case = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       person sex adult                         state code
## 1        sam   m     0 Computer is fun. Not too fun.   K1
## 2       greg   m     0       No it&amp;#39;s not, it&amp;#39;s dumb.   K2
## 3    teacher   m     1            What should we do?   K3
## 4       greg   m     0       I am telling the truth!   K5
## 5      sally   f     0        How can we be certain?   K6
## 6       greg   m     0              There is no way.   K7
## 7 researcher   f     1 Shall we move on?  Good then.  K10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New Website</title>
      <link>https://ianadamsresearch.com/post/new-website/new-website/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/new-website/new-website/</guid>
      <description>&lt;p&gt;I really appreciate &lt;a href=&#34;https://www.dsquintana.blog/free-website-in-r-easy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dan Quintana for his walkthrough&lt;/a&gt; on getting an Academic themed website up and running.&lt;/p&gt;
&lt;p&gt;Thank you to &lt;a href=&#34;http://www.pik-potsdam.de/~pichler/blog/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Peter Paul Pichler for his script&lt;/a&gt; adapated from &lt;a href=&#34;https://lbusett.netlify.app/post/automatically-importing-publications-from-bibtex-to-a-hugo-academic-blog/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lorenzo Busetto&amp;rsquo;s original script&lt;/a&gt; to import publication data from bibtex files (I use Zotero, but other citation software should work fine).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Tyranny of Feeling</title>
      <link>https://ianadamsresearch.com/post/tyranny-of-feeling/tyranny-of-feeling/</link>
      <pubDate>Wed, 13 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/tyranny-of-feeling/tyranny-of-feeling/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;“That’s the problem with police, you don’t show enough feeling,” she said. “You don’t feel enough.” She’s right, of course.&lt;/p&gt;
&lt;p&gt;A drowning in a desert town with no lakes. My partner jumped into the canal and pushed the huge man to the bank. I struggled and pulled, he pushed and slipped, both of us wet and covered with mud, neither of us feeling the cold water. Our new officer arrived and jumped into the scene, pushing on the man’s chest while I hovered over his face, trying to see inside his mouth. His wife, hands on my shoulders, screaming in my ear, screaming no. I couldn’t feel her breath on my neck, her tears on my head. Finally, my partner says to stop, just stop. I looked down and saw my pants were covered in the man’s blood, which had poured from the bullet hole in his temple. I couldn’t feel the wet blood soaking through my pants. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;A gunshot in the basement of a home. As I made my way down the stairs, the air was filled with a haze. A man, missing his face, and a rifle sitting in a lake of blood on the bed. Three walls covered with meat. The mewling, writhing figure unable to speak, but clearly letting me know the horror, the pain he was feeling. A few inches of jaw, glued to the carpet, the stubble of beard visible from the inside. The home now filled with explosive gas, a mother unaware. A mother begging us to just let her son die. As I grabbed the woman by the arm, I couldn’t feel her brittle, old bones under my grip. I couldn’t smell the gas, couldn’t gag as I pulled the jaw from the carpet; I couldn’t find it inside me to feel the horror. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;A mother, worn by the chemotherapy, held hostage. A son, a mind broken by drugs and now holding mom hostage until a girlfriend returns. I can’t feel the gun in my hands. A plan develops, a promise of a drink for a thirsty mother, worn by the long negotiation. A foot through the door, a son brings the knife towards my partner. I can’t feel my friend get cut. I can’t feel my gun, screwed into the temple of a man who’s so close to having a mind broken by a bullet. “I’ve got the knife,” the officer behind me yells. I can’t feel the relief. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;A breathing problem, a medical call, leave it for the medics. But I’m here, and this lady isn’t breathing, won’t breathe again. I can’t feel her granddaughter behind me, watching me place shock pads on grandma’s chest, watching me push helplessly on grandma as the machine tells me to push harder. Later now, the medics gone. As her husband pulls me into a hug, I can’t feel his heart breaking inside. Her husband has to say goodbye, and I go to her first. I never knew her, but she wouldn’t want to be seen like this, not for a goodbye. I pull a breathing tube from her throat, I can’t feel the bulb catch on her teeth, her stiffening jaw fighting this release. I pull on the bone needles screwed into her shins, I can’t feel how diabetes has scarred her lower legs. I wipe the blood from her nose and mouth, I can’t feel how cold the blood already is. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;A naked monster, celebrating his first day outside of prison with a cocktail of street drugs and liquor, kicking in the door. A boy, just eight, standing behind the door, holding a bat to protect his four-year-old sister from the monster outside. I can’t feel their panic, I don’t know they stand just feet from where the monster and I fight. I can’t feel his fingernails, carving deep and bloody into my arm. I can’t feel the burning as sweat, blood, and mace spray mix into the bloody cuts. He can’t feel the pain, he’s well beyond feeling. As he breaks the porch, breaks the door, breaks my skin, breaks the quiet peace of the neighborhood, I can’t feel his hair in both my hands, pulling him back from the sidewalk where he slams his head. Even today, I can’t feel those five long scars on my arm. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;A stolen car, a property crime. A man, too much time inside bars, reaching for the gun wrapped in a white t-shirt, cleaner than any of his other clothing. I can’t feel his hands around my waist as we fight, as we drag him from the car. I can’t feel the cars driving by us as I punch. His girlfriend screams, but I can’t feel her fear. As I continue to punch, five, six, seven hits, why won’t he stop? My wrist breaks, but I can’t feel that right now. “I’ll give you this,” he says later as we laugh together, “you boys know how to get down. I ain’t never been punched like that.” I can’t feel this admiration, can’t feel how sometimes the only one who understands is the guy you have to fight on the other side of the game. Months later, putting together another Lego set for my son. He can’t feel the bone inside my wrist give too much, the sharp pain that makes me gasp. I can’t feel the wrist, the back, the shoulder that has given too much. She’s right, of course, I couldn’t feel enough.&lt;/p&gt;
&lt;p&gt;Another friend, another loss. Years ago now, he pulled that girl out of the cold creek, did he feel how her six-year-old body was too heavy, too water-soaked? She was the same age as his daughter, his daughter the same age as mine. His daughter’s hand-made cards alongside my daughter’s on the fridge. He’d felt enough; he must’ve had enough.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It Will Have Blood</title>
      <link>https://ianadamsresearch.com/post/it-will-have-blood/it-will-have-blood/</link>
      <pubDate>Thu, 13 Jun 2013 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/it-will-have-blood/it-will-have-blood/</guid>
      <description>
&lt;script src=&#34;https://ianadamsresearch.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I was dispatched on a gunshot. The 65-year-old mother reported her son had just shot himself. She was refusing to provide CPR or go see if he was okay. I was only a couple blocks away. My best friend and I arrived simultaneously and contacted the complainant at the back door. She was in a thin nightgown and completely calm. She said, “He’s down there,” pointing downstairs.&lt;/p&gt;
&lt;p&gt;As we made our way down, I walked through a haze in the air, thick enough that it was forming waves in the air. I didn’t take immediate conscious notice of it, but both my partner and I commented on a strong smell in the air. Although I must have known better, I said that it must be gunpowder, making the connection with the call description of a gunshot.&lt;/p&gt;
&lt;p&gt;As we got to the bottom of the stairs, I stopped at the sound of horrible moaning coming from a back bedroom. I made eye contact with Adam. “You ready?” He nodded, and we moved in slowly.&lt;/p&gt;
&lt;p&gt;The bedroom was tucked off a small hallway that intersected with the main downstairs hallway. I saw the blood before entering. Three walls of the room were covered in goo. I couldn’t see the victim, but I could hear him. I saw a rifle laying on the bed, in a literal pool of blood. I forced myself to take a few more steps through the door. Training takes over, “Don’t stop in the fatal funnel.”&lt;/p&gt;
&lt;p&gt;As I came through the door, I saw him to my left. He was down on all fours, rocking back and forth. The first detail I noticed was his very red shirt. I saw the bottom hem of the shirt was white, it was just a normal white t-shirt.&lt;/p&gt;
&lt;p&gt;“Buddy, we’ve got help coming, just stay there.” I’m not sure what you’re supposed to say. He raised his face to me. It was completely cut in half, the cheek flaps waving back and forth. He had stuck a rifle under his chin, and when he stretched to reach the trigger, his head tipped back. The bullet entered the soft jaw, crossing the hard palate, and left at the top of his nose. There was nothing left but cheeks and eyes.&lt;/p&gt;
&lt;p&gt;I’ll never forget the moaning. On all fours, he rocked back and forth, shaking his head back and forth and just moaning. The sound is still with me. As he shook his head, the two flaps of cheek kept swinging back and forth, opening and closing, just like the fucking Predator. I swear, if that guy had stood up and walked towards me, I would’ve shot him.&lt;/p&gt;
&lt;p&gt;The first few medics arrived. They had been told by dispatch that the subject was “echo” (obviously deceased), and hesitated until I pointed out that they needed to get on this one, and get on it now. They started to cut off his red shirt. I told dispatch to get the bird going now. She said, “You want them on standby?” She was trying to help me, as really only medics are supposed to tell the air medics to fly. “No, tell them to fly now, this one’s going.”&lt;/p&gt;
&lt;p&gt;My sergeant was the third to arrive. When he got downstairs, he took a deep breath, “What’s that smell?”&lt;/p&gt;
&lt;p&gt;“Gunpowder, sarge.”&lt;/p&gt;
&lt;p&gt;“Nah, that’s not gunpowder.” He breathed a few deep nasal breaths. “That’s…like propane or something.”&lt;/p&gt;
&lt;p&gt;The medics stopped and inhaled. “Fuck.” Silence took over, and we all hear at the same time what had been covered up by horrible moaning. In the wall, behind where the man shot himself, was a bullet hole. Out of the hole came a hissing sound. The bullet had cut through the natural gas main that fed the house from the outside meter.&lt;/p&gt;
&lt;p&gt;For the first time in my career, I saw firefighters panic. “Get out get out get out” three of them yelling at the same time. I got on the radio and called “No flames” and told everyone to clear. I saw for the first time what the “waves of haze” I had noticed earlier were. It was natural gas which had filled up the bottom floor of the house, filled it up so much that the “top” of the gas lake was over my eyes, at about six feet deep.&lt;/p&gt;
&lt;p&gt;The medics grabbed the guy and ran upstairs. I quickly cleared the downstairs, thinking the guy might have small kids in the rooms or something. They were clear. I came upstairs and found Adam sitting calmly in the sitting room with the victim’s mother. I stopped, unable to understand what he was doing still in the house.&lt;/p&gt;
&lt;p&gt;“Adam, get her out of here!” I wasn’t yelling yet, but I was angry. I had stayed behind for two minutes in a situation that was probably going to kill me, and he had stayed in the fucking house talking with mom?&lt;/p&gt;
&lt;p&gt;He looked at me, confused. “Adam, get her the fuck out of this house,” I was yelling now. The mother stood up, saying she needed shoes. I grabbed her, probably too hard on the arm, she was old. I pushed her through the door. “Get the fuck out and do it now.” I could feel myself losing a bit of control. I’ve never, never lost control.&lt;/p&gt;
&lt;p&gt;Adam didn’t understand. He had turned his radio down so he could sit with the mom and not have her hear the awful details that would likely be on the radio. He didn’t hear me give out the evacuate order. He still didn’t understand, but he trusted me, or was scared by my reaction, I’m not sure. He stepped between me and the mom, who was still trying to get inside. He did what had to be done, but he did it gently, at least. I couldn’t manage that.&lt;/p&gt;
&lt;p&gt;I went back in with some haz-mat guys ten minutes later. The horror of the room was more noticeable this time. I saw the little bone and teeth chips were stuck in the soles of my boot. I saw that huge glops of human goo were dripping down the walls. I got to the clean wall, the only wall without spackled meat all over it. It was the wall he had faced when he pulled the trigger. I looked down and saw his chin, laying on the carpet at my feet.&lt;/p&gt;
&lt;p&gt;“Dispatch, check with the hospital, see if they want this tissue.” I couldn’t believe I was even asking. The dude was going to die, I knew it, everyone knew it, right?&lt;/p&gt;
&lt;p&gt;“That’s affirm, they want it delivered.”&lt;/p&gt;
&lt;p&gt;“Copy.” How…the…fuck. My sergeant, one of my best friends, offered to do it. “Nah sarge, fuck it, I’ll get it.” I knew I was already gonna feel this one, no need for anyone else to take more of a hit on this. I grabbed a bio sack from one of the firefighters and went upstairs to the freezer. I put a layer of ice inside and went back to the chin.&lt;/p&gt;
&lt;p&gt;You know how sometimes it’s the false expectations that get you? I went to pick up the chin. I knew it would be hard, like chins are. When I grabbed it, though, it felt like unset jello. Of course it did, there was no bone there, it was literally just the chin. It had fallen goo side down, and stuck to the carpet fibers as it dried over the previous thirty or so minutes. I had to tug at, and when it released it landed in my palm, gooey side up. I could see where his whiskers poked out…from the inside. Whoever thought that there was another end to each of our chin whiskers?&lt;/p&gt;
&lt;p&gt;I gave the bad to a firefighter to run it to the hospital. It didn’t matter; I knew he was dead. Or going to be soon enough.&lt;/p&gt;
&lt;p&gt;I learned later that he was 45 years old. At age 35, he got a degenerative brain disease, Huntington’s or something. It took him pretty quick, leaving him with the reasoning skills of an eight-year-old. His mother begged us on the front grass, after I probably bruised her arm, just to let him die. Where’s the DNR? I asked. There wasn’t one.&lt;/p&gt;
&lt;p&gt;He died two hours after shooting himself. They pumped blood bag after blood bag into him, but it all just came out his massive facial wounds.&lt;/p&gt;
&lt;p&gt;The ME called me that night, asked, “So, that was a weird one huh?” Fucking ME’s.&lt;/p&gt;
&lt;p&gt;“What’ya need man?” I asked him.&lt;/p&gt;
&lt;p&gt;“You notice anything strange in there?” he asked.&lt;/p&gt;
&lt;p&gt;“…nope. Just another fucking suicide.”&lt;/p&gt;
&lt;p&gt;“Yeah, figured. Alright, see you on the next one,” he said.&lt;/p&gt;
&lt;p&gt;“Yup.”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ianadamsresearch.com/post/2026-01-04-mpv-data-analysis/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ianadamsresearch.com/post/2026-01-04-mpv-data-analysis/readme/</guid>
      <description>&lt;h1 id=&#34;mpv-data-analysis---auto-updating-blog-post&#34;&gt;MPV Data Analysis - Auto-Updating Blog Post&lt;/h1&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This blog post &lt;strong&gt;automatically updates&lt;/strong&gt; whenever the website is rebuilt. It downloads the latest data from Mapping Police Violence and regenerates all visualizations.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;R Markdown&lt;/strong&gt;: The post is written in R Markdown (&lt;code&gt;index.Rmd&lt;/code&gt;), which contains both text and R code&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automatic Download&lt;/strong&gt;: When the site builds, the R code downloads the latest MPV Excel file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Processing&lt;/strong&gt;: The code cleans and analyzes the data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualization Generation&lt;/strong&gt;: All charts are generated fresh with the latest data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTML Output&lt;/strong&gt;: The &lt;code&gt;.Rmd&lt;/code&gt; file is knitted to &lt;code&gt;index.html&lt;/code&gt;, which is then served by Hugo&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;build-process&#34;&gt;Build Process&lt;/h2&gt;
&lt;p&gt;When you rebuild your website (either locally or via Netlify):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hugo/blogdown processes all &lt;code&gt;.Rmd&lt;/code&gt; files&lt;/li&gt;
&lt;li&gt;The R code chunks execute in order&lt;/li&gt;
&lt;li&gt;Fresh data is downloaded from: &lt;code&gt;https://mappingpoliceviolence.us/s/MPVDatasetDownload.xlsx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Visualizations are created and embedded in the post&lt;/li&gt;
&lt;li&gt;The HTML output includes the latest data and charts&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;h3 id=&#34;data-disclaimers&#34;&gt;Data Disclaimers&lt;/h3&gt;
&lt;p&gt;The post includes prominent warnings that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This data captures &lt;strong&gt;killings only&lt;/strong&gt;, not all uses of lethal force&lt;/li&gt;
&lt;li&gt;Most police shootings are survived, so these numbers undercount total incidents&lt;/li&gt;
&lt;li&gt;The statistics are descriptive only and don&amp;rsquo;t establish causation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;automatic-updates&#34;&gt;Automatic Updates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;No manual intervention needed&lt;/strong&gt; - just rebuild the site&lt;/li&gt;
&lt;li&gt;Data is always current as of the last build&lt;/li&gt;
&lt;li&gt;Date stamps update automatically&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comprehensive-analysis&#34;&gt;Comprehensive Analysis&lt;/h3&gt;
&lt;p&gt;Includes visualizations for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cumulative trends (all deaths and shootings only)&lt;/li&gt;
&lt;li&gt;Demographic patterns (race, age)&lt;/li&gt;
&lt;li&gt;Behavioral context (armed status, mental health)&lt;/li&gt;
&lt;li&gt;Temporal patterns (seasonal, day of week)&lt;/li&gt;
&lt;li&gt;Geographic distribution (maps, states, cities)&lt;/li&gt;
&lt;li&gt;Per capita rates&lt;/li&gt;
&lt;li&gt;Accountability and socioeconomic factors&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;required-r-packages&#34;&gt;Required R Packages&lt;/h2&gt;
&lt;p&gt;The analysis requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tidyverse&lt;/li&gt;
&lt;li&gt;readxl&lt;/li&gt;
&lt;li&gt;lubridate&lt;/li&gt;
&lt;li&gt;gghighlight&lt;/li&gt;
&lt;li&gt;ggthemes&lt;/li&gt;
&lt;li&gt;ggrepel&lt;/li&gt;
&lt;li&gt;slider&lt;/li&gt;
&lt;li&gt;sf&lt;/li&gt;
&lt;li&gt;rnaturalearth&lt;/li&gt;
&lt;li&gt;rnaturalearthdata&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These should be installed in your R environment where the site builds.&lt;/p&gt;
&lt;h2 id=&#34;customization&#34;&gt;Customization&lt;/h2&gt;
&lt;p&gt;To modify the analysis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Edit &lt;code&gt;index.Rmd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rebuild the site locally to test: &lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Commit and push changes&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;data-source&#34;&gt;Data Source&lt;/h2&gt;
&lt;p&gt;Data automatically downloaded from:
&lt;strong&gt;Mapping Police Violence&lt;/strong&gt;: &lt;a href=&#34;https://mappingpoliceviolence.org/&#34;&gt;https://mappingpoliceviolence.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The database is continuously updated and currently includes data through 12/31/2025.&lt;/p&gt;
&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The download happens at build time, so there&amp;rsquo;s a brief delay&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;.Rmd&lt;/code&gt; file has &lt;code&gt;cache=FALSE&lt;/code&gt; on the download chunk to ensure fresh data&lt;/li&gt;
&lt;li&gt;All file paths are temporary to avoid cluttering the repository&lt;/li&gt;
&lt;li&gt;Visualizations are embedded directly in the HTML (no separate image files needed)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
